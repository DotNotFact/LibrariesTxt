public class Microsoft.Spark.Broadcast`1 : object {
    private string _path;
    private JvmObjectReference _jvmObject;
    private long _bid;
    public JvmObjectReference Reference { get; }
    internal Broadcast`1(SparkContext sc, T value);
    public sealed virtual JvmObjectReference get_Reference();
    public T Value();
    public void Unpersist();
    public void Unpersist(bool blocking);
    public void Destroy();
    [OnSerializedAttribute]
internal void OnSerialized(StreamingContext context);
    private string CreateTempFilePath(SparkConf conf);
    private JvmObjectReference CreateBroadcast(SparkContext sc, T value);
    private JvmObjectReference CreateBroadcast_V2_4_X(JvmObjectReference javaSparkContext, SparkContext sc, object value);
    private void WriteToStream(object value, Stream stream);
    private void WriteToFile(object value);
    private void Dump(object value, Stream stream);
}
internal static class Microsoft.Spark.BroadcastRegistry : object {
    private static ConcurrentDictionary`2<long, object> s_registry;
    private static ILoggerService s_logger;
    private static BroadcastRegistry();
    internal static void Add(long bid, object value);
    internal static void Remove(long bid);
    internal static object Get(long bid);
}
internal class Microsoft.Spark.Constants : object {
    internal static string RunningREPLEnvVar;
}
[AttributeUsageAttribute("32767")]
public class Microsoft.Spark.DeprecatedAttribute : VersionAttribute {
    public DeprecatedAttribute(string version);
}
[ExtensionAttribute]
public static class Microsoft.Spark.Experimental.Sql.SparkSessionExtensions : object {
    [ExtensionAttribute]
public static DataFrame GetAssemblyInfo(SparkSession session, int numPartitions);
    private static GenericRow CreateGenericRow(AssemblyInfo assemblyInfo);
}
public class Microsoft.Spark.Hadoop.Conf.Configuration : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal Configuration(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
}
public class Microsoft.Spark.Hadoop.Fs.FileSystem : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal FileSystem(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public static FileSystem Get(Configuration conf);
    public bool Delete(string path, bool recursive);
    public bool Exists(string path);
    public sealed virtual void Dispose();
}
internal class Microsoft.Spark.Interop.Internal.Java.Util.ArrayList : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal ArrayList(IJvmBridge jvm);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    internal void Add(object element);
    internal void AddAll(IEnumerable`1<object> collection);
}
internal class Microsoft.Spark.Interop.Internal.Java.Util.HashMap : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal HashMap(IJvmBridge jvm);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    internal void Put(object key, object value);
    internal object Get(object key);
    internal bool ContainsValue(object value);
    internal Object[] Keys();
}
internal class Microsoft.Spark.Interop.Internal.Java.Util.Hashtable : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal Hashtable(IJvmBridge jvm);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    internal void Put(object key, object value);
}
internal class Microsoft.Spark.Interop.Internal.Java.Util.Properties : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal Properties(IJvmBridge jvm);
    internal Properties(IJvmBridge jvm, Dictionary`2<string, string> properties);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
}
internal class Microsoft.Spark.Interop.Internal.Scala.Option : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal Option(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    internal bool IsEmpty();
    internal bool IsDefined();
    internal object Get();
    internal object OrNull();
}
internal class Microsoft.Spark.Interop.Internal.Scala.Seq`1 : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public int Size { get; }
    internal Seq`1(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    private sealed virtual override IEnumerator System.Collections.IEnumerable.GetEnumerator();
    public int get_Size();
    [IteratorStateMachineAttribute("Microsoft.Spark.Interop.Internal.Scala.Seq`1/<GetEnumerator>d__8")]
public sealed virtual IEnumerator`1<T> GetEnumerator();
    public T Apply(int index);
}
internal class Microsoft.Spark.Interop.Ipc.CallbackConnection : object {
    private static ILoggerService s_logger;
    private ISocketWrapper _socket;
    private ConcurrentDictionary`2<int, ICallbackHandler> _callbackHandlers;
    private Boolean modreq(System.Runtime.CompilerServices.IsVolatile) _isRunning;
    private int _numCallbacksRun;
    [CompilerGeneratedAttribute]
private long <ConnectionId>k__BackingField;
    internal long ConnectionId { get; }
    internal bool IsRunning { get; }
    internal CallbackConnection(long connectionId, ISocketWrapper socket, ConcurrentDictionary`2<int, ICallbackHandler> callbackHandlers);
    private static CallbackConnection();
    [CompilerGeneratedAttribute]
internal long get_ConnectionId();
    internal bool get_IsRunning();
    internal void Run(CancellationToken token);
    private void Stop();
    private ConnectionStatus ProcessStream(Stream inputStream, Stream outputStream, Boolean& readComplete);
    [CompilerGeneratedAttribute]
private void <Run>b__12_0();
}
internal enum Microsoft.Spark.Interop.Ipc.CallbackFlags : Enum {
    public int value__;
    public static CallbackFlags CLOSE;
    public static CallbackFlags CALLBACK;
    public static CallbackFlags DOTNET_EXCEPTION_THROWN;
    public static CallbackFlags END_OF_STREAM;
}
internal class Microsoft.Spark.Interop.Ipc.CallbackServer : object {
    private static ILoggerService s_logger;
    private IJvmBridge _jvm;
    private ConcurrentDictionary`2<int, ICallbackHandler> _callbackHandlers;
    private ConcurrentDictionary`2<long, CallbackConnection> _connections;
    private BlockingCollection`1<CallbackConnection> _waitingConnections;
    private CancellationTokenSource _tokenSource;
    private int _callbackCounter;
    private bool _isRunning;
    private ISocketWrapper _listener;
    private JvmObjectReference _jvmCallbackClient;
    internal int CurrentNumConnections { get; }
    internal JvmObjectReference JvmCallbackClient { get; }
    internal CallbackServer(IJvmBridge jvm, bool run);
    private static CallbackServer();
    internal int get_CurrentNumConnections();
    internal JvmObjectReference get_JvmCallbackClient();
    internal int RegisterCallback(ICallbackHandler callbackHandler);
    internal void Run(ISocketWrapper listener);
    private void Run();
    private void StartServer(ISocketWrapper listener);
    private void RunWorkerThread();
    private void Shutdown();
    [CompilerGeneratedAttribute]
private void <.ctor>b__14_0(object s, EventArgs e);
    [CompilerGeneratedAttribute]
private void <Run>b__16_0();
}
internal class Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler : object {
    private IJvmBridge _jvm;
    private Action`2<DataFrame, long> _func;
    internal ForeachBatchCallbackHandler(IJvmBridge jvm, Action`2<DataFrame, long> func);
    public sealed virtual void Run(Stream inputStream);
}
internal interface Microsoft.Spark.Interop.Ipc.ICallbackHandler {
    public abstract virtual void Run(Stream inputStream);
}
public interface Microsoft.Spark.Interop.Ipc.IJvmBridge {
    public abstract virtual JvmObjectReference CallConstructor(string className, object arg0);
    public abstract virtual JvmObjectReference CallConstructor(string className, object arg0, object arg1);
    public abstract virtual JvmObjectReference CallConstructor(string className, Object[] args);
    public abstract virtual object CallStaticJavaMethod(string className, string methodName, object arg0);
    public abstract virtual object CallStaticJavaMethod(string className, string methodName, object arg0, object arg1);
    public abstract virtual object CallStaticJavaMethod(string className, string methodName, Object[] args);
    public abstract virtual object CallNonStaticJavaMethod(JvmObjectReference jvmObject, string methodName, object arg0);
    public abstract virtual object CallNonStaticJavaMethod(JvmObjectReference jvmObject, string methodName, object arg0, object arg1);
    public abstract virtual object CallNonStaticJavaMethod(JvmObjectReference jvmObject, string methodName, Object[] args);
}
internal interface Microsoft.Spark.Interop.Ipc.IJvmBridgeFactory {
    public abstract virtual IJvmBridge Create(int portNumber);
}
public interface Microsoft.Spark.Interop.Ipc.IJvmObjectReferenceProvider {
    public JvmObjectReference Reference { get; }
    public abstract virtual JvmObjectReference get_Reference();
}
[ExtensionAttribute]
internal static class Microsoft.Spark.Interop.Ipc.JsonSerDe : object {
    [ExtensionAttribute]
public static JObject SortProperties(JObject jObject);
    [ExtensionAttribute]
public static JArray SortProperties(JArray jArray);
}
internal class Microsoft.Spark.Interop.Ipc.JvmBridge : object {
    [ThreadStaticAttribute]
private static Object[] s_oneArgArray;
    [ThreadStaticAttribute]
private static Object[] s_twoArgArray;
    [ThreadStaticAttribute]
private static MemoryStream s_payloadMemoryStream;
    private static int SocketBufferThreshold;
    private static int ThreadIdForRepl;
    private int _processId;
    private SemaphoreSlim _socketSemaphore;
    private ConcurrentQueue`1<ISocketWrapper> _sockets;
    private ILoggerService _logger;
    private int _portNumber;
    private JvmThreadPoolGC _jvmThreadPoolGC;
    private bool _isRunningRepl;
    internal JvmBridge(int portNumber);
    private ISocketWrapper GetConnection();
    public sealed virtual JvmObjectReference CallConstructor(string className, object arg0);
    public sealed virtual JvmObjectReference CallConstructor(string className, object arg0, object arg1);
    public sealed virtual JvmObjectReference CallConstructor(string className, Object[] args);
    public sealed virtual object CallStaticJavaMethod(string className, string methodName, object arg0);
    public sealed virtual object CallStaticJavaMethod(string className, string methodName, object arg0, object arg1);
    public sealed virtual object CallStaticJavaMethod(string className, string methodName, Object[] args);
    public sealed virtual object CallNonStaticJavaMethod(JvmObjectReference jvmObject, string methodName, object arg0);
    public sealed virtual object CallNonStaticJavaMethod(JvmObjectReference jvmObject, string methodName, object arg0, object arg1);
    public sealed virtual object CallNonStaticJavaMethod(JvmObjectReference jvmObject, string methodName, Object[] args);
    private object CallJavaMethod(bool isStatic, object classNameOrJvmObjectReference, string methodName, object arg0);
    private object CallJavaMethod(bool isStatic, object classNameOrJvmObjectReference, string methodName, object arg0, object arg1);
    private object CallJavaMethod(bool isStatic, object classNameOrJvmObjectReference, string methodName, Object[] args);
    private string BuildErrorMessage(bool isStatic, object classNameOrJvmObjectReference, string methodName, Object[] args);
    private string GetArgsAsString(IEnumerable`1<object> args);
    private object ReadCollection(Stream s);
    public sealed virtual void Dispose();
}
internal class Microsoft.Spark.Interop.Ipc.JvmBridgeFactory : object {
    public sealed virtual IJvmBridge Create(int portNumber);
}
internal class Microsoft.Spark.Interop.Ipc.JvmObjectId : object {
    private static ILoggerService s_logger;
    [CompilerGeneratedAttribute]
private string <Id>k__BackingField;
    [CompilerGeneratedAttribute]
private IJvmBridge <Jvm>k__BackingField;
    internal string Id { get; }
    internal IJvmBridge Jvm { get; }
    internal JvmObjectId(string id, IJvmBridge jvm);
    private static JvmObjectId();
    protected virtual override void Finalize();
    [CompilerGeneratedAttribute]
internal string get_Id();
    [CompilerGeneratedAttribute]
internal IJvmBridge get_Jvm();
    public static string op_Implicit(JvmObjectId jvmObjectId);
    public virtual string ToString();
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    private void RemoveId();
    [CompilerGeneratedAttribute]
private void <Finalize>b__2_0(object _);
}
public class Microsoft.Spark.Interop.Ipc.JvmObjectReference : object {
    private DateTime _creationTime;
    [CompilerGeneratedAttribute]
private JvmObjectId <Id>k__BackingField;
    internal JvmObjectId Id { get; }
    public IJvmBridge Jvm { get; }
    private JvmObjectReference Microsoft.Spark.Interop.Ipc.IJvmObjectReferenceProvider.Reference { get; }
    internal JvmObjectReference(string id, IJvmBridge jvm);
    internal JvmObjectReference(JvmObjectReference other);
    [CompilerGeneratedAttribute]
internal JvmObjectId get_Id();
    public IJvmBridge get_Jvm();
    private sealed virtual override JvmObjectReference Microsoft.Spark.Interop.Ipc.IJvmObjectReferenceProvider.get_Reference();
    public object Invoke(string methodName, object arg0);
    public object Invoke(string methodName, object arg0, object arg1);
    public object Invoke(string methodName, Object[] args);
    public virtual string ToString();
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    public string GetDebugInfo();
}
internal class Microsoft.Spark.Interop.Ipc.JvmThreadPoolGC : object {
    private ILoggerService _loggerService;
    private IJvmBridge _jvmBridge;
    private TimeSpan _threadGCInterval;
    private int _processId;
    private ConcurrentDictionary`2<int, Thread> _activeThreads;
    private object _activeThreadGCTimerLock;
    private Timer _activeThreadGCTimer;
    public JvmThreadPoolGC(ILoggerService loggerService, IJvmBridge jvmBridge, TimeSpan threadGCInterval, int processId);
    public sealed virtual void Dispose();
    public bool TryAddThread(Thread thread);
    private bool TryDisposeJvmThread(int threadId);
    private void GCThreads();
    [CompilerGeneratedAttribute]
private void <TryAddThread>b__9_0(object state);
}
internal class Microsoft.Spark.Interop.Ipc.PayloadHelper : object {
    private static Byte[] s_int32TypeId;
    private static Byte[] s_int64TypeId;
    private static Byte[] s_stringTypeId;
    private static Byte[] s_boolTypeId;
    private static Byte[] s_doubleTypeId;
    private static Byte[] s_dateTypeId;
    private static Byte[] s_timestampTypeId;
    private static Byte[] s_jvmObjectTypeId;
    private static Byte[] s_byteArrayTypeId;
    private static Byte[] s_doubleArrayArrayTypeId;
    private static Byte[] s_arrayTypeId;
    private static Byte[] s_dictionaryTypeId;
    private static Byte[] s_rowArrTypeId;
    private static Byte[] s_objectArrTypeId;
    private static ConcurrentDictionary`2<Type, bool> s_isDictionaryTable;
    private static PayloadHelper();
    internal static void BuildPayload(MemoryStream destination, bool isStaticMethod, int processId, int threadId, object classNameOrJvmObjectReference, string methodName, Object[] args);
    internal static void ConvertArgsToBytes(MemoryStream destination, Object[] args, bool addTypeIdPrefix);
    internal static Byte[] GetTypeId(Type type);
    private static bool IsDictionary(Type type);
}
internal class Microsoft.Spark.Interop.Ipc.SerDe : object {
    [ThreadStaticAttribute]
private static Byte[] s_threadLocalBuffer;
    public static bool ReadBool(Stream s);
    public static int ReadInt32(Stream s);
    public static long ReadInt64(Stream s);
    public static double ReadDouble(Stream s);
    public static string ReadString(Stream s);
    public static string ReadString(Stream s, int length);
    public static Byte[] ReadBytes(Stream s, int length);
    public static bool TryReadBytes(Stream s, Byte[] buffer, int length);
    public static Nullable`1<int> ReadBytesLength(Stream s);
    public static Byte[] ReadBytes(Stream s);
    private static Byte[] GetThreadLocalBuffer(int minSize);
    public static void Write(Stream s, byte value);
    public static void Write(Stream s, Byte[] value);
    public static void Write(Stream s, Byte[] value, int count);
    public static void Write(Stream s, bool value);
    public static void Write(Stream s, int value);
    public static void Write(Stream s, long value);
    public static void Write(Stream s, double value);
    public static void Write(Stream s, string value);
}
internal enum Microsoft.Spark.Interop.Ipc.SpecialLengths : Enum {
    public int value__;
    public static SpecialLengths END_OF_DATA_SECTION;
    public static SpecialLengths PYTHON_EXCEPTION_THROWN;
    public static SpecialLengths TIMING_DATA;
    public static SpecialLengths END_OF_STREAM;
    public static SpecialLengths NULL;
    public static SpecialLengths START_ARROW_STREAM;
}
public static class Microsoft.Spark.Interop.SparkEnvironment : object {
    private static ILoggerService s_logger;
    private static Lazy`1<Version> s_sparkVersion;
    private static IJvmBridgeFactory s_jvmBridgeFactory;
    private static IJvmBridge s_jvmBridge;
    private static IConfigurationService s_configurationService;
    private static CallbackServer s_callbackServer;
    internal static Version SparkVersion { get; }
    internal static IJvmBridgeFactory JvmBridgeFactory { get; internal set; }
    public static IJvmBridge JvmBridge { get; public set; }
    internal static IConfigurationService ConfigurationService { get; internal set; }
    internal static CallbackServer CallbackServer { get; }
    private static SparkEnvironment();
    private static Version GetSparkVersion();
    internal static Version get_SparkVersion();
    internal static IJvmBridgeFactory get_JvmBridgeFactory();
    internal static void set_JvmBridgeFactory(IJvmBridgeFactory value);
    public static IJvmBridge get_JvmBridge();
    public static void set_JvmBridge(IJvmBridge value);
    internal static IConfigurationService get_ConfigurationService();
    internal static void set_ConfigurationService(IConfigurationService value);
    internal static CallbackServer get_CallbackServer();
}
internal static class Microsoft.Spark.JvmBroadcastRegistry : object {
    private static ThreadLocal`1<List`1<JvmObjectReference>> s_jvmBroadcastVariables;
    private static JvmBroadcastRegistry();
    internal static void Add(JvmObjectReference broadcastJvmObject);
    internal static void Clear();
    internal static List`1<JvmObjectReference> GetAll();
}
public class Microsoft.Spark.JvmException : Exception {
    public JvmException(string message);
}
public class Microsoft.Spark.ML.Feature.Bucketizer : JavaModel`1<Bucketizer> {
    private static string s_className;
    public Bucketizer(string uid);
    internal Bucketizer(JvmObjectReference jvmObject);
    private static Bucketizer();
    public Double[] GetSplits();
    public Bucketizer SetSplits(Double[] value);
    public Double[][] GetSplitsArray();
    public Bucketizer SetSplitsArray(Double[][] value);
    public string GetInputCol();
    public Bucketizer SetInputCol(string value);
    public IEnumerable`1<string> GetInputCols();
    public Bucketizer SetInputCols(IEnumerable`1<string> value);
    public string GetOutputCol();
    public Bucketizer SetOutputCol(string value);
    public IEnumerable`1<string> GetOutputCols();
    public Bucketizer SetOutputCols(List`1<string> value);
    public static Bucketizer Load(string path);
    public virtual DataFrame Transform(DataFrame source);
    public string GetHandleInvalid();
    public Bucketizer SetHandleInvalid(string value);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<Bucketizer> Read();
    private static Bucketizer WrapAsBucketizer(object obj);
}
public class Microsoft.Spark.ML.Feature.CountVectorizer : JavaEstimator`1<CountVectorizerModel> {
    private static string s_className;
    public CountVectorizer(string uid);
    internal CountVectorizer(JvmObjectReference jvmObject);
    private static CountVectorizer();
    public virtual CountVectorizerModel Fit(DataFrame dataFrame);
    public static CountVectorizer Load(string path);
    public bool GetBinary();
    public CountVectorizer SetBinary(bool value);
    public string GetInputCol();
    public CountVectorizer SetInputCol(string value);
    public string GetOutputCol();
    public CountVectorizer SetOutputCol(string value);
    [SinceAttribute("2.4.0")]
public double GetMaxDF();
    [SinceAttribute("2.4.0")]
public CountVectorizer SetMaxDF(double value);
    public double GetMinDF();
    public CountVectorizer SetMinDF(double value);
    public double GetMinTF();
    public CountVectorizer SetMinTF(double value);
    public int GetVocabSize();
    public CountVectorizer SetVocabSize(int value);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<CountVectorizer> Read();
    private static CountVectorizer WrapAsCountVectorizer(object obj);
}
public class Microsoft.Spark.ML.Feature.CountVectorizerModel : JavaModel`1<CountVectorizerModel> {
    private static string s_className;
    public CountVectorizerModel(List`1<string> vocabulary);
    public CountVectorizerModel(string uid, List`1<string> vocabulary);
    internal CountVectorizerModel(JvmObjectReference jvmObject);
    private static CountVectorizerModel();
    public static CountVectorizerModel Load(string path);
    public bool GetBinary();
    public CountVectorizerModel SetBinary(bool value);
    public string GetInputCol();
    public CountVectorizerModel SetInputCol(string value);
    public string GetOutputCol();
    public CountVectorizerModel SetOutputCol(string value);
    public double GetMaxDF();
    public double GetMinDF();
    public double GetMinTF();
    public CountVectorizerModel SetMinTF(double value);
    public int GetVocabSize();
    public virtual StructType TransformSchema(StructType value);
    public virtual DataFrame Transform(DataFrame document);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<CountVectorizerModel> Read();
    private static CountVectorizerModel WrapAsCountVectorizerModel(object obj);
}
public class Microsoft.Spark.ML.Feature.FeatureHasher : JavaTransformer {
    private static string s_className;
    public FeatureHasher(string uid);
    internal FeatureHasher(JvmObjectReference jvmObject);
    private static FeatureHasher();
    public static FeatureHasher Load(string path);
    public IEnumerable`1<string> GetCategoricalCols();
    public FeatureHasher SetCategoricalCols(IEnumerable`1<string> value);
    public IEnumerable`1<string> GetInputCols();
    public FeatureHasher SetInputCols(IEnumerable`1<string> value);
    public int GetNumFeatures();
    public FeatureHasher SetNumFeatures(int value);
    public string GetOutputCol();
    public FeatureHasher SetOutputCol(string value);
    public virtual DataFrame Transform(DataFrame value);
    public virtual StructType TransformSchema(StructType value);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<FeatureHasher> Read();
    private static FeatureHasher WrapAsFeatureHasher(object obj);
}
public class Microsoft.Spark.ML.Feature.HashingTF : JavaTransformer {
    private static string s_className;
    public HashingTF(string uid);
    internal HashingTF(JvmObjectReference jvmObject);
    private static HashingTF();
    public static HashingTF Load(string path);
    public bool GetBinary();
    public HashingTF SetBinary(bool value);
    public string GetInputCol();
    public HashingTF SetInputCol(string value);
    public string GetOutputCol();
    public HashingTF SetOutputCol(string value);
    public int GetNumFeatures();
    public HashingTF SetNumFeatures(int value);
    public virtual DataFrame Transform(DataFrame source);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<HashingTF> Read();
    private static HashingTF WrapAsHashingTF(object obj);
}
public interface Microsoft.Spark.ML.Feature.Identifiable {
    public abstract virtual string Uid();
}
public class Microsoft.Spark.ML.Feature.IDF : JavaEstimator`1<IDFModel> {
    private static string s_className;
    public IDF(string uid);
    internal IDF(JvmObjectReference jvmObject);
    private static IDF();
    public string GetInputCol();
    public IDF SetInputCol(string value);
    public string GetOutputCol();
    public IDF SetOutputCol(string value);
    public int GetMinDocFreq();
    public IDF SetMinDocFreq(int value);
    public virtual IDFModel Fit(DataFrame source);
    public static IDF Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<IDF> Read();
    private static IDF WrapAsIDF(object obj);
}
public class Microsoft.Spark.ML.Feature.IDFModel : JavaModel`1<IDFModel> {
    private static string s_className;
    public IDFModel(string uid);
    internal IDFModel(JvmObjectReference jvmObject);
    private static IDFModel();
    public string GetInputCol();
    public IDFModel SetInputCol(string value);
    public string GetOutputCol();
    public IDFModel SetOutputCol(string value);
    public int GetMinDocFreq();
    public virtual DataFrame Transform(DataFrame source);
    public static IDFModel Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<IDFModel> Read();
    private static IDFModel WrapAsIDFModel(object obj);
}
public interface Microsoft.Spark.ML.Feature.IEstimator`1 {
    public abstract virtual M Fit(DataFrame dataset);
}
public interface Microsoft.Spark.ML.Feature.IJavaMLReadable`1 {
    public abstract virtual JavaMLReader`1<T> Read();
}
public interface Microsoft.Spark.ML.Feature.IJavaMLWritable {
    public abstract virtual JavaMLWriter Write();
    public abstract virtual void Save(string path);
}
public interface Microsoft.Spark.ML.Feature.IModel`1 {
    public abstract virtual bool HasParent();
}
public abstract class Microsoft.Spark.ML.Feature.JavaEstimator`1 : JavaPipelineStage {
    internal JavaEstimator`1(string className);
    internal JavaEstimator`1(string className, string uid);
    internal JavaEstimator`1(JvmObjectReference jvmObject);
    public virtual M Fit(DataFrame dataset);
}
public abstract class Microsoft.Spark.ML.Feature.JavaEvaluator : Params {
    public bool IsLargerBetter { get; }
    internal JavaEvaluator(string className);
    internal JavaEvaluator(string className, string uid);
    internal JavaEvaluator(JvmObjectReference jvmObject);
    public virtual double Evaluate(DataFrame dataset);
    public bool get_IsLargerBetter();
}
public class Microsoft.Spark.ML.Feature.JavaMLReader`1 : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal JavaMLReader`1(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public T Load(string path);
    public JavaMLReader`1<T> Session(SparkSession sparkSession);
    private static T WrapAsType(JvmObjectReference reference);
}
public class Microsoft.Spark.ML.Feature.JavaMLWriter : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal JavaMLWriter(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public void Save(string path);
    protected void SaveImpl(string path);
    public JavaMLWriter Overwrite();
    public JavaMLWriter Option(string key, string value);
    public JavaMLWriter Session(SparkSession sparkSession);
}
public abstract class Microsoft.Spark.ML.Feature.JavaModel`1 : JavaTransformer {
    internal JavaModel`1(string className);
    internal JavaModel`1(string className, string uid);
    internal JavaModel`1(JvmObjectReference jvmObject);
    public M SetParent(JavaEstimator`1<M> parent);
    public sealed virtual bool HasParent();
}
public abstract class Microsoft.Spark.ML.Feature.JavaPipelineStage : Params {
    internal JavaPipelineStage(string className);
    internal JavaPipelineStage(string className, string uid);
    internal JavaPipelineStage(JvmObjectReference jvmObject);
    public virtual StructType TransformSchema(StructType schema);
}
public abstract class Microsoft.Spark.ML.Feature.JavaTransformer : JavaPipelineStage {
    internal JavaTransformer(string className);
    internal JavaTransformer(string className, string uid);
    internal JavaTransformer(JvmObjectReference jvmObject);
    public virtual DataFrame Transform(DataFrame dataset);
}
public class Microsoft.Spark.ML.Feature.NGram : JavaTransformer {
    private static string s_className;
    public NGram(string uid);
    internal NGram(JvmObjectReference jvmObject);
    private static NGram();
    public string GetInputCol();
    public NGram SetInputCol(string value);
    public string GetOutputCol();
    public NGram SetOutputCol(string value);
    public int GetN();
    public NGram SetN(int value);
    public virtual DataFrame Transform(DataFrame source);
    public virtual StructType TransformSchema(StructType value);
    public static NGram Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<NGram> Read();
    private static NGram WrapAsNGram(object obj);
}
public class Microsoft.Spark.ML.Feature.Param.Param : object {
    private static string s_ParamClassName;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public string Doc { get; }
    public string Name { get; }
    public string Parent { get; }
    public Param(Identifiable parent, string name, string doc);
    public Param(string parent, string name, string doc);
    internal Param(JvmObjectReference jvmObject);
    private static Param();
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public string get_Doc();
    public string get_Name();
    public string get_Parent();
}
public class Microsoft.Spark.ML.Feature.Param.ParamMap : object {
    private static string s_ParamMapClassName;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal ParamMap(JvmObjectReference jvmObject);
    private static ParamMap();
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public ParamMap Put(Param param, T value);
    public virtual string ToString();
    private static ParamMap WrapAsParamMap(object obj);
}
public class Microsoft.Spark.ML.Feature.Param.ParamPair`1 : object {
    private static string s_ParamPairClassName;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public ParamPair`1(Param param, T value);
    internal ParamPair`1(JvmObjectReference jvmObject);
    private static ParamPair`1();
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
}
public abstract class Microsoft.Spark.ML.Feature.Params : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal Params(string className);
    internal Params(string className, string uid);
    internal Params(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public virtual string ToString();
    public sealed virtual string Uid();
    public string ExplainParam(Param param);
    public string ExplainParams();
    public bool IsSet(Param param);
    public bool IsDefined(Param param);
    public bool HasParam(string paramName);
    public Param GetParam(string paramName);
    public T Set(Param param, object value);
    public T Clear(Param param);
    protected static T WrapAsType(JvmObjectReference reference);
}
public class Microsoft.Spark.ML.Feature.Pipeline : JavaEstimator`1<PipelineModel> {
    private static string s_className;
    public Pipeline(string uid);
    internal Pipeline(JvmObjectReference jvmObject);
    private static Pipeline();
    public Pipeline SetStages(JavaPipelineStage[] value);
    public JavaPipelineStage[] GetStages();
    public virtual PipelineModel Fit(DataFrame dataset);
    public static Pipeline Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<Pipeline> Read();
    private static Pipeline WrapAsPipeline(object obj);
}
public class Microsoft.Spark.ML.Feature.PipelineModel : JavaModel`1<PipelineModel> {
    private static string s_className;
    public PipelineModel(string uid, JavaTransformer[] stages);
    internal PipelineModel(JvmObjectReference jvmObject);
    private static PipelineModel();
    public static PipelineModel Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<PipelineModel> Read();
    private static PipelineModel WrapAsPipelineModel(object obj);
}
public class Microsoft.Spark.ML.Feature.SQLTransformer : JavaTransformer {
    private static string s_className;
    public SQLTransformer(string uid);
    internal SQLTransformer(JvmObjectReference jvmObject);
    private static SQLTransformer();
    public virtual DataFrame Transform(DataFrame source);
    public virtual StructType TransformSchema(StructType value);
    public string GetStatement();
    public SQLTransformer SetStatement(string statement);
    public static SQLTransformer Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<SQLTransformer> Read();
    private static SQLTransformer WrapAsSQLTransformer(object obj);
}
public class Microsoft.Spark.ML.Feature.StopWordsRemover : JavaTransformer {
    private static string s_className;
    public StopWordsRemover(string uid);
    internal StopWordsRemover(JvmObjectReference jvmObject);
    private static StopWordsRemover();
    public StopWordsRemover SetInputCol(string value);
    public StopWordsRemover SetOutputCol(string value);
    public virtual DataFrame Transform(DataFrame source);
    public string GetInputCol();
    public string GetOutputCol();
    [SinceAttribute("2.4.0")]
public StopWordsRemover SetLocale(string value);
    [SinceAttribute("2.4.0")]
public string GetLocale();
    public StopWordsRemover SetCaseSensitive(bool value);
    public bool GetCaseSensitive();
    public StopWordsRemover SetStopWords(IEnumerable`1<string> values);
    public IEnumerable`1<string> GetStopWords();
    public virtual StructType TransformSchema(StructType value);
    public static String[] LoadDefaultStopWords(string language);
    public static StopWordsRemover Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<StopWordsRemover> Read();
    private static StopWordsRemover WrapAsStopWordsRemover(object obj);
}
public class Microsoft.Spark.ML.Feature.Tokenizer : JavaTransformer {
    private static string s_className;
    public Tokenizer(string uid);
    internal Tokenizer(JvmObjectReference jvmObject);
    private static Tokenizer();
    public string GetInputCol();
    public Tokenizer SetInputCol(string value);
    public string GetOutputCol();
    public Tokenizer SetOutputCol(string value);
    public virtual DataFrame Transform(DataFrame source);
    public static Tokenizer Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<Tokenizer> Read();
    private static Tokenizer WrapAsTokenizer(object obj);
}
public class Microsoft.Spark.ML.Feature.Word2Vec : JavaEstimator`1<Word2VecModel> {
    private static string s_className;
    public Word2Vec(string uid);
    internal Word2Vec(JvmObjectReference jvmObject);
    private static Word2Vec();
    public string GetInputCol();
    public Word2Vec SetInputCol(string value);
    public string GetOutputCol();
    public Word2Vec SetOutputCol(string value);
    public int GetVectorSize();
    public Word2Vec SetVectorSize(int value);
    public int GetMinCount();
    public virtual Word2Vec SetMinCount(int value);
    public int GetMaxIter();
    public Word2Vec SetMaxIter(int value);
    public virtual int GetMaxSentenceLength();
    public Word2Vec SetMaxSentenceLength(int value);
    public int GetNumPartitions();
    public Word2Vec SetNumPartitions(int value);
    public long GetSeed();
    public Word2Vec SetSeed(long value);
    public double GetStepSize();
    public Word2Vec SetStepSize(double value);
    public int GetWindowSize();
    public Word2Vec SetWindowSize(int value);
    public virtual Word2VecModel Fit(DataFrame dataFrame);
    public static Word2Vec Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<Word2Vec> Read();
    private static Word2Vec WrapAsWord2Vec(object obj);
}
public class Microsoft.Spark.ML.Feature.Word2VecModel : JavaModel`1<Word2VecModel> {
    private static string s_className;
    public Word2VecModel(string uid);
    internal Word2VecModel(JvmObjectReference jvmObject);
    private static Word2VecModel();
    public virtual DataFrame Transform(DataFrame documentDF);
    public DataFrame FindSynonyms(string word, int num);
    public static Word2VecModel Load(string path);
    public sealed virtual void Save(string path);
    public sealed virtual JavaMLWriter Write();
    public sealed virtual JavaMLReader`1<Word2VecModel> Read();
    private static Word2VecModel WrapAsWord2VecModel(object obj);
}
internal class Microsoft.Spark.Network.DefaultSocketWrapper : object {
    private Socket _innerSocket;
    private Stream _inputStream;
    private Stream _outputStream;
    public Stream InputStream { get; }
    public Stream OutputStream { get; }
    public EndPoint LocalEndPoint { get; }
    public EndPoint RemoteEndPoint { get; }
    private DefaultSocketWrapper(Socket socket);
    public sealed virtual void Dispose();
    public sealed virtual ISocketWrapper Accept();
    public sealed virtual void Connect(IPAddress remoteaddr, int port, string secret);
    private NetworkStream CreateNetworkStream();
    public sealed virtual Stream get_InputStream();
    public sealed virtual Stream get_OutputStream();
    private Stream CreateStream(string bufferSizeEnvVarName);
    public sealed virtual void Listen(int backlog);
    public sealed virtual EndPoint get_LocalEndPoint();
    public sealed virtual EndPoint get_RemoteEndPoint();
}
internal interface Microsoft.Spark.Network.ISocketWrapper {
    public Stream InputStream { get; }
    public Stream OutputStream { get; }
    public EndPoint LocalEndPoint { get; }
    public EndPoint RemoteEndPoint { get; }
    public abstract virtual ISocketWrapper Accept();
    public abstract virtual void Connect(IPAddress remoteaddr, int port, string secret);
    public abstract virtual Stream get_InputStream();
    public abstract virtual Stream get_OutputStream();
    public abstract virtual void Listen(int backlog);
    public abstract virtual EndPoint get_LocalEndPoint();
    public abstract virtual EndPoint get_RemoteEndPoint();
}
internal static class Microsoft.Spark.Network.SocketFactory : object {
    public static ISocketWrapper CreateSocket();
}
[ExtensionAttribute]
internal static class Microsoft.Spark.PairRDDFunctions : object {
    [ExtensionAttribute]
public static IDictionary`2<TKey, TValue> CollectAsMap(RDD`1<Tuple`2<TKey, TValue>> self);
    [ExtensionAttribute]
public static RDD`1<TKey> Keys(RDD`1<Tuple`2<TKey, TValue>> self);
    [ExtensionAttribute]
public static RDD`1<TValue> Values(RDD`1<Tuple`2<TKey, TValue>> self);
}
internal class Microsoft.Spark.PipelinedRDD`1 : RDD`1<T> {
    private WorkerFunction _func;
    private bool _preservesPartitioning;
    private JvmObjectReference Microsoft.Spark.Interop.Ipc.IJvmObjectReferenceProvider.Reference { get; }
    internal PipelinedRDD`1(WorkerFunction func, bool preservesPartitioning, JvmObjectReference prevRddJvmObjRef, SparkContext sparkContext, SerializedMode prevSerializedMode);
    internal virtual RDD`1<U> MapPartitionsWithIndexInternal(ExecuteDelegate newFunc, bool preservesPartitioning);
    private sealed virtual override JvmObjectReference Microsoft.Spark.Interop.Ipc.IJvmObjectReferenceProvider.get_Reference();
    private bool IsPipelinable();
}
internal class Microsoft.Spark.RDD.Collector : object {
    [IteratorStateMachineAttribute("Microsoft.Spark.RDD.Collector/<Collect>d__0")]
public IEnumerable`1<object> Collect(Stream stream, SerializedMode serializedMode);
    internal static IDeserializer GetDeserializer(SerializedMode mode);
}
internal class Microsoft.Spark.RDD.WorkerFunction : object {
    [CompilerGeneratedAttribute]
private ExecuteDelegate <Func>k__BackingField;
    internal ExecuteDelegate Func { get; }
    public WorkerFunction(ExecuteDelegate func);
    [CompilerGeneratedAttribute]
internal ExecuteDelegate get_Func();
    internal static WorkerFunction Chain(WorkerFunction innerFunction, WorkerFunction outerFunction);
}
internal class Microsoft.Spark.RDD`1 : object {
    internal JvmObjectReference _jvmObject;
    internal JvmObjectReference _prevRddJvmObjRef;
    internal SparkContext _sparkContext;
    protected bool _isCached;
    protected bool _isCheckpointed;
    internal SerializedMode _serializedMode;
    internal SerializedMode _prevSerializedMode;
    private JvmObjectReference Microsoft.Spark.Interop.Ipc.IJvmObjectReferenceProvider.Reference { get; }
    internal RDD`1(JvmObjectReference jvmObject, SparkContext sparkContext, SerializedMode serializedMode);
    internal RDD`1(JvmObjectReference prevRddJvmObjRef, SparkContext sparkContext, SerializedMode serializedMode, SerializedMode prevSerializedMode);
    private sealed virtual override JvmObjectReference Microsoft.Spark.Interop.Ipc.IJvmObjectReferenceProvider.get_Reference();
    public RDD`1<T> Cache();
    public void Checkpoint();
    public RDD`1<U> Map(Func`2<T, U> func, bool preservesPartitioning);
    public RDD`1<U> FlatMap(Func`2<T, IEnumerable`1<U>> func, bool preservesPartitioning);
    public RDD`1<U> MapPartitions(Func`2<IEnumerable`1<T>, IEnumerable`1<U>> func, bool preservesPartitioning);
    public RDD`1<U> MapPartitionsWithIndex(Func`3<int, IEnumerable`1<T>, IEnumerable`1<U>> func, bool preservesPartitioning);
    public int GetNumPartitions();
    public RDD`1<T> Filter(Func`2<T, bool> func);
    public RDD`1<T> Sample(bool withReplacement, double fraction, Nullable`1<long> seed);
    [IteratorStateMachineAttribute("Microsoft.Spark.RDD`1/<Collect>d__20")]
public IEnumerable`1<T> Collect();
    internal virtual RDD`1<U> MapPartitionsWithIndexInternal(ExecuteDelegate func, bool preservesPartitioning);
    private ValueTuple`2<int, string> CollectAndServe();
    private JvmObjectReference GetJvmRef();
}
[AttributeUsageAttribute("32767")]
public class Microsoft.Spark.RemovedAttribute : VersionAttribute {
    public RemovedAttribute(string version);
}
internal class Microsoft.Spark.Services.ConfigurationService : object {
    public static string WorkerReadBufferSizeEnvVarName;
    public static string WorkerWriteBufferSizeEnvVarName;
    internal static string DefaultWorkerDirEnvVarName;
    internal static string WorkerVerDirEnvVarNameFormat;
    private static string DotnetBackendPortEnvVarName;
    private static int DotnetBackendDebugPort;
    private static string DotnetNumBackendThreadsEnvVarName;
    private static int DotnetNumBackendThreadsDefault;
    private static string s_procBaseFileName;
    private ILoggerService _logger;
    private string _workerPath;
    private string _workerDirEnvVarName;
    [CompilerGeneratedAttribute]
private static string <ProcFileName>k__BackingField;
    [CompilerGeneratedAttribute]
private static bool <IsDatabricks>k__BackingField;
    internal static string ProcFileName { get; }
    internal string WorkerDirEnvVarName { get; }
    public TimeSpan JvmThreadGCInterval { get; }
    internal static bool IsDatabricks { get; }
    private static ConfigurationService();
    [CompilerGeneratedAttribute]
internal static string get_ProcFileName();
    internal string get_WorkerDirEnvVarName();
    public sealed virtual TimeSpan get_JvmThreadGCInterval();
    [CompilerGeneratedAttribute]
internal static bool get_IsDatabricks();
    public sealed virtual int GetBackendPortNumber();
    public sealed virtual int GetNumBackendThreads();
    public sealed virtual string GetWorkerExePath();
    public sealed virtual bool IsRunningRepl();
}
internal class Microsoft.Spark.Services.ConsoleLoggerService : object {
    internal static ConsoleLoggerService s_instance;
    private Type _type;
    public bool IsDebugEnabled { get; }
    private ConsoleLoggerService(Type t);
    private static ConsoleLoggerService();
    public sealed virtual bool get_IsDebugEnabled();
    public sealed virtual ILoggerService GetLoggerInstance(Type type);
    public sealed virtual void LogDebug(string message);
    public sealed virtual void LogDebug(string messageFormat, Object[] messageParameters);
    public sealed virtual void LogInfo(string message);
    public sealed virtual void LogInfo(string messageFormat, Object[] messageParameters);
    public sealed virtual void LogWarn(string message);
    public sealed virtual void LogWarn(string messageFormat, Object[] messageParameters);
    public sealed virtual void LogFatal(string message);
    public sealed virtual void LogFatal(string messageFormat, Object[] messageParameters);
    public sealed virtual void LogError(string message);
    public sealed virtual void LogError(string messageFormat, Object[] messageParameters);
    public sealed virtual void LogException(Exception e);
    private void Log(string level, string message);
}
internal interface Microsoft.Spark.Services.IConfigurationService {
    public TimeSpan JvmThreadGCInterval { get; }
    public abstract virtual TimeSpan get_JvmThreadGCInterval();
    public abstract virtual int GetBackendPortNumber();
    public abstract virtual int GetNumBackendThreads();
    public abstract virtual string GetWorkerExePath();
    public abstract virtual bool IsRunningRepl();
}
internal interface Microsoft.Spark.Services.ILoggerService {
    public bool IsDebugEnabled { get; }
    public abstract virtual bool get_IsDebugEnabled();
    public abstract virtual ILoggerService GetLoggerInstance(Type type);
    public abstract virtual void LogDebug(string message);
    public abstract virtual void LogDebug(string messageFormat, Object[] messageParameters);
    public abstract virtual void LogInfo(string message);
    public abstract virtual void LogInfo(string messageFormat, Object[] messageParameters);
    public abstract virtual void LogWarn(string message);
    public abstract virtual void LogWarn(string messageFormat, Object[] messageParameters);
    public abstract virtual void LogFatal(string message);
    public abstract virtual void LogFatal(string messageFormat, Object[] messageParameters);
    public abstract virtual void LogError(string message);
    public abstract virtual void LogError(string messageFormat, Object[] messageParameters);
    public abstract virtual void LogException(Exception e);
}
internal class Microsoft.Spark.Services.LoggerServiceFactory : object {
    private static Lazy`1<ILoggerService> s_loggerService;
    private static LoggerServiceFactory();
    public static void SetLoggerService(ILoggerService loggerServiceOverride);
    public static ILoggerService GetLogger(Type type);
    private static ILoggerService GetDefaultLogger();
}
[AttributeUsageAttribute("32767")]
public class Microsoft.Spark.SinceAttribute : VersionAttribute {
    public SinceAttribute(string version);
}
public class Microsoft.Spark.SparkConf : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public SparkConf(bool loadDefaults);
    internal SparkConf(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public SparkConf SetMaster(string master);
    public SparkConf SetAppName(string appName);
    public SparkConf SetSparkHome(string sparkHome);
    public SparkConf Set(string key, string value);
    public int GetInt(string key, int defaultValue);
    public string Get(string key, string defaultValue);
    public IReadOnlyList`1<KeyValuePair`2<string, string>> GetAll();
}
public class Microsoft.Spark.SparkContext : object {
    private SparkConf _conf;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public int DefaultParallelism { get; }
    public SparkContext(SparkConf conf);
    public SparkContext(string master, string appName, SparkConf conf);
    public SparkContext(string master, string appName);
    public SparkContext(string master, string appName, string sparkHome);
    internal SparkContext(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public SparkConf GetConf();
    public static SparkContext GetOrCreate(SparkConf conf);
    public void SetLogLevel(string logLevel);
    public void Stop();
    public int get_DefaultParallelism();
    private static SparkConf GetUpdatedConf(string master, string appName, string sparkHome, SparkConf conf);
    public void SetJobDescription(string value);
    public void SetJobGroup(string groupId, string description, bool interruptOnCancel);
    public void ClearJobGroup();
    internal RDD`1<T> Parallelize(IEnumerable`1<T> seq, Nullable`1<int> numSlices);
    internal RDD`1<string> TextFile(string path, Nullable`1<int> minPartitions);
    public void AddFile(string path, bool recursive);
    public IEnumerable`1<string> ListFiles();
    [SinceAttribute("3.1.0")]
public void AddArchive(string path);
    [SinceAttribute("3.1.0")]
public IEnumerable`1<string> ListArchives();
    public void SetCheckpointDir(string directory);
    public string GetCheckpointDir();
    public Broadcast`1<T> Broadcast(T value);
    public Configuration HadoopConfiguration();
    private JvmObjectReference WrapAsJavaRDD(JvmObjectReference rdd);
    public string Version();
}
public static class Microsoft.Spark.SparkFiles : object {
    [CompilerGeneratedAttribute]
private static IJvmBridge <Jvm>k__BackingField;
    private static string s_sparkFilesClassName;
    [ThreadStaticAttribute]
private static string s_rootDirectory;
    [ThreadStaticAttribute]
private static bool s_isRunningOnWorker;
    private static IJvmBridge Jvm { get; }
    private static SparkFiles();
    [CompilerGeneratedAttribute]
private static IJvmBridge get_Jvm();
    public static string Get(string fileName);
    public static string GetRootDirectory();
    internal static void SetRootDirectory(string path);
}
internal static class Microsoft.Spark.Sql.ArrowArrayHelpers : object {
    private static HashSet`1<ArrowTypeId> s_twoBufferArrowTypes;
    private static HashSet`1<ArrowTypeId> s_threeBufferArrowTypes;
    private static ArrowArrayHelpers();
    public static DataFrameColumn CreateEmptyColumn();
    public static IArrowArray CreateEmptyArray(IArrowType arrowType);
    public static IArrowArray CreateEmptyArray();
    private static ArrayData BuildEmptyArrayDataFromArrayType();
    private static ArrayData BuildEmptyArrayDataFromArrowType(IArrowType arrowType);
}
public static class Microsoft.Spark.Sql.ArrowFunctions : object {
    public static Func`2<Column, Column> VectorUdf(Func`2<T, TResult> udf);
    public static Func`3<Column, Column, Column> VectorUdf(Func`3<T1, T2, TResult> udf);
    public static Func`4<Column, Column, Column, Column> VectorUdf(Func`4<T1, T2, T3, TResult> udf);
    public static Func`5<Column, Column, Column, Column, Column> VectorUdf(Func`5<T1, T2, T3, T4, TResult> udf);
    public static Func`6<Column, Column, Column, Column, Column, Column> VectorUdf(Func`6<T1, T2, T3, T4, T5, TResult> udf);
    public static Func`7<Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`7<T1, T2, T3, T4, T5, T6, TResult> udf);
    public static Func`8<Column, Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> udf);
    public static Func`9<Column, Column, Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> udf);
    public static Func`10<Column, Column, Column, Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> udf);
    public static Func`11<Column, Column, Column, Column, Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> udf);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowGroupedMapUdfWrapper : object {
    private Func`2<RecordBatch, RecordBatch> _func;
    internal ArrowGroupedMapUdfWrapper(Func`2<RecordBatch, RecordBatch> func);
    internal RecordBatch Execute(RecordBatch input);
}
internal class Microsoft.Spark.Sql.ArrowGroupedMapWorkerFunction : WorkerFunction {
    [CompilerGeneratedAttribute]
private ExecuteDelegate <Func>k__BackingField;
    internal ExecuteDelegate Func { get; }
    internal ArrowGroupedMapWorkerFunction(ExecuteDelegate func);
    [CompilerGeneratedAttribute]
internal ExecuteDelegate get_Func();
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`10 : object {
    private Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> _func;
    internal ArrowUdfWrapper`10(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`11 : object {
    private Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> _func;
    internal ArrowUdfWrapper`11(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`2 : object {
    private Func`2<T, TResult> _func;
    internal ArrowUdfWrapper`2(Func`2<T, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`3 : object {
    private Func`3<T1, T2, TResult> _func;
    internal ArrowUdfWrapper`3(Func`3<T1, T2, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`4 : object {
    private Func`4<T1, T2, T3, TResult> _func;
    internal ArrowUdfWrapper`4(Func`4<T1, T2, T3, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`5 : object {
    private Func`5<T1, T2, T3, T4, TResult> _func;
    internal ArrowUdfWrapper`5(Func`5<T1, T2, T3, T4, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`6 : object {
    private Func`6<T1, T2, T3, T4, T5, TResult> _func;
    internal ArrowUdfWrapper`6(Func`6<T1, T2, T3, T4, T5, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`7 : object {
    private Func`7<T1, T2, T3, T4, T5, T6, TResult> _func;
    internal ArrowUdfWrapper`7(Func`7<T1, T2, T3, T4, T5, T6, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`8 : object {
    private Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> _func;
    internal ArrowUdfWrapper`8(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ArrowUdfWrapper`9 : object {
    private Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> _func;
    internal ArrowUdfWrapper`9(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> func);
    internal IArrowArray Execute(ReadOnlyMemory`1<IArrowArray> input, Int32[] argOffsets);
}
internal class Microsoft.Spark.Sql.ArrowWorkerFunction : WorkerFunction {
    [CompilerGeneratedAttribute]
private ExecuteDelegate <Func>k__BackingField;
    internal ExecuteDelegate Func { get; }
    internal ArrowWorkerFunction(ExecuteDelegate func);
    [CompilerGeneratedAttribute]
internal ExecuteDelegate get_Func();
    internal static ArrowWorkerFunction Chain(ArrowWorkerFunction innerWorkerFunction, ArrowWorkerFunction outerWorkerFunction);
}
public static class Microsoft.Spark.Sql.Avro.Functions : object {
    [CompilerGeneratedAttribute]
private static IJvmBridge <Jvm>k__BackingField;
    private static Lazy`1<string> s_avroClassName;
    private static IJvmBridge Jvm { get; }
    private static Functions();
    [CompilerGeneratedAttribute]
private static IJvmBridge get_Jvm();
    [SinceAttribute("2.4.0")]
public static Column FromAvro(Column data, string jsonFormatSchema);
    [SinceAttribute("3.0.0")]
public static Column FromAvro(Column data, string jsonFormatSchema, Dictionary`2<string, string> options);
    [SinceAttribute("2.4.0")]
public static Column ToAvro(Column data);
    [SinceAttribute("3.0.0")]
public static Column ToAvro(Column data, string jsonFormatSchema);
}
public class Microsoft.Spark.Sql.Builder : object {
    private Dictionary`2<string, string> _options;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal Builder(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public Builder Master(string master);
    public Builder AppName(string appName);
    public Builder Config(string key, string value);
    public Builder Config(string key, bool value);
    public Builder Config(string key, double value);
    public Builder Config(string key, long value);
    public Builder Config(SparkConf conf);
    public Builder EnableHiveSupport();
    public SparkSession GetOrCreate();
}
public class Microsoft.Spark.Sql.Catalog.Catalog : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal Catalog(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public void CacheTable(string tableName);
    public void ClearCache();
    public DataFrame CreateTable(string tableName, string path);
    public DataFrame CreateTable(string tableName, string path, string source);
    public DataFrame CreateTable(string tableName, string source, IDictionary`2<string, string> options);
    [SinceAttribute("3.1.0")]
public DataFrame CreateTable(string tableName, string source, string description, IDictionary`2<string, string> options);
    public DataFrame CreateTable(string tableName, string source, StructType schema, IDictionary`2<string, string> options);
    [SinceAttribute("3.1.0")]
public DataFrame CreateTable(string tableName, string source, StructType schema, string description, IDictionary`2<string, string> options);
    public string CurrentDatabase();
    public bool DatabaseExists(string dbName);
    public bool DropGlobalTempView(string viewName);
    public bool DropTempView(string viewName);
    public bool FunctionExists(string functionName);
    public bool FunctionExists(string dbName, string functionName);
    public Database GetDatabase(string dbName);
    public Function GetFunction(string functionName);
    public Function GetFunction(string dbName, string functionName);
    public Table GetTable(string tableName);
    public Table GetTable(string dbName, string tableName);
    public bool IsCached(string tableName);
    public DataFrame ListColumns(string tableName);
    public DataFrame ListColumns(string dbName, string tableName);
    public DataFrame ListDatabases();
    public DataFrame ListFunctions();
    public DataFrame ListFunctions(string dbName);
    public DataFrame ListTables();
    public DataFrame ListTables(string dbName);
    public void RecoverPartitions(string tableName);
    public void RefreshByPath(string path);
    public void RefreshTable(string tableName);
    public void SetCurrentDatabase(string dbName);
    public bool TableExists(string tableName);
    public bool TableExists(string dbName, string tableName);
    public void UncacheTable(string tableName);
}
public class Microsoft.Spark.Sql.Catalog.Database : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public string Description { get; }
    public string LocationUri { get; }
    public string Name { get; }
    internal Database(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public string get_Description();
    public string get_LocationUri();
    public string get_Name();
}
public class Microsoft.Spark.Sql.Catalog.Function : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public string Database { get; }
    public string Description { get; }
    public bool IsTemporary { get; }
    public string Name { get; }
    public string ClassName { get; }
    internal Function(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public string get_Database();
    public string get_Description();
    public bool get_IsTemporary();
    public string get_Name();
    public string get_ClassName();
}
public class Microsoft.Spark.Sql.Catalog.Table : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public string Database { get; }
    public string Description { get; }
    public bool IsTemporary { get; }
    public string Name { get; }
    public string TableType { get; }
    internal Table(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public string get_Database();
    public string get_Description();
    public bool get_IsTemporary();
    public string get_Name();
    public string get_TableType();
}
public class Microsoft.Spark.Sql.Column : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal Column(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public static Column op_UnaryNegation(Column self);
    public static Column op_LogicalNot(Column self);
    public static Column op_Equality(Column lhs, object rhs);
    public Column EqualTo(object rhs);
    public static Column op_Inequality(Column lhs, object rhs);
    public Column NotEqual(object rhs);
    public static Column op_GreaterThan(Column lhs, object rhs);
    public Column Gt(object rhs);
    public static Column op_LessThan(Column lhs, object rhs);
    public Column Lt(object rhs);
    public static Column op_LessThanOrEqual(Column lhs, object rhs);
    public Column Leq(object rhs);
    public static Column op_GreaterThanOrEqual(Column lhs, object rhs);
    public Column Geq(object rhs);
    public Column EqNullSafe(object obj);
    public Column When(Column condition, object value);
    public Column Otherwise(object value);
    public Column Between(object lowerBound, object upperBound);
    public Column IsNaN();
    public Column IsNull();
    public Column IsNotNull();
    public static Column op_BitwiseOr(Column lhs, Column rhs);
    public Column Or(Column other);
    public static Column op_BitwiseAnd(Column lhs, Column rhs);
    public Column And(Column other);
    public static Column op_Addition(Column lhs, object rhs);
    public Column Plus(object rhs);
    public static Column op_Subtraction(Column lhs, object rhs);
    public Column Minus(object rhs);
    public static Column op_Multiply(Column lhs, object rhs);
    public Column Multiply(object rhs);
    public static Column op_Division(Column lhs, object rhs);
    public Column Divide(object rhs);
    public static Column op_Modulus(Column lhs, object rhs);
    public Column Mod(object rhs);
    public Column Like(string literal);
    public Column RLike(string literal);
    public Column GetItem(object key);
    [SinceAttribute("3.1.0")]
public Column WithField(string fieldName, Column column);
    [SinceAttribute("3.1.0")]
public Column DropFields(String[] fieldNames);
    public Column GetField(string fieldName);
    public Column SubStr(Column startPos, Column len);
    public Column SubStr(int startPos, int len);
    public Column Contains(object other);
    public Column StartsWith(Column other);
    public Column StartsWith(string literal);
    public Column EndsWith(Column other);
    public Column EndsWith(string literal);
    public Column Alias(string alias);
    public Column As(string alias);
    public Column As(IEnumerable`1<string> alias);
    public Column Apply(object extraction);
    public Column Name(string alias);
    public Column Cast(string to);
    public Column Desc();
    public Column DescNullsFirst();
    public Column DescNullsLast();
    public Column Asc();
    public Column AscNullsFirst();
    public Column AscNullsLast();
    public void Explain(bool extended);
    public Column BitwiseOR(object other);
    public Column BitwiseAND(object other);
    public Column BitwiseXOR(object other);
    public Column Over(WindowSpec window);
    public Column Over();
    public Column IsIn(String[] list);
    public Column IsIn(Int32[] list);
    public Column IsIn(Int64[] list);
    public Column IsIn(Boolean[] list);
    public Column IsIn(Int16[] list);
    public Column IsIn(Single[] list);
    public Column IsIn(Double[] list);
    public Column IsIn(Decimal[] list);
    internal JvmObjectReference Expr();
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    public virtual string ToString();
    private static Column ApplyFunction(Column column, string name);
    private Column ApplyMethod(string op);
    private Column ApplyMethod(string op, object other);
    private Column ApplyMethod(string op, object other1, object other2);
}
[DefaultMemberAttribute("Item")]
public class Microsoft.Spark.Sql.DataFrame : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public Column Item { get; }
    internal DataFrame(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public Column get_Item(string columnName);
    public DataFrame ToDF();
    public DataFrame ToDF(String[] colNames);
    public StructType Schema();
    public void PrintSchema();
    [SinceAttribute("3.0.0")]
public void PrintSchema(int level);
    public void Explain(bool extended);
    [SinceAttribute("3.0.0")]
public void Explain(string mode);
    public IEnumerable`1<Tuple`2<string, string>> DTypes();
    public IReadOnlyList`1<string> Columns();
    public bool IsLocal();
    [SinceAttribute("2.4.0")]
public bool IsEmpty();
    public bool IsStreaming();
    public DataFrame Checkpoint(bool eager);
    public DataFrame LocalCheckpoint(bool eager);
    public DataFrame WithWatermark(string eventTime, string delayThreshold);
    public void Show(int numRows, int truncate, bool vertical);
    public DataFrameNaFunctions Na();
    public DataFrameStatFunctions Stat();
    public DataFrame ToJSON();
    public DataFrame Join(DataFrame right);
    public DataFrame Join(DataFrame right, string usingColumn);
    public DataFrame Join(DataFrame right, IEnumerable`1<string> usingColumns, string joinType);
    public DataFrame Join(DataFrame right, Column joinExpr, string joinType);
    public DataFrame CrossJoin(DataFrame right);
    public DataFrame SortWithinPartitions(string column, String[] columns);
    public DataFrame SortWithinPartitions(Column[] columns);
    public DataFrame Sort(string column, String[] columns);
    public DataFrame Sort(Column[] columns);
    public DataFrame OrderBy(string column, String[] columns);
    public DataFrame OrderBy(Column[] columns);
    public DataFrame Hint(string name, Object[] parameters);
    public Column Col(string colName);
    public Column ColRegex(string colName);
    public DataFrame As(string alias);
    public DataFrame Alias(string alias);
    public DataFrame Select(Column[] columns);
    public DataFrame Select(string column, String[] columns);
    public DataFrame SelectExpr(String[] expressions);
    public DataFrame Filter(Column condition);
    public DataFrame Filter(string conditionExpr);
    public DataFrame Where(Column condition);
    public DataFrame Where(string conditionExpr);
    public RelationalGroupedDataset GroupBy(Column[] columns);
    public RelationalGroupedDataset GroupBy(string column, String[] columns);
    public RelationalGroupedDataset Rollup(Column[] columns);
    public RelationalGroupedDataset Rollup(string column, String[] columns);
    public RelationalGroupedDataset Cube(Column[] columns);
    public RelationalGroupedDataset Cube(string column, String[] columns);
    public DataFrame Agg(Column expr, Column[] exprs);
    [SinceAttribute("3.0.0")]
public DataFrame Observe(string name, Column expr, Column[] exprs);
    [SinceAttribute("3.0.0")]
public DataFrameWriterV2 WriteTo(string table);
    public DataFrame Limit(int n);
    public DataFrame Union(DataFrame other);
    public DataFrame UnionByName(DataFrame other);
    [SinceAttribute("3.1.0")]
public DataFrame UnionByName(DataFrame other, bool allowMissingColumns);
    public DataFrame Intersect(DataFrame other);
    [SinceAttribute("2.4.0")]
public DataFrame IntersectAll(DataFrame other);
    public DataFrame Except(DataFrame other);
    [SinceAttribute("2.4.0")]
public DataFrame ExceptAll(DataFrame other);
    public DataFrame Sample(double fraction, bool withReplacement, Nullable`1<long> seed);
    public DataFrame[] RandomSplit(Double[] weights, Nullable`1<long> seed);
    public DataFrame WithColumn(string colName, Column col);
    public DataFrame WithColumnRenamed(string existingName, string newName);
    public DataFrame Drop(String[] colNames);
    public DataFrame Drop(Column col);
    public DataFrame DropDuplicates();
    public DataFrame DropDuplicates(string col, String[] cols);
    public DataFrame Describe(String[] cols);
    public DataFrame Summary(String[] statistics);
    public IEnumerable`1<Row> Head(int n);
    public Row Head();
    public Row First();
    public DataFrame Transform(Func`2<DataFrame, DataFrame> func);
    public IEnumerable`1<Row> Take(int n);
    [SinceAttribute("3.0.0")]
public IEnumerable`1<Row> Tail(int n);
    public IEnumerable`1<Row> Collect();
    public IEnumerable`1<Row> ToLocalIterator();
    [IteratorStateMachineAttribute("Microsoft.Spark.Sql.DataFrame/<ToLocalIterator>d__84")]
[SinceAttribute("3.0.0")]
public IEnumerable`1<Row> ToLocalIterator(bool prefetchPartitions);
    public long Count();
    public DataFrame Repartition(int numPartitions);
    public DataFrame Repartition(int numPartitions, Column[] partitionExprs);
    public DataFrame Repartition(Column[] partitionExprs);
    public DataFrame RepartitionByRange(int numPartitions, Column[] partitionExprs);
    public DataFrame RepartitionByRange(Column[] partitionExprs);
    public DataFrame Coalesce(int numPartitions);
    public DataFrame Distinct();
    public DataFrame Persist();
    public DataFrame Persist(StorageLevel storageLevel);
    public DataFrame Cache();
    public StorageLevel StorageLevel();
    public DataFrame Unpersist(bool blocking);
    public void CreateTempView(string viewName);
    public void CreateOrReplaceTempView(string viewName);
    public void CreateGlobalTempView(string viewName);
    public void CreateOrReplaceGlobalTempView(string viewName);
    public DataFrameWriter Write();
    public DataStreamWriter WriteStream();
    public IEnumerable`1<string> InputFiles();
    [SinceAttribute("3.1.0")]
public bool SameSemantics(DataFrame other);
    [SinceAttribute("3.1.0")]
public int SemanticHash();
    [IteratorStateMachineAttribute("Microsoft.Spark.Sql.DataFrame/<GetRows>d__107")]
private IEnumerable`1<Row> GetRows(string funcName, Object[] args);
    private ValueTuple`3<int, string, JvmObjectReference> GetConnectionInfo(string funcName, Object[] args);
    private ValueTuple`3<int, string, JvmObjectReference> ParseConnectionInfo(object info, bool parseServer);
    private DataFrame WrapAsDataFrame(object obj);
    private Column WrapAsColumn(object obj);
    private RelationalGroupedDataset WrapAsGroupedDataset(object obj);
}
public static class Microsoft.Spark.Sql.DataFrameFunctions : object {
    public static Func`2<Column, Column> VectorUdf(Func`2<T, TResult> udf);
    public static Func`3<Column, Column, Column> VectorUdf(Func`3<T1, T2, TResult> udf);
    public static Func`4<Column, Column, Column, Column> VectorUdf(Func`4<T1, T2, T3, TResult> udf);
    public static Func`5<Column, Column, Column, Column, Column> VectorUdf(Func`5<T1, T2, T3, T4, TResult> udf);
    public static Func`6<Column, Column, Column, Column, Column, Column> VectorUdf(Func`6<T1, T2, T3, T4, T5, TResult> udf);
    public static Func`7<Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`7<T1, T2, T3, T4, T5, T6, TResult> udf);
    public static Func`8<Column, Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> udf);
    public static Func`9<Column, Column, Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> udf);
    public static Func`10<Column, Column, Column, Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> udf);
    public static Func`11<Column, Column, Column, Column, Column, Column, Column, Column, Column, Column, Column> VectorUdf(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> udf);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameGroupedMapUdfWrapper : object {
    private Func`2<DataFrame, DataFrame> _func;
    internal DataFrameGroupedMapUdfWrapper(Func`2<DataFrame, DataFrame> func);
    internal DataFrame Execute(DataFrame input);
}
internal class Microsoft.Spark.Sql.DataFrameGroupedMapWorkerFunction : WorkerFunction {
    [CompilerGeneratedAttribute]
private ExecuteDelegate <Func>k__BackingField;
    internal ExecuteDelegate Func { get; }
    internal DataFrameGroupedMapWorkerFunction(ExecuteDelegate func);
    [CompilerGeneratedAttribute]
internal ExecuteDelegate get_Func();
}
public class Microsoft.Spark.Sql.DataFrameNaFunctions : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal DataFrameNaFunctions(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public DataFrame Drop();
    public DataFrame Drop(string how);
    public DataFrame Drop(IEnumerable`1<string> columnNames);
    public DataFrame Drop(string how, IEnumerable`1<string> columnNames);
    public DataFrame Drop(int minNonNulls);
    public DataFrame Drop(int minNonNulls, IEnumerable`1<string> columnNames);
    public DataFrame Fill(long value);
    public DataFrame Fill(double value);
    public DataFrame Fill(string value);
    public DataFrame Fill(long value, IEnumerable`1<string> columnNames);
    public DataFrame Fill(double value, IEnumerable`1<string> columnNames);
    public DataFrame Fill(string value, IEnumerable`1<string> columnNames);
    public DataFrame Fill(bool value);
    public DataFrame Fill(bool value, IEnumerable`1<string> columnNames);
    public DataFrame Fill(IDictionary`2<string, int> valueMap);
    public DataFrame Fill(IDictionary`2<string, long> valueMap);
    public DataFrame Fill(IDictionary`2<string, double> valueMap);
    public DataFrame Fill(IDictionary`2<string, string> valueMap);
    public DataFrame Fill(IDictionary`2<string, bool> valueMap);
    public DataFrame Replace(string columnName, IDictionary`2<double, double> replacement);
    public DataFrame Replace(string columnName, IDictionary`2<bool, bool> replacement);
    public DataFrame Replace(string columnName, IDictionary`2<string, string> replacement);
    public DataFrame Replace(IEnumerable`1<string> columnNames, IDictionary`2<double, double> replacement);
    public DataFrame Replace(IEnumerable`1<string> columnNames, IDictionary`2<bool, bool> replacement);
    public DataFrame Replace(IEnumerable`1<string> columnNames, IDictionary`2<string, string> replacement);
    private DataFrame WrapAsDataFrame(object obj);
}
public class Microsoft.Spark.Sql.DataFrameReader : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal DataFrameReader(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public DataFrameReader Format(string source);
    public DataFrameReader Schema(StructType schema);
    public DataFrameReader Schema(string schemaString);
    public DataFrameReader Option(string key, string value);
    public DataFrameReader Option(string key, bool value);
    public DataFrameReader Option(string key, long value);
    public DataFrameReader Option(string key, double value);
    public DataFrameReader Options(Dictionary`2<string, string> options);
    public DataFrame Load();
    public DataFrame Load(string path);
    public DataFrame Load(String[] paths);
    public DataFrame Jdbc(string url, string table, Dictionary`2<string, string> properties);
    public DataFrame Jdbc(string url, string table, string columnName, long lowerBound, long upperBound, int numPartitions, Dictionary`2<string, string> properties);
    public DataFrame Jdbc(string url, string table, IEnumerable`1<string> predicates, Dictionary`2<string, string> properties);
    public DataFrame Json(String[] paths);
    public DataFrame Csv(String[] paths);
    public DataFrame Parquet(String[] paths);
    public DataFrame Orc(String[] paths);
    public DataFrame Table(string tableName);
    public DataFrame Text(String[] paths);
    private DataFrameReader OptionInternal(string key, object value);
    private DataFrame LoadSource(string source, String[] paths);
}
public class Microsoft.Spark.Sql.DataFrameStatFunctions : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal DataFrameStatFunctions(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public Double[] ApproxQuantile(string columnName, IEnumerable`1<double> probabilities, double relativeError);
    public double Cov(string colName1, string colName2);
    public double Corr(string colName1, string colName2, string method);
    public double Corr(string colName1, string colName2);
    public DataFrame Crosstab(string colName1, string colName2);
    public DataFrame FreqItems(IEnumerable`1<string> columnNames, double support);
    public DataFrame FreqItems(IEnumerable`1<string> columnNames);
    public DataFrame SampleBy(string columnName, IDictionary`2<T, double> fractions, long seed);
    [SinceAttribute("3.0.0")]
public DataFrame SampleBy(Column column, IDictionary`2<T, double> fractions, long seed);
    private DataFrame WrapAsDataFrame(object obj);
}
[ExtensionAttribute]
public static class Microsoft.Spark.Sql.DataFrameUdfRegistrationExtensions : object {
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`2<T, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`3<T1, T2, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`4<T1, T2, T3, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`5<T1, T2, T3, T4, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`6<T1, T2, T3, T4, T5, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`7<T1, T2, T3, T4, T5, T6, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> f);
    private static void RegisterVector(UdfRegistration udf, string name, Delegate func);
}
internal abstract class Microsoft.Spark.Sql.DataFrameUdfWrapper : object {
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`10 : DataFrameUdfWrapper {
    private Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> _func;
    internal DataFrameUdfWrapper`10(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`11 : DataFrameUdfWrapper {
    private Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> _func;
    internal DataFrameUdfWrapper`11(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`2 : DataFrameUdfWrapper {
    private Func`2<T, TResult> _func;
    internal DataFrameUdfWrapper`2(Func`2<T, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`3 : DataFrameUdfWrapper {
    private Func`3<T1, T2, TResult> _func;
    internal DataFrameUdfWrapper`3(Func`3<T1, T2, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`4 : DataFrameUdfWrapper {
    private Func`4<T1, T2, T3, TResult> _func;
    internal DataFrameUdfWrapper`4(Func`4<T1, T2, T3, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`5 : DataFrameUdfWrapper {
    private Func`5<T1, T2, T3, T4, TResult> _func;
    internal DataFrameUdfWrapper`5(Func`5<T1, T2, T3, T4, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`6 : DataFrameUdfWrapper {
    private Func`6<T1, T2, T3, T4, T5, TResult> _func;
    internal DataFrameUdfWrapper`6(Func`6<T1, T2, T3, T4, T5, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`7 : DataFrameUdfWrapper {
    private Func`7<T1, T2, T3, T4, T5, T6, TResult> _func;
    internal DataFrameUdfWrapper`7(Func`7<T1, T2, T3, T4, T5, T6, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`8 : DataFrameUdfWrapper {
    private Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> _func;
    internal DataFrameUdfWrapper`8(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.DataFrameUdfWrapper`9 : DataFrameUdfWrapper {
    private Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> _func;
    internal DataFrameUdfWrapper`9(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> func);
    internal DataFrameColumn Execute(ReadOnlyMemory`1<DataFrameColumn> input, Int32[] argOffsets);
}
internal class Microsoft.Spark.Sql.DataFrameWorkerFunction : WorkerFunction {
    [CompilerGeneratedAttribute]
private ExecuteDelegate <Func>k__BackingField;
    internal ExecuteDelegate Func { get; }
    internal DataFrameWorkerFunction(ExecuteDelegate func);
    [CompilerGeneratedAttribute]
internal ExecuteDelegate get_Func();
    internal static DataFrameWorkerFunction Chain(DataFrameWorkerFunction innerWorkerFunction, DataFrameWorkerFunction outerWorkerFunction);
}
public class Microsoft.Spark.Sql.DataFrameWriter : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal DataFrameWriter(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public DataFrameWriter Mode(SaveMode saveMode);
    public DataFrameWriter Mode(string saveMode);
    public DataFrameWriter Format(string source);
    public DataFrameWriter Option(string key, string value);
    public DataFrameWriter Option(string key, bool value);
    public DataFrameWriter Option(string key, long value);
    public DataFrameWriter Option(string key, double value);
    public DataFrameWriter Options(Dictionary`2<string, string> options);
    public DataFrameWriter PartitionBy(String[] colNames);
    public DataFrameWriter BucketBy(int numBuckets, string colName, String[] colNames);
    public DataFrameWriter SortBy(string colName, String[] colNames);
    public void Save(string path);
    public void Save();
    public void InsertInto(string tableName);
    public void SaveAsTable(string tableName);
    public void Jdbc(string url, string table, Dictionary`2<string, string> properties);
    public void Json(string path);
    public void Parquet(string path);
    public void Orc(string path);
    public void Text(string path);
    public void Csv(string path);
    private DataFrameWriter OptionInternal(string key, object value);
}
[SinceAttribute("3.0.0")]
public class Microsoft.Spark.Sql.DataFrameWriterV2 : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal DataFrameWriterV2(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public DataFrameWriterV2 Using(string provider);
    public DataFrameWriterV2 Option(string key, string value);
    public DataFrameWriterV2 Option(string key, bool value);
    public DataFrameWriterV2 Option(string key, long value);
    public DataFrameWriterV2 Option(string key, double value);
    public DataFrameWriterV2 Options(Dictionary`2<string, string> options);
    public DataFrameWriterV2 TableProperty(string property, string value);
    public DataFrameWriterV2 PartitionedBy(Column column, Column[] columns);
    public void Create();
    public void Replace();
    public void CreateOrReplace();
    public void Append();
    public void Overwrite(Column condition);
    public void OverwritePartitions();
}
internal class Microsoft.Spark.Sql.DatePickler : object {
    public sealed virtual void pickle(object o, Stream outs, Pickler currentPickler);
}
internal class Microsoft.Spark.Sql.Expressions.UserDefinedFunction : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal UserDefinedFunction(JvmObjectReference jvmObject);
    internal static UserDefinedFunction Create(string name, Byte[] command, PythonEvalType evalType, string returnType);
    internal static UserDefinedFunction Create(IJvmBridge jvm, string name, Byte[] command, PythonEvalType evalType, string returnType);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    internal Column Apply0();
    internal Column Apply1(Column col);
    internal Column Apply2(Column col1, Column col2);
    internal Column Apply3(Column col1, Column col2, Column col3);
    internal Column Apply4(Column col1, Column col2, Column col3, Column col4);
    internal Column Apply5(Column col1, Column col2, Column col3, Column col4, Column col5);
    internal Column Apply6(Column col1, Column col2, Column col3, Column col4, Column col5, Column col6);
    internal Column Apply7(Column col1, Column col2, Column col3, Column col4, Column col5, Column col6, Column col7);
    internal Column Apply8(Column col1, Column col2, Column col3, Column col4, Column col5, Column col6, Column col7, Column col8);
    internal Column Apply9(Column col1, Column col2, Column col3, Column col4, Column col5, Column col6, Column col7, Column col8, Column col9);
    internal Column Apply10(Column col1, Column col2, Column col3, Column col4, Column col5, Column col6, Column col7, Column col8, Column col9, Column col10);
    internal Column Apply(Column[] columns);
}
public static class Microsoft.Spark.Sql.Expressions.Window : object {
    [CompilerGeneratedAttribute]
private static IJvmBridge <Jvm>k__BackingField;
    private static string s_windowClassName;
    private static IJvmBridge Jvm { get; }
    public static long UnboundedPreceding { get; }
    public static long UnboundedFollowing { get; }
    public static long CurrentRow { get; }
    private static Window();
    [CompilerGeneratedAttribute]
private static IJvmBridge get_Jvm();
    public static long get_UnboundedPreceding();
    public static long get_UnboundedFollowing();
    public static long get_CurrentRow();
    public static WindowSpec PartitionBy(string colName, String[] colNames);
    public static WindowSpec PartitionBy(Column[] columns);
    public static WindowSpec OrderBy(string colName, String[] colNames);
    public static WindowSpec OrderBy(Column[] columns);
    public static WindowSpec RowsBetween(long start, long end);
    public static WindowSpec RangeBetween(long start, long end);
    [DeprecatedAttribute("2.4.0")]
[RemovedAttribute("3.0.0")]
public static WindowSpec RangeBetween(Column start, Column end);
    private static WindowSpec Apply(string methodName, object arg);
    private static WindowSpec Apply(string methodName, object arg1, object arg2);
}
public class Microsoft.Spark.Sql.Expressions.WindowSpec : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal WindowSpec(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public WindowSpec PartitionBy(string colName, String[] colNames);
    public WindowSpec PartitionBy(Column[] columns);
    public WindowSpec OrderBy(string colName, String[] colNames);
    public WindowSpec OrderBy(Column[] columns);
    public WindowSpec RowsBetween(long start, long end);
    public WindowSpec RangeBetween(long start, long end);
    [DeprecatedAttribute("2.4.0")]
[RemovedAttribute("3.0.0")]
public WindowSpec RangeBetween(Column start, Column end);
    private WindowSpec WrapAsWindowSpec(object obj);
}
internal class Microsoft.Spark.Sql.ForeachWriterWrapper : object {
    private IForeachWriter _foreachWriter;
    internal ForeachWriterWrapper(IForeachWriter foreachWriter);
    internal IEnumerable`1<object> Process(int partitionId, IEnumerable`1<Row> rows);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.ForeachWriterWrapperUdfWrapper : object {
    private Func`3<int, IEnumerable`1<Row>, IEnumerable`1<object>> _func;
    internal ForeachWriterWrapperUdfWrapper(Func`3<int, IEnumerable`1<Row>, IEnumerable`1<object>> func);
    internal IEnumerable`1<object> Execute(int pid, IEnumerable`1<object> input);
}
public static class Microsoft.Spark.Sql.Functions : object {
    [CompilerGeneratedAttribute]
private static IJvmBridge <Jvm>k__BackingField;
    private static string s_functionsClassName;
    private static IJvmBridge Jvm { get; }
    private static Functions();
    [CompilerGeneratedAttribute]
private static IJvmBridge get_Jvm();
    public static Column Column(string columnName);
    public static Column Col(string columnName);
    public static Column Lit(object literal);
    public static Column Asc(string columnName);
    public static Column AscNullsFirst(string columnName);
    public static Column AscNullsLast(string columnName);
    public static Column Desc(string columnName);
    public static Column DescNullsFirst(string columnName);
    public static Column DescNullsLast(string columnName);
    public static Column ApproxCountDistinct(Column column);
    public static Column ApproxCountDistinct(string columnName);
    public static Column ApproxCountDistinct(Column column, double rsd);
    public static Column ApproxCountDistinct(string columnName, double rsd);
    public static Column Avg(Column column);
    public static Column Avg(string columnName);
    public static Column CollectList(Column column);
    public static Column CollectList(string columnName);
    public static Column CollectSet(Column column);
    public static Column CollectSet(string columnName);
    public static Column Corr(Column column1, Column column2);
    public static Column Corr(string columnName1, string columnName2);
    public static Column Count(Column column);
    public static Column Count(string columnName);
    public static Column CountDistinct(Column column, Column[] columns);
    public static Column CountDistinct(string columnName, String[] columnNames);
    [SinceAttribute("3.2.0")]
public static Column Count_Distinct(Column column, Column[] columns);
    public static Column CovarPop(Column column1, Column column2);
    public static Column CovarPop(string columnName1, string columnName2);
    public static Column CovarSamp(Column column1, Column column2);
    public static Column CovarSamp(string columnName1, string columnName2);
    public static Column First(Column column, bool ignoreNulls);
    public static Column First(string columnName, bool ignoreNulls);
    public static Column Grouping(Column column);
    public static Column Grouping(string columnName);
    public static Column GroupingId(Column[] columns);
    public static Column GroupingId(string columnName, String[] columnNames);
    public static Column Kurtosis(Column column);
    public static Column Kurtosis(string columnName);
    public static Column Last(Column column, bool ignoreNulls);
    public static Column Last(string columnName, bool ignoreNulls);
    public static Column Max(Column column);
    public static Column Max(string columnName);
    public static Column Mean(Column column);
    public static Column Mean(string columnName);
    public static Column Min(Column column);
    public static Column Min(string columnName);
    [SinceAttribute("3.1.0")]
public static Column PercentileApprox(Column column, Column percentage, Column accuracy);
    [SinceAttribute("3.2.0")]
public static Column Product(Column column);
    public static Column Skewness(Column column);
    public static Column Skewness(string columnName);
    public static Column Stddev(Column column);
    public static Column Stddev(string columnName);
    public static Column StddevSamp(Column column);
    public static Column StddevSamp(string columnName);
    public static Column StddevPop(Column column);
    public static Column StddevPop(string columnName);
    public static Column Sum(Column column);
    public static Column Sum(string columnName);
    [DeprecatedAttribute("3.2.0")]
public static Column SumDistinct(Column column);
    [DeprecatedAttribute("3.2.0")]
public static Column SumDistinct(string columnName);
    [SinceAttribute("3.2.0")]
public static Column Sum_Distinct(Column column);
    public static Column Variance(Column column);
    public static Column Variance(string columnName);
    public static Column VarSamp(Column column);
    public static Column VarSamp(string columnName);
    public static Column VarPop(Column column);
    public static Column VarPop(string columnName);
    [DeprecatedAttribute("2.4.0")]
[RemovedAttribute("3.0.0")]
public static Column UnboundedPreceding();
    [DeprecatedAttribute("2.4.0")]
[RemovedAttribute("3.0.0")]
public static Column UnboundedFollowing();
    [DeprecatedAttribute("2.4.0")]
[RemovedAttribute("3.0.0")]
public static Column CurrentRow();
    public static Column CumeDist();
    public static Column DenseRank();
    public static Column Lag(Column column, int offset, object defaultValue);
    public static Column Lag(string columnName, int offset, object defaultValue);
    [SinceAttribute("3.2.0")]
public static Column Lag(Column column, int offset, object defaultValue, bool ignoreNulls);
    public static Column Lead(Column column, int offset, object defaultValue);
    public static Column Lead(string columnName, int offset, object defaultValue);
    [SinceAttribute("3.2.0")]
public static Column Lead(Column column, int offset, object defaultValue, bool ignoreNulls);
    [SinceAttribute("3.1.0")]
public static Column NthValue(Column column, int offset, bool ignoreNulls);
    public static Column Ntile(int n);
    public static Column PercentRank();
    public static Column Rank();
    public static Column RowNumber();
    public static Column Abs(Column column);
    public static Column Array(Column[] columns);
    public static Column Array(string columnName, String[] columnNames);
    public static Column Map(Column[] columns);
    [SinceAttribute("2.4.0")]
public static Column MapFromArrays(Column key, Column values);
    public static DataFrame Broadcast(DataFrame df);
    public static Column Coalesce(Column[] columns);
    public static Column InputFileName();
    public static Column IsNaN(Column column);
    public static Column IsNull(Column column);
    public static Column MonotonicallyIncreasingId();
    public static Column NaNvl(Column column1, Column column2);
    public static Column Negate(Column column);
    public static Column Not(Column column);
    public static Column Rand(long seed);
    public static Column Rand();
    public static Column Randn(long seed);
    public static Column Randn();
    public static Column SparkPartitionId();
    public static Column Sqrt(Column column);
    public static Column Sqrt(string columnName);
    public static Column Struct(Column[] columns);
    public static Column Struct(string columnName, String[] columnNames);
    public static Column When(Column condition, object value);
    [DeprecatedAttribute("3.2.0")]
public static Column BitwiseNOT(Column column);
    [SinceAttribute("3.2.0")]
public static Column Bitwise_Not(Column column);
    public static Column Expr(string expr);
    public static Column Acos(Column column);
    public static Column Acos(string columnName);
    [SinceAttribute("3.1.0")]
public static Column Acosh(Column column);
    [SinceAttribute("3.1.0")]
public static Column Acosh(string columnName);
    public static Column Asin(Column column);
    public static Column Asin(string columnName);
    [SinceAttribute("3.1.0")]
public static Column Asinh(Column column);
    [SinceAttribute("3.1.0")]
public static Column Asinh(string columnName);
    public static Column Atan(Column column);
    public static Column Atan(string columnName);
    public static Column Atan2(Column y, Column x);
    public static Column Atan2(Column y, string xName);
    public static Column Atan2(string yName, Column x);
    public static Column Atan2(string yName, string xName);
    public static Column Atan2(Column y, double xValue);
    public static Column Atan2(string yName, double xValue);
    public static Column Atan2(double yValue, Column x);
    public static Column Atan2(double yValue, string xName);
    [SinceAttribute("3.1.0")]
public static Column Atanh(Column column);
    [SinceAttribute("3.1.0")]
public static Column Atanh(string columnName);
    public static Column Bin(Column column);
    public static Column Bin(string columnName);
    public static Column Cbrt(Column column);
    public static Column Cbrt(string columnName);
    public static Column Ceil(Column column);
    public static Column Ceil(string columnName);
    public static Column Conv(Column column, int fromBase, int toBase);
    public static Column Cos(Column column);
    public static Column Cos(string columnName);
    public static Column Cosh(Column column);
    public static Column Cosh(string columnName);
    public static Column Exp(Column column);
    public static Column Exp(string columnName);
    public static Column Expm1(Column column);
    public static Column Expm1(string columnName);
    public static Column Factorial(Column column);
    public static Column Floor(Column column);
    public static Column Floor(string columnName);
    public static Column Greatest(Column[] columns);
    public static Column Greatest(string columnName, String[] columnNames);
    public static Column Hex(Column column);
    public static Column Unhex(Column column);
    public static Column Hypot(Column left, Column right);
    public static Column Hypot(Column left, string rightName);
    public static Column Hypot(string leftName, Column right);
    public static Column Hypot(string leftName, string rightName);
    public static Column Hypot(Column left, double right);
    public static Column Hypot(string leftName, double right);
    public static Column Hypot(double left, Column right);
    public static Column Hypot(double left, string rightName);
    public static Column Least(Column[] columns);
    public static Column Least(string columnName, String[] columnNames);
    public static Column Log(Column column);
    public static Column Log(string columnName);
    public static Column Log(double logBase, Column column);
    public static Column Log(double logBase, string columnName);
    public static Column Log10(Column column);
    public static Column Log10(string columnName);
    public static Column Log1p(Column column);
    public static Column Log1p(string columnName);
    public static Column Log2(Column column);
    public static Column Log2(string columnName);
    public static Column Pow(Column left, Column right);
    public static Column Pow(Column left, string rightName);
    public static Column Pow(string leftName, Column right);
    public static Column Pow(string leftName, string rightName);
    public static Column Pow(Column left, double right);
    public static Column Pow(string leftName, double right);
    public static Column Pow(double left, Column right);
    public static Column Pow(double left, string rightName);
    public static Column Pmod(Column left, Column right);
    public static Column Rint(Column column);
    public static Column Rint(string columnName);
    public static Column Round(Column column);
    public static Column Round(Column column, int scale);
    public static Column Bround(Column column);
    public static Column Bround(Column column, int scale);
    [DeprecatedAttribute("3.2.0")]
public static Column ShiftLeft(Column column, int numBits);
    [SinceAttribute("3.2.0")]
public static Column Shiftleft(Column column, int numBits);
    [DeprecatedAttribute("3.2.0")]
public static Column ShiftRight(Column column, int numBits);
    [SinceAttribute("3.2.0")]
public static Column Shiftright(Column column, int numBits);
    [DeprecatedAttribute("3.2.0")]
public static Column ShiftRightUnsigned(Column column, int numBits);
    [SinceAttribute("3.2.0")]
public static Column Shiftrightunsigned(Column column, int numBits);
    public static Column Signum(Column column);
    public static Column Signum(string columnName);
    public static Column Sin(Column column);
    public static Column Sin(string columnName);
    public static Column Sinh(Column column);
    public static Column Sinh(string columnName);
    public static Column Tan(Column column);
    public static Column Tan(string columnName);
    public static Column Tanh(Column column);
    public static Column Tanh(string columnName);
    public static Column Degrees(Column column);
    public static Column Degrees(string columnName);
    public static Column Radians(Column column);
    public static Column Radians(string columnName);
    public static Column Md5(Column column);
    public static Column Sha1(Column column);
    public static Column Sha2(Column column, int numBits);
    public static Column Crc32(Column column);
    public static Column Hash(Column[] columns);
    [SinceAttribute("3.0.0")]
public static Column XXHash64(Column[] columns);
    [SinceAttribute("3.1.0")]
public static Column AssertTrue(Column column);
    [SinceAttribute("3.1.0")]
public static Column AssertTrue(Column column, Column errMsg);
    [SinceAttribute("3.1.0")]
public static Column RaiseError(Column errMsg);
    public static Column Ascii(Column column);
    public static Column Base64(Column column);
    public static Column ConcatWs(string sep, Column[] columns);
    public static Column Decode(Column column, string charset);
    public static Column Encode(Column column, string charset);
    public static Column FormatNumber(Column column, int d);
    public static Column FormatString(string format, Column[] columns);
    public static Column InitCap(Column column);
    public static Column Instr(Column column, string substring);
    public static Column Length(Column column);
    public static Column Lower(Column column);
    public static Column Levenshtein(Column left, Column right);
    public static Column Locate(string substring, Column column);
    public static Column Locate(string substring, Column column, int pos);
    public static Column Lpad(Column column, int len, string pad);
    public static Column Ltrim(Column column);
    public static Column Ltrim(Column column, string trimString);
    public static Column RegexpExtract(Column column, string exp, int groupIdx);
    public static Column RegexpReplace(Column column, string pattern, string replacement);
    public static Column RegexpReplace(Column column, Column pattern, Column replacement);
    public static Column Unbase64(Column column);
    public static Column Rpad(Column column, int len, string pad);
    public static Column Repeat(Column column, int n);
    public static Column Rtrim(Column column);
    public static Column Rtrim(Column column, string trimString);
    public static Column Soundex(Column column);
    public static Column Split(Column column, string pattern);
    [SinceAttribute("3.0.0")]
public static Column Split(Column column, string pattern, int limit);
    public static Column Substring(Column column, int pos, int len);
    public static Column SubstringIndex(Column column, string delimiter, int count);
    [SinceAttribute("3.0.0")]
public static Column Overlay(Column src, Column replace, Column pos, Column len);
    [SinceAttribute("3.0.0")]
public static Column Overlay(Column src, Column replace, Column pos);
    [SinceAttribute("3.2.0")]
public static Column Sentences(Column str, Column language, Column country);
    [SinceAttribute("3.2.0")]
public static Column Sentences(Column str);
    public static Column Translate(Column column, string matchingString, string replaceString);
    public static Column Trim(Column column);
    public static Column Trim(Column column, string trimString);
    public static Column Upper(Column column);
    public static Column AddMonths(Column startDate, int numMonths);
    [SinceAttribute("3.0.0")]
public static Column AddMonths(Column startDate, Column numMonths);
    public static Column CurrentDate();
    public static Column CurrentTimestamp();
    public static Column DateFormat(Column dateExpr, string format);
    public static Column DateAdd(Column start, int days);
    [SinceAttribute("3.0.0")]
public static Column DateAdd(Column start, Column days);
    public static Column DateSub(Column start, int days);
    [SinceAttribute("3.0.0")]
public static Column DateSub(Column start, Column days);
    public static Column DateDiff(Column end, Column start);
    public static Column Year(Column column);
    public static Column Quarter(Column column);
    public static Column Month(Column column);
    public static Column DayOfWeek(Column column);
    public static Column DayOfMonth(Column column);
    public static Column DayOfYear(Column column);
    public static Column Hour(Column column);
    public static Column LastDay(Column column);
    public static Column Minute(Column column);
    public static Column MonthsBetween(Column end, Column start);
    [SinceAttribute("2.4.0")]
public static Column MonthsBetween(Column end, Column start, bool roundOff);
    public static Column NextDay(Column date, string dayOfWeek);
    [SinceAttribute("3.2.0")]
public static Column NextDay(Column date, Column dayOfWeek);
    public static Column Second(Column column);
    public static Column WeekOfYear(Column column);
    public static Column FromUnixTime(Column column);
    public static Column FromUnixTime(Column column, string format);
    public static Column UnixTimestamp();
    public static Column UnixTimestamp(Column column);
    public static Column UnixTimestamp(Column column, string format);
    public static Column ToTimestamp(Column column);
    public static Column ToTimestamp(Column column, string format);
    public static Column ToDate(Column column);
    public static Column ToDate(Column column, string format);
    public static Column Trunc(Column column, string format);
    public static Column DateTrunc(string format, Column column);
    [DeprecatedAttribute("3.0.0")]
public static Column FromUtcTimestamp(Column column, string tz);
    [SinceAttribute("2.4.0")]
[DeprecatedAttribute("3.0.0")]
public static Column FromUtcTimestamp(Column column, Column tz);
    [DeprecatedAttribute("3.0.0")]
public static Column ToUtcTimestamp(Column column, string tz);
    [SinceAttribute("2.4.0")]
[DeprecatedAttribute("3.0.0")]
public static Column ToUtcTimestamp(Column column, Column tz);
    public static Column Window(Column column, string windowDuration, string slideDuration, string startTime);
    public static Column Window(Column column, string windowDuration, string slideDuration);
    public static Column Window(Column column, string windowDuration);
    [SinceAttribute("3.2.0")]
public static Column Session_Window(Column timeColumn, string gapDuration);
    [SinceAttribute("3.2.0")]
public static Column Session_Window(Column timeColumn, Column gapDuration);
    [SinceAttribute("3.1.0")]
public static Column TimestampSeconds(Column column);
    public static Column ArrayContains(Column column, object value);
    [SinceAttribute("2.4.0")]
public static Column ArraysOverlap(Column a1, Column a2);
    [SinceAttribute("2.4.0")]
public static Column Slice(Column column, int start, int length);
    [SinceAttribute("3.1.0")]
public static Column Slice(Column column, Column start, Column length);
    [SinceAttribute("2.4.0")]
public static Column ArrayJoin(Column column, string delimiter, string nullReplacement);
    [SinceAttribute("2.4.0")]
public static Column ArrayJoin(Column column, string delimiter);
    public static Column Concat(Column[] columns);
    [SinceAttribute("2.4.0")]
public static Column ArrayPosition(Column column, object value);
    [SinceAttribute("2.4.0")]
public static Column ElementAt(Column column, object value);
    [SinceAttribute("2.4.0")]
public static Column ArraySort(Column column);
    [SinceAttribute("2.4.0")]
public static Column ArrayRemove(Column column, object element);
    [SinceAttribute("2.4.0")]
public static Column ArrayDistinct(Column column);
    [SinceAttribute("2.4.0")]
public static Column ArrayIntersect(Column col1, Column col2);
    [SinceAttribute("2.4.0")]
public static Column ArrayUnion(Column col1, Column col2);
    [SinceAttribute("2.4.0")]
public static Column ArrayExcept(Column col1, Column col2);
    public static Column Explode(Column column);
    public static Column ExplodeOuter(Column column);
    public static Column PosExplode(Column column);
    public static Column PosExplodeOuter(Column column);
    public static Column GetJsonObject(Column column, string path);
    public static Column JsonTuple(Column column, String[] fields);
    public static Column FromJson(Column column, string schema, Dictionary`2<string, string> options);
    [SinceAttribute("2.4.0")]
public static Column FromJson(Column column, Column schema, Dictionary`2<string, string> options);
    [SinceAttribute("2.4.0")]
public static Column SchemaOfJson(string json);
    [SinceAttribute("2.4.0")]
public static Column SchemaOfJson(Column json);
    [SinceAttribute("3.0.0")]
public static Column SchemaOfJson(Column json, Dictionary`2<string, string> options);
    public static Column ToJson(Column column, Dictionary`2<string, string> options);
    public static Column Size(Column column);
    public static Column SortArray(Column column, bool asc);
    [SinceAttribute("2.4.0")]
public static Column ArrayMin(Column column);
    [SinceAttribute("2.4.0")]
public static Column ArrayMax(Column column);
    [SinceAttribute("2.4.0")]
public static Column Shuffle(Column column);
    public static Column Reverse(Column column);
    [SinceAttribute("2.4.0")]
public static Column Flatten(Column column);
    [SinceAttribute("2.4.0")]
public static Column Sequence(Column start, Column stop, Column step);
    [SinceAttribute("2.4.0")]
public static Column Sequence(Column start, Column stop);
    [SinceAttribute("2.4.0")]
public static Column ArrayRepeat(Column left, Column right);
    [SinceAttribute("2.4.0")]
public static Column ArrayRepeat(Column left, int count);
    public static Column MapKeys(Column column);
    public static Column MapValues(Column column);
    [SinceAttribute("3.0.0")]
public static Column MapEntries(Column column);
    [SinceAttribute("2.4.0")]
public static Column MapFromEntries(Column column);
    [SinceAttribute("2.4.0")]
public static Column ArraysZip(Column[] columns);
    [SinceAttribute("2.4.0")]
public static Column MapConcat(Column[] columns);
    [SinceAttribute("3.0.0")]
public static Column FromCsv(Column column, StructType schema, Dictionary`2<string, string> options);
    [SinceAttribute("3.0.0")]
public static Column FromCsv(Column column, Column schema, Dictionary`2<string, string> options);
    [SinceAttribute("3.0.0")]
public static Column SchemaOfCsv(string csv);
    [SinceAttribute("3.0.0")]
public static Column SchemaOfCsv(Column csv);
    [SinceAttribute("3.0.0")]
public static Column SchemaOfCsv(Column csv, Dictionary`2<string, string> options);
    [SinceAttribute("3.0.0")]
public static Column ToCsv(Column column);
    [SinceAttribute("3.0.0")]
public static Column ToCsv(Column column, Dictionary`2<string, string> options);
    [SinceAttribute("3.0.0")]
public static Column Years(Column column);
    [SinceAttribute("3.0.0")]
public static Column Months(Column column);
    [SinceAttribute("3.0.0")]
public static Column Days(Column column);
    [SinceAttribute("3.0.0")]
public static Column Hours(Column column);
    [SinceAttribute("3.0.0")]
public static Column Bucket(Column numBuckets, Column column);
    [SinceAttribute("3.0.0")]
public static Column Bucket(int numBuckets, Column column);
    public static Func`1<Column> Udf(Func`1<TResult> udf);
    public static Func`2<Column, Column> Udf(Func`2<T, TResult> udf);
    public static Func`3<Column, Column, Column> Udf(Func`3<T1, T2, TResult> udf);
    public static Func`4<Column, Column, Column, Column> Udf(Func`4<T1, T2, T3, TResult> udf);
    public static Func`5<Column, Column, Column, Column, Column> Udf(Func`5<T1, T2, T3, T4, TResult> udf);
    public static Func`6<Column, Column, Column, Column, Column, Column> Udf(Func`6<T1, T2, T3, T4, T5, TResult> udf);
    public static Func`7<Column, Column, Column, Column, Column, Column, Column> Udf(Func`7<T1, T2, T3, T4, T5, T6, TResult> udf);
    public static Func`8<Column, Column, Column, Column, Column, Column, Column, Column> Udf(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> udf);
    public static Func`9<Column, Column, Column, Column, Column, Column, Column, Column, Column> Udf(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> udf);
    public static Func`10<Column, Column, Column, Column, Column, Column, Column, Column, Column, Column> Udf(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> udf);
    public static Func`11<Column, Column, Column, Column, Column, Column, Column, Column, Column, Column, Column> Udf(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> udf);
    public static Func`1<Column> Udf(Func`1<Row> udf, StructType returnType);
    public static Func`2<Column, Column> Udf(Func`2<T, Row> udf, StructType returnType);
    public static Func`3<Column, Column, Column> Udf(Func`3<T1, T2, Row> udf, StructType returnType);
    public static Func`4<Column, Column, Column, Column> Udf(Func`4<T1, T2, T3, Row> udf, StructType returnType);
    public static Func`5<Column, Column, Column, Column, Column> Udf(Func`5<T1, T2, T3, T4, Row> udf, StructType returnType);
    public static Func`6<Column, Column, Column, Column, Column, Column> Udf(Func`6<T1, T2, T3, T4, T5, Row> udf, StructType returnType);
    public static Func`7<Column, Column, Column, Column, Column, Column, Column> Udf(Func`7<T1, T2, T3, T4, T5, T6, Row> udf, StructType returnType);
    public static Func`8<Column, Column, Column, Column, Column, Column, Column, Column> Udf(Func`8<T1, T2, T3, T4, T5, T6, T7, Row> udf, StructType returnType);
    public static Func`9<Column, Column, Column, Column, Column, Column, Column, Column, Column> Udf(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, Row> udf, StructType returnType);
    public static Func`10<Column, Column, Column, Column, Column, Column, Column, Column, Column, Column> Udf(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, Row> udf, StructType returnType);
    public static Func`11<Column, Column, Column, Column, Column, Column, Column, Column, Column, Column, Column> Udf(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, Row> udf, StructType returnType);
    [DeprecatedAttribute("3.2.0")]
public static Column CallUDF(string udfName, Column[] columns);
    [SinceAttribute("3.2.0")]
public static Column Call_UDF(string udfName, Column[] columns);
    private static UserDefinedFunction CreateUdf(string name, Delegate execute);
    private static UserDefinedFunction CreateUdf(string name, Delegate execute, StructType returnType);
    internal static UserDefinedFunction CreateVectorUdf(string name, Delegate execute);
    private static UserDefinedFunction CreateUdf(string name, Delegate execute, PythonEvalType evalType);
    private static UserDefinedFunction CreateUdf(string name, Delegate execute, PythonEvalType evalType, StructType returnType);
    private static UserDefinedFunction CreateUdf(string name, Delegate execute, PythonEvalType evalType, string returnType);
    private static Column ApplyFunction(string funcName);
    private static Column ApplyFunction(string funcName, object arg);
    private static Column ApplyFunction(string funcName, object arg1, object arg2);
    private static Column ApplyFunction(string funcName, Object[] args);
}
[DefaultMemberAttribute("Item")]
public class Microsoft.Spark.Sql.GenericRow : object {
    [CompilerGeneratedAttribute]
private Object[] <Values>k__BackingField;
    public Object[] Values { get; }
    public object Item { get; }
    public GenericRow(Object[] values);
    [CompilerGeneratedAttribute]
public Object[] get_Values();
    public int Size();
    public object get_Item(int index);
    public object Get(int index);
    public virtual string ToString();
    public T GetAs(int index);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
}
internal class Microsoft.Spark.Sql.GenericRowPickler : object {
    public sealed virtual void pickle(object o, Stream outs, Pickler currentPickler);
}
public interface Microsoft.Spark.Sql.IForeachWriter {
    public abstract virtual bool Open(long partitionId, long epochId);
    public abstract virtual void Process(Row row);
    public abstract virtual void Close(Exception errorOrNull);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`1 : object {
    private Func`1<TResult> _func;
    internal PicklingUdfWrapper`1(Func`1<TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`10 : object {
    private Nullable`1[] _sameT;
    private Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> _func;
    internal PicklingUdfWrapper`10(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`11 : object {
    private Nullable`1[] _sameT;
    private Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> _func;
    internal PicklingUdfWrapper`11(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`2 : object {
    private Nullable`1<bool> _sameT;
    private Func`2<T, TResult> _func;
    internal PicklingUdfWrapper`2(Func`2<T, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`3 : object {
    private Nullable`1[] _sameT;
    private Func`3<T1, T2, TResult> _func;
    internal PicklingUdfWrapper`3(Func`3<T1, T2, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`4 : object {
    private Nullable`1[] _sameT;
    private Func`4<T1, T2, T3, TResult> _func;
    internal PicklingUdfWrapper`4(Func`4<T1, T2, T3, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`5 : object {
    private Nullable`1[] _sameT;
    private Func`5<T1, T2, T3, T4, TResult> _func;
    internal PicklingUdfWrapper`5(Func`5<T1, T2, T3, T4, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`6 : object {
    private Nullable`1[] _sameT;
    private Func`6<T1, T2, T3, T4, T5, TResult> _func;
    internal PicklingUdfWrapper`6(Func`6<T1, T2, T3, T4, T5, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`7 : object {
    private Nullable`1[] _sameT;
    private Func`7<T1, T2, T3, T4, T5, T6, TResult> _func;
    internal PicklingUdfWrapper`7(Func`7<T1, T2, T3, T4, T5, T6, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`8 : object {
    private Nullable`1[] _sameT;
    private Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> _func;
    internal PicklingUdfWrapper`8(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
[UdfWrapperAttribute]
internal class Microsoft.Spark.Sql.PicklingUdfWrapper`9 : object {
    private Nullable`1[] _sameT;
    private Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> _func;
    internal PicklingUdfWrapper`9(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> func);
    internal object Execute(int splitIndex, Object[] input, Int32[] argOffsets);
}
internal class Microsoft.Spark.Sql.PicklingWorkerFunction : WorkerFunction {
    [CompilerGeneratedAttribute]
private ExecuteDelegate <Func>k__BackingField;
    internal ExecuteDelegate Func { get; }
    internal PicklingWorkerFunction(ExecuteDelegate func);
    [CompilerGeneratedAttribute]
internal ExecuteDelegate get_Func();
    internal static PicklingWorkerFunction Chain(PicklingWorkerFunction innerWorkerFunction, PicklingWorkerFunction outerWorkerFunction);
}
public class Microsoft.Spark.Sql.RelationalGroupedDataset : object {
    private DataFrame _dataFrame;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal RelationalGroupedDataset(JvmObjectReference jvmObject, DataFrame dataFrame);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public DataFrame Agg(Column expr, Column[] exprs);
    public DataFrame Count();
    public DataFrame Mean(String[] colNames);
    public DataFrame Max(String[] colNames);
    public DataFrame Avg(String[] colNames);
    public DataFrame Min(String[] colNames);
    public DataFrame Sum(String[] colNames);
    public RelationalGroupedDataset Pivot(string pivotColumn);
    public RelationalGroupedDataset Pivot(string pivotColumn, IEnumerable`1<object> values);
    public RelationalGroupedDataset Pivot(Column pivotColumn);
    public RelationalGroupedDataset Pivot(Column pivotColumn, IEnumerable`1<object> values);
    public DataFrame Apply(StructType returnType, Func`2<DataFrame, DataFrame> func);
    public DataFrame Apply(StructType returnType, Func`2<RecordBatch, RecordBatch> func);
}
[DefaultMemberAttribute("Item")]
public class Microsoft.Spark.Sql.Row : object {
    private GenericRow _genericRow;
    [CompilerGeneratedAttribute]
private StructType <Schema>k__BackingField;
    public StructType Schema { get; }
    public Object[] Values { get; }
    public object Item { get; }
    internal Row(Object[] values, StructType schema);
    internal Row(GenericRow genericRow);
    public static Row op_Implicit(GenericRow genericRow);
    [CompilerGeneratedAttribute]
public StructType get_Schema();
    public Object[] get_Values();
    public int Size();
    public object get_Item(int index);
    public object Get(int index);
    public object Get(string columnName);
    public virtual string ToString();
    public T GetAs(int index);
    public T GetAs(string columnName);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    private void Convert();
}
internal class Microsoft.Spark.Sql.RowCollector : object {
    [IteratorStateMachineAttribute("Microsoft.Spark.Sql.RowCollector/<Collect>d__0")]
public IEnumerable`1<Row> Collect(ISocketWrapper socket);
    public IEnumerable`1<Row> Collect(ISocketWrapper socket, JvmObjectReference server);
}
internal class Microsoft.Spark.Sql.RowConstructor : object {
    [ThreadStaticAttribute]
private static IDictionary`2<string, StructType> s_schemaCache;
    public sealed virtual object construct(Object[] args);
    internal void Reset();
    private static StructType GetSchema(IDictionary`2<string, StructType> schemaCache, string schemaString);
}
internal class Microsoft.Spark.Sql.RowPickler : object {
    public sealed virtual void pickle(object o, Stream outs, Pickler currentPickler);
}
internal class Microsoft.Spark.Sql.RowWithSchemaConstructor : object {
    private StructType _schema;
    internal RowWithSchemaConstructor(StructType schema);
    public sealed virtual object construct(Object[] args);
}
public class Microsoft.Spark.Sql.RuntimeConfig : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal RuntimeConfig(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public void Set(string key, string value);
    public void Set(string key, bool value);
    public void Set(string key, long value);
    public string Get(string key);
    public string Get(string key, string defaultValue);
    public void Unset(string key);
    public bool IsModifiable(string key);
}
public enum Microsoft.Spark.Sql.SaveMode : Enum {
    public int value__;
    public static SaveMode Append;
    public static SaveMode Overwrite;
    public static SaveMode ErrorIfExists;
    public static SaveMode Ignore;
}
public class Microsoft.Spark.Sql.SparkSession : object {
    private Lazy`1<SparkContext> _sparkContext;
    private Lazy`1<Catalog> _catalog;
    private static string s_sparkSessionClassName;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public SparkContext SparkContext { get; }
    public Catalog Catalog { get; }
    internal SparkSession(JvmObjectReference jvmObject);
    private static SparkSession();
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public SparkContext get_SparkContext();
    public Catalog get_Catalog();
    public static Builder Builder();
    public static void SetActiveSession(SparkSession session);
    public static void ClearActiveSession();
    public static SparkSession GetActiveSession();
    public static void SetDefaultSession(SparkSession session);
    public static void ClearDefaultSession();
    public static SparkSession GetDefaultSession();
    [SinceAttribute("2.4.0")]
public static SparkSession Active();
    public sealed virtual void Dispose();
    public RuntimeConfig Conf();
    public StreamingQueryManager Streams();
    public SparkSession NewSession();
    public string Version();
    public DataFrame Table(string tableName);
    public DataFrame CreateDataFrame(IEnumerable`1<GenericRow> data, StructType schema);
    public DataFrame CreateDataFrame(IEnumerable`1<int> data);
    public DataFrame CreateDataFrame(IEnumerable`1<Nullable`1<int>> data);
    public DataFrame CreateDataFrame(IEnumerable`1<string> data);
    public DataFrame CreateDataFrame(IEnumerable`1<double> data);
    public DataFrame CreateDataFrame(IEnumerable`1<Nullable`1<double>> data);
    public DataFrame CreateDataFrame(IEnumerable`1<bool> data);
    public DataFrame CreateDataFrame(IEnumerable`1<Nullable`1<bool>> data);
    public DataFrame CreateDataFrame(IEnumerable`1<Date> data);
    public DataFrame CreateDataFrame(IEnumerable`1<Timestamp> data);
    public DataFrame Sql(string sqlText);
    [SinceAttribute("3.0.0")]
public DataFrame ExecuteCommand(string runner, string command, Dictionary`2<string, string> options);
    public DataFrameReader Read();
    public DataFrame Range(long end);
    public DataFrame Range(long start, long end);
    public DataFrame Range(long start, long end, long step);
    public DataFrame Range(long start, long end, long step, int numPartitions);
    public DataStreamReader ReadStream();
    public UdfRegistration Udf();
    public void Stop();
    private StructType SchemaWithSingleColumn(DataType dataType, bool isNullable);
    private IEnumerable`1<GenericRow> ToGenericRows(IEnumerable`1<T> rows);
    [CompilerGeneratedAttribute]
private SparkContext <.ctor>b__3_0();
    [CompilerGeneratedAttribute]
private Catalog <.ctor>b__3_1();
}
public class Microsoft.Spark.Sql.StorageLevel : object {
    private static string s_storageLevelClassName;
    private static StorageLevel s_none;
    private static StorageLevel s_diskOnly;
    private static StorageLevel s_diskOnly2;
    private static StorageLevel s_memoryOnly;
    private static StorageLevel s_memoryOnly2;
    private static StorageLevel s_memoryOnlySer;
    private static StorageLevel s_memoryOnlySer2;
    private static StorageLevel s_memoryAndDisk;
    private static StorageLevel s_memoryAndDisk2;
    private static StorageLevel s_memoryAndDiskSer;
    private static StorageLevel s_memoryAndDiskSer2;
    private static StorageLevel s_offHeap;
    private Nullable`1<bool> _useDisk;
    private Nullable`1<bool> _useMemory;
    private Nullable`1<bool> _useOffHeap;
    private Nullable`1<bool> _deserialized;
    private Nullable`1<int> _replication;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public static StorageLevel NONE { get; }
    public static StorageLevel DISK_ONLY { get; }
    public static StorageLevel DISK_ONLY_2 { get; }
    public static StorageLevel MEMORY_ONLY { get; }
    public static StorageLevel MEMORY_ONLY_2 { get; }
    public static StorageLevel MEMORY_ONLY_SER { get; }
    public static StorageLevel MEMORY_ONLY_SER_2 { get; }
    public static StorageLevel MEMORY_AND_DISK { get; }
    public static StorageLevel MEMORY_AND_DISK_2 { get; }
    public static StorageLevel MEMORY_AND_DISK_SER { get; }
    public static StorageLevel MEMORY_AND_DISK_SER_2 { get; }
    public static StorageLevel OFF_HEAP { get; }
    public bool UseDisk { get; }
    public bool UseMemory { get; }
    public bool UseOffHeap { get; }
    public bool Deserialized { get; }
    public int Replication { get; }
    internal StorageLevel(JvmObjectReference jvmObject);
    public StorageLevel(bool useDisk, bool useMemory, bool useOffHeap, bool deserialized, int replication);
    private static StorageLevel();
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public static StorageLevel get_NONE();
    public static StorageLevel get_DISK_ONLY();
    public static StorageLevel get_DISK_ONLY_2();
    public static StorageLevel get_MEMORY_ONLY();
    public static StorageLevel get_MEMORY_ONLY_2();
    public static StorageLevel get_MEMORY_ONLY_SER();
    public static StorageLevel get_MEMORY_ONLY_SER_2();
    public static StorageLevel get_MEMORY_AND_DISK();
    public static StorageLevel get_MEMORY_AND_DISK_2();
    public static StorageLevel get_MEMORY_AND_DISK_SER();
    public static StorageLevel get_MEMORY_AND_DISK_SER_2();
    public static StorageLevel get_OFF_HEAP();
    public bool get_UseDisk();
    public bool get_UseMemory();
    public bool get_UseOffHeap();
    public bool get_Deserialized();
    public int get_Replication();
    public string Description();
    public virtual string ToString();
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
}
public class Microsoft.Spark.Sql.Streaming.DataStreamReader : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal DataStreamReader(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public DataStreamReader Format(string source);
    public DataStreamReader Schema(StructType schema);
    public DataStreamReader Schema(string schemaString);
    public DataStreamReader Option(string key, string value);
    public DataStreamReader Option(string key, bool value);
    public DataStreamReader Option(string key, long value);
    public DataStreamReader Option(string key, double value);
    public DataStreamReader Options(Dictionary`2<string, string> options);
    public DataFrame Load();
    public DataFrame Load(string path);
    public DataFrame Json(string path);
    public DataFrame Csv(string path);
    public DataFrame Orc(string path);
    public DataFrame Parquet(string path);
    [SinceAttribute("3.1.0")]
public DataFrame Table(string tableName);
    public DataFrame Text(string path);
    private DataStreamReader OptionInternal(string key, object value);
    private DataFrame LoadSource(string source, string path);
}
public class Microsoft.Spark.Sql.Streaming.DataStreamWriter : object {
    private DataFrame _df;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal DataStreamWriter(JvmObjectReference jvmObject, DataFrame df);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public DataStreamWriter OutputMode(string outputMode);
    public DataStreamWriter OutputMode(OutputMode outputMode);
    public DataStreamWriter Format(string source);
    public DataStreamWriter PartitionBy(String[] colNames);
    public DataStreamWriter Option(string key, string value);
    public DataStreamWriter Option(string key, bool value);
    public DataStreamWriter Option(string key, long value);
    public DataStreamWriter Option(string key, double value);
    public DataStreamWriter Options(Dictionary`2<string, string> options);
    public DataStreamWriter Trigger(Trigger trigger);
    public DataStreamWriter QueryName(string queryName);
    public StreamingQuery Start(string path);
    [SinceAttribute("3.1.0")]
public StreamingQuery ToTable(string tableName);
    [SinceAttribute("2.4.0")]
public DataStreamWriter Foreach(IForeachWriter writer);
    [SinceAttribute("2.4.0")]
public DataStreamWriter ForeachBatch(Action`2<DataFrame, long> func);
    private DataStreamWriter OptionInternal(string key, object value);
}
public enum Microsoft.Spark.Sql.Streaming.OutputMode : Enum {
    public int value__;
    public static OutputMode Append;
    public static OutputMode Complete;
    public static OutputMode Update;
}
public class Microsoft.Spark.Sql.Streaming.StreamingQuery : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    public string Name { get; }
    public string Id { get; }
    public string RunId { get; }
    internal StreamingQuery(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public string get_Name();
    public string get_Id();
    public string get_RunId();
    public bool IsActive();
    public void AwaitTermination();
    public bool AwaitTermination(long timeoutMs);
    public void ProcessAllAvailable();
    public void Stop();
    public void Explain(bool extended);
    public StreamingQueryException Exception();
}
public class Microsoft.Spark.Sql.Streaming.StreamingQueryException : JvmException {
    public StreamingQueryException(string message);
}
public class Microsoft.Spark.Sql.Streaming.StreamingQueryManager : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal StreamingQueryManager(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public IEnumerable`1<StreamingQuery> Active();
    public StreamingQuery Get(string id);
    public void AwaitAnyTermination();
    public void AwaitAnyTermination(long timeoutMs);
    public void ResetTerminated();
}
public class Microsoft.Spark.Sql.Streaming.Trigger : object {
    [CompilerGeneratedAttribute]
private static IJvmBridge <Jvm>k__BackingField;
    private static string s_triggerClassName;
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    private static IJvmBridge Jvm { get; }
    public JvmObjectReference Reference { get; private set; }
    internal Trigger(JvmObjectReference jvmObject);
    private static Trigger();
    [CompilerGeneratedAttribute]
private static IJvmBridge get_Jvm();
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public static Trigger ProcessingTime(long intervalMs);
    public static Trigger ProcessingTime(string interval);
    public static Trigger Once();
    public static Trigger Continuous(long intervalMs);
    public static Trigger Continuous(string interval);
    private static Trigger Apply(string funcName, Object[] args);
}
internal class Microsoft.Spark.Sql.TimestampPickler : object {
    public sealed virtual void pickle(object o, Stream outs, Pickler currentPickler);
}
public class Microsoft.Spark.Sql.Types.ArrayType : DataType {
    [CompilerGeneratedAttribute]
private DataType <ElementType>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <ContainsNull>k__BackingField;
    public DataType ElementType { get; private set; }
    public bool ContainsNull { get; private set; }
    public string SimpleString { get; }
    internal object JsonValue { get; }
    public ArrayType(DataType elementType, bool containsNull);
    internal ArrayType(JObject json);
    [CompilerGeneratedAttribute]
public DataType get_ElementType();
    [CompilerGeneratedAttribute]
private void set_ElementType(DataType value);
    [CompilerGeneratedAttribute]
public bool get_ContainsNull();
    [CompilerGeneratedAttribute]
private void set_ContainsNull(bool value);
    public virtual string get_SimpleString();
    internal virtual object get_JsonValue();
    private DataType FromJson(JObject json);
    internal virtual bool NeedConversion();
    internal virtual object FromInternal(object obj);
}
public abstract class Microsoft.Spark.Sql.Types.AtomicType : DataType {
}
public class Microsoft.Spark.Sql.Types.BinaryType : AtomicType {
}
public class Microsoft.Spark.Sql.Types.BooleanType : AtomicType {
}
public class Microsoft.Spark.Sql.Types.ByteType : IntegralType {
}
public abstract class Microsoft.Spark.Sql.Types.DataType : object {
    private static Type[] s_simpleTypes;
    private static Type[] s_complexTypes;
    private static Lazy`1<String[]> s_simpleTypeNormalizedNames;
    private static Lazy`1<String[]> s_complexTypeNormalizedNames;
    private string _typeName;
    public string TypeName { get; }
    public string SimpleString { get; }
    public string Json { get; }
    internal object JsonValue { get; }
    private static DataType();
    public string get_TypeName();
    public virtual string get_SimpleString();
    public string get_Json();
    internal virtual object get_JsonValue();
    internal static JvmObjectReference FromJson(IJvmBridge jvm, string json);
    public static DataType ParseDataType(string json);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    internal static DataType ParseDataType(JToken json);
    internal virtual bool NeedConversion();
    internal virtual object FromInternal(object obj);
    private static DataType ParseSimpleType(JToken json);
    private static string NormalizeTypeName(string typeName);
}
public class Microsoft.Spark.Sql.Types.Date : object {
    private DateTime _dateTime;
    public int Year { get; }
    public int Month { get; }
    public int Day { get; }
    public Date(DateTime dateTime);
    public Date(int year, int month, int day);
    public int get_Year();
    public int get_Month();
    public int get_Day();
    public virtual string ToString();
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    public DateTime ToDateTime();
    internal int GetInterval();
}
public class Microsoft.Spark.Sql.Types.DateType : AtomicType {
    internal static DateTime s_unixTimeEpoch;
    private static DateType();
    internal virtual bool NeedConversion();
    internal virtual object FromInternal(object obj);
}
public class Microsoft.Spark.Sql.Types.DecimalType : FractionalType {
    internal static Regex s_fixedDecimal;
    private int _precision;
    private int _scale;
    public string SimpleString { get; }
    internal object JsonValue { get; }
    public DecimalType(int precision, int scale);
    private static DecimalType();
    public virtual string get_SimpleString();
    internal virtual object get_JsonValue();
}
public class Microsoft.Spark.Sql.Types.DoubleType : FractionalType {
}
public class Microsoft.Spark.Sql.Types.FloatType : FractionalType {
}
public abstract class Microsoft.Spark.Sql.Types.FractionalType : NumericType {
}
public class Microsoft.Spark.Sql.Types.IntegerType : IntegralType {
}
public abstract class Microsoft.Spark.Sql.Types.IntegralType : NumericType {
}
public class Microsoft.Spark.Sql.Types.LongType : IntegralType {
}
public class Microsoft.Spark.Sql.Types.MapType : DataType {
    [CompilerGeneratedAttribute]
private DataType <KeyType>k__BackingField;
    [CompilerGeneratedAttribute]
private DataType <ValueType>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <ValueContainsNull>k__BackingField;
    public DataType KeyType { get; private set; }
    public DataType ValueType { get; private set; }
    public bool ValueContainsNull { get; private set; }
    public string SimpleString { get; }
    internal object JsonValue { get; }
    public MapType(DataType keyType, DataType valueType, bool valueContainsNull);
    internal MapType(JObject json);
    [CompilerGeneratedAttribute]
public DataType get_KeyType();
    [CompilerGeneratedAttribute]
private void set_KeyType(DataType value);
    [CompilerGeneratedAttribute]
public DataType get_ValueType();
    [CompilerGeneratedAttribute]
private void set_ValueType(DataType value);
    [CompilerGeneratedAttribute]
public bool get_ValueContainsNull();
    [CompilerGeneratedAttribute]
private void set_ValueContainsNull(bool value);
    public virtual string get_SimpleString();
    internal virtual object get_JsonValue();
    private DataType FromJson(JObject json);
    internal virtual bool NeedConversion();
    internal virtual object FromInternal(object obj);
}
public class Microsoft.Spark.Sql.Types.NullType : DataType {
}
public abstract class Microsoft.Spark.Sql.Types.NumericType : AtomicType {
}
public class Microsoft.Spark.Sql.Types.ShortType : IntegralType {
}
public class Microsoft.Spark.Sql.Types.StringType : AtomicType {
}
public class Microsoft.Spark.Sql.Types.StructField : object {
    [CompilerGeneratedAttribute]
private string <Name>k__BackingField;
    [CompilerGeneratedAttribute]
private DataType <DataType>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <IsNullable>k__BackingField;
    [CompilerGeneratedAttribute]
private JObject <Metadata>k__BackingField;
    public string Name { get; }
    public DataType DataType { get; }
    public bool IsNullable { get; }
    internal JObject Metadata { get; }
    internal object JsonValue { get; }
    public StructField(string name, DataType dataType, bool isNullable, JObject metadata);
    internal StructField(JObject json);
    [CompilerGeneratedAttribute]
public string get_Name();
    [CompilerGeneratedAttribute]
public DataType get_DataType();
    [CompilerGeneratedAttribute]
public bool get_IsNullable();
    [CompilerGeneratedAttribute]
internal JObject get_Metadata();
    public virtual string ToString();
    internal object get_JsonValue();
}
public class Microsoft.Spark.Sql.Types.StructType : DataType {
    [CompilerGeneratedAttribute]
private List`1<StructField> <Fields>k__BackingField;
    public List`1<StructField> Fields { get; private set; }
    public string SimpleString { get; }
    internal object JsonValue { get; }
    internal StructType(JObject json);
    internal StructType(JvmObjectReference jvmObject);
    public StructType(IEnumerable`1<StructField> fields);
    [CompilerGeneratedAttribute]
public List`1<StructField> get_Fields();
    [CompilerGeneratedAttribute]
private void set_Fields(List`1<StructField> value);
    public virtual string get_SimpleString();
    internal virtual object get_JsonValue();
    private DataType FromJson(JObject json);
}
public class Microsoft.Spark.Sql.Types.Timestamp : object {
    private DateTime _dateTime;
    public int Year { get; }
    public int Month { get; }
    public int Day { get; }
    public int Hour { get; }
    public int Minute { get; }
    public int Second { get; }
    public int Microsecond { get; }
    public Timestamp(DateTime dateTime);
    public Timestamp(int year, int month, int day, int hour, int minute, int second, int microsecond);
    public int get_Year();
    public int get_Month();
    public int get_Day();
    public int get_Hour();
    public int get_Minute();
    public int get_Second();
    public int get_Microsecond();
    public virtual string ToString();
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    public DateTime ToDateTime();
    internal double GetIntervalInSeconds();
    internal long GetIntervalInMicroseconds();
}
public class Microsoft.Spark.Sql.Types.TimestampType : AtomicType {
    internal virtual bool NeedConversion();
    internal virtual object FromInternal(object obj);
}
public class Microsoft.Spark.Sql.UdfRegistration : object {
    [CompilerGeneratedAttribute]
private JvmObjectReference <Reference>k__BackingField;
    public JvmObjectReference Reference { get; private set; }
    internal UdfRegistration(JvmObjectReference jvmObject);
    [CompilerGeneratedAttribute]
public sealed virtual JvmObjectReference get_Reference();
    [CompilerGeneratedAttribute]
private void set_Reference(JvmObjectReference value);
    public void Register(string name, Func`1<TResult> f);
    public void Register(string name, Func`2<T, TResult> f);
    public void Register(string name, Func`3<T1, T2, TResult> f);
    public void Register(string name, Func`4<T1, T2, T3, TResult> f);
    public void Register(string name, Func`5<T1, T2, T3, T4, TResult> f);
    public void Register(string name, Func`6<T1, T2, T3, T4, T5, TResult> f);
    public void Register(string name, Func`7<T1, T2, T3, T4, T5, T6, TResult> f);
    public void Register(string name, Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> f);
    public void Register(string name, Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> f);
    public void Register(string name, Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> f);
    public void Register(string name, Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> f);
    public void Register(string name, Func`1<Row> f, StructType returnType);
    public void Register(string name, Func`2<T, Row> f, StructType returnType);
    public void Register(string name, Func`3<T1, T2, Row> f, StructType returnType);
    public void Register(string name, Func`4<T1, T2, T3, Row> f, StructType returnType);
    public void Register(string name, Func`5<T1, T2, T3, T4, Row> f, StructType returnType);
    public void Register(string name, Func`6<T1, T2, T3, T4, T5, Row> f, StructType returnType);
    public void Register(string name, Func`7<T1, T2, T3, T4, T5, T6, Row> f, StructType returnType);
    public void Register(string name, Func`8<T1, T2, T3, T4, T5, T6, T7, Row> f, StructType returnType);
    public void Register(string name, Func`9<T1, T2, T3, T4, T5, T6, T7, T8, Row> f, StructType returnType);
    public void Register(string name, Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, Row> f, StructType returnType);
    public void Register(string name, Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, Row> f, StructType returnType);
    public void RegisterJava(string name, string className);
    public void RegisterJavaUDAF(string name, string className);
    private void Register(string name, Delegate func);
    private void Register(string name, Delegate func, StructType returnType);
    internal void Register(string name, Delegate func, PythonEvalType evalType);
    private void Register(string name, Delegate func, PythonEvalType evalType, string returnType);
    private JvmObjectReference GetDataType();
}
[ExtensionAttribute]
public static class Microsoft.Spark.Sql.UdfRegistrationExtensions : object {
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`2<T, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`3<T1, T2, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`4<T1, T2, T3, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`5<T1, T2, T3, T4, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`6<T1, T2, T3, T4, T5, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`7<T1, T2, T3, T4, T5, T6, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> f);
    [ExtensionAttribute]
public static void RegisterVector(UdfRegistration udf, string name, Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> f);
    private static void RegisterVector(UdfRegistration udf, string name, Delegate func);
}
internal abstract class Microsoft.Spark.Sql.WorkerFunction : object {
}
internal class Microsoft.Spark.TaskContext : object {
    [CompilerGeneratedAttribute]
private int <StageId>k__BackingField;
    [CompilerGeneratedAttribute]
private int <PartitionId>k__BackingField;
    [CompilerGeneratedAttribute]
private int <AttemptNumber>k__BackingField;
    [CompilerGeneratedAttribute]
private long <AttemptId>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <IsBarrier>k__BackingField;
    [CompilerGeneratedAttribute]
private int <Port>k__BackingField;
    [CompilerGeneratedAttribute]
private string <Secret>k__BackingField;
    [CompilerGeneratedAttribute]
private IEnumerable`1<Resource> <Resources>k__BackingField;
    [CompilerGeneratedAttribute]
private Dictionary`2<string, string> <LocalProperties>k__BackingField;
    internal int StageId { get; internal set; }
    internal int PartitionId { get; internal set; }
    internal int AttemptNumber { get; internal set; }
    internal long AttemptId { get; internal set; }
    internal bool IsBarrier { get; internal set; }
    internal int Port { get; internal set; }
    internal string Secret { get; internal set; }
    internal IEnumerable`1<Resource> Resources { get; internal set; }
    internal Dictionary`2<string, string> LocalProperties { get; internal set; }
    [CompilerGeneratedAttribute]
internal int get_StageId();
    [CompilerGeneratedAttribute]
internal void set_StageId(int value);
    [CompilerGeneratedAttribute]
internal int get_PartitionId();
    [CompilerGeneratedAttribute]
internal void set_PartitionId(int value);
    [CompilerGeneratedAttribute]
internal int get_AttemptNumber();
    [CompilerGeneratedAttribute]
internal void set_AttemptNumber(int value);
    [CompilerGeneratedAttribute]
internal long get_AttemptId();
    [CompilerGeneratedAttribute]
internal void set_AttemptId(long value);
    [CompilerGeneratedAttribute]
internal bool get_IsBarrier();
    [CompilerGeneratedAttribute]
internal void set_IsBarrier(bool value);
    [CompilerGeneratedAttribute]
internal int get_Port();
    [CompilerGeneratedAttribute]
internal void set_Port(int value);
    [CompilerGeneratedAttribute]
internal string get_Secret();
    [CompilerGeneratedAttribute]
internal void set_Secret(string value);
    [CompilerGeneratedAttribute]
internal IEnumerable`1<Resource> get_Resources();
    [CompilerGeneratedAttribute]
internal void set_Resources(IEnumerable`1<Resource> value);
    [CompilerGeneratedAttribute]
internal Dictionary`2<string, string> get_LocalProperties();
    [CompilerGeneratedAttribute]
internal void set_LocalProperties(Dictionary`2<string, string> value);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
}
internal static class Microsoft.Spark.TaskContextHolder : object {
    [ThreadStaticAttribute]
internal static TaskContext s_taskContext;
    internal static TaskContext Get();
    internal static void Set(TaskContext tc);
}
[AttributeUsageAttribute("4")]
internal class Microsoft.Spark.UdfWrapperAttribute : Attribute {
}
internal static class Microsoft.Spark.Utils.AssemblyInfoProvider : object {
    private static string MicrosoftSparkAssemblyName;
    private static string MicrosoftSparkWorkerAssemblyName;
    private static Lazy`1<AssemblyInfo> s_microsoftSparkAssemblyInfo;
    private static Lazy`1<AssemblyInfo> s_microsoftSparkWorkerAssemblyInfo;
    private static AssemblyInfoProvider();
    internal static AssemblyInfo MicrosoftSparkAssemblyInfo();
    internal static AssemblyInfo MicrosoftSparkWorkerAssemblyInfo();
    private static AssemblyInfo CreateAssemblyInfo(string assemblyName);
}
internal static class Microsoft.Spark.Utils.AssemblyLoader : object {
    [CompilerGeneratedAttribute]
private static Func`2<string, Assembly> <LoadFromFile>k__BackingField;
    private static ILoggerService s_logger;
    private static Dictionary`2<string, Assembly> s_assemblyCache;
    private static Lazy`1<String[]> s_searchPaths;
    private static String[] s_extensions;
    private static object s_cacheLock;
    private static Regex s_roslynAssemblyNameRegex;
    internal static Func`2<string, Assembly> LoadFromFile { get; internal set; }
    private static AssemblyLoader();
    [CompilerGeneratedAttribute]
internal static Func`2<string, Assembly> get_LoadFromFile();
    [CompilerGeneratedAttribute]
internal static void set_LoadFromFile(Func`2<string, Assembly> value);
    internal static Assembly LoadAssembly(string assemblyName, string assemblyFileName);
    internal static Assembly ResolveAssembly(string assemblyName);
    private static bool TryLoadAssembly(string assemblyFileName, Assembly& assembly);
    internal static string NormalizeAssemblyName(string assemblyName);
}
internal static class Microsoft.Spark.Utils.AssemblySearchPathResolver : object {
    internal static string AssemblySearchPathsEnvVarName;
    internal static String[] GetAssemblySearchPaths();
}
internal static class Microsoft.Spark.Utils.Authenticator : object {
    private static string s_validResponseCode;
    private static string s_invalidResponseCode;
    private static Authenticator();
    public static bool AuthenticateAsClient(Stream stream, string secret);
    public static bool AuthenticateAsServer(ISocketWrapper socket, string secret);
}
internal static class Microsoft.Spark.Utils.CollectionUtils : object {
    internal static bool ArrayEquals(T[] array1, T[] array2);
}
internal static class Microsoft.Spark.Utils.CommandSerDe : object {
    private static string UdfWrapperMethodName;
    internal static Byte[] Serialize(Delegate func, SerializedMode deserializerMode, SerializedMode serializerMode);
    private static void SerializeUdfs(Delegate func, UdfWrapperNode parent, List`1<UdfWrapperNode> udfWrapperNodes, List`1<UdfData> udfs);
    internal static object DeserializeArrowOrDataFrameUdf(Stream stream, SerializedMode& serializerMode, SerializedMode& deserializerMode, String& runMode);
    private static UdfWrapperData GetUdfWrapperDataFromStream(Stream stream, SerializedMode& serializerMode, SerializedMode& deserializerMode, String& runMode);
    internal static T Deserialize(Stream stream, SerializedMode& serializerMode, SerializedMode& deserializerMode, String& runMode);
    private static Delegate DeserializeUdfs(UdfWrapperData data, Int32& nodeIndex, Int32& udfIndex);
    private static Delegate CreateUdfWrapperDelegate(Type type, Object[] parameters);
}
internal static class Microsoft.Spark.Utils.DataFrameUdfUtils : object {
    internal static Delegate CreateVectorUdfWrapper(Func`2<T, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`3<T1, T2, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`4<T1, T2, T3, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`5<T1, T2, T3, T4, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`6<T1, T2, T3, T4, T5, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`7<T1, T2, T3, T4, T5, T6, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> udf);
}
internal class Microsoft.Spark.Utils.DependencyProviderUtils : object {
    private static string s_filePattern;
    private static DependencyProviderUtils();
    internal static String[] GetMetadataFiles(string path);
    internal static string CreateFileName(long number);
}
internal static class Microsoft.Spark.Utils.EnvironmentUtils : object {
    internal static bool GetEnvironmentVariableAsBool(string name);
}
internal class Microsoft.Spark.Utils.JvmObjectUtils : object {
    internal static Dictionary`2<string, Type> ConstructJavaClassMapping(Type parentType, string javaClassFieldName);
    internal static bool TryConstructInstanceFromJvmObject(JvmObjectReference jvmObject, Dictionary`2<string, Type> classMapping, T& instance);
}
internal class Microsoft.Spark.Utils.PythonSerDe : object {
    private static RowConstructor s_rowConstructor;
    private static PythonSerDe();
    internal static Object[] GetUnpickledObjects(Stream stream, int messageLength);
}
internal static class Microsoft.Spark.Utils.TypeConverter : object {
    internal static T ConvertTo(object obj);
    private static object Convert(object obj, Type toType);
    private static object ConvertToArray(ArrayList arrayList, Type type);
    private static object ConvertToDictionary(Hashtable hashtable, Type type);
}
internal class Microsoft.Spark.Utils.UdfSerDe : object {
    private static ConcurrentDictionary`2<TypeData, Type> s_typeCache;
    private static UdfSerDe();
    internal static UdfData Serialize(Delegate udf);
    internal static Delegate Deserialize(UdfData udfData);
    private static TargetData SerializeTarget(object target);
    private static object DeserializeTargetData(TargetData targetData);
    private static TypeData SerializeType(Type type);
    private static Type DeserializeType(TypeData typeData);
}
[ExtensionAttribute]
internal static class Microsoft.Spark.Utils.UdfTypeUtils : object {
    [ExtensionAttribute]
internal static string CanBeNull(Type type);
    [ExtensionAttribute]
internal static Type ImplementsGenericTypeOf(Type type, Type compare);
}
internal static class Microsoft.Spark.Utils.UdfUtils : object {
    private static Dictionary`2<Type, string> s_returnTypes;
    private static UdfUtils();
    internal static string GetReturnType(Type type);
    internal static JvmObjectReference CreatePythonFunction(IJvmBridge jvm, Byte[] command);
    private static IJvmObjectReferenceProvider CreateEnvVarsForPythonFunction(IJvmBridge jvm);
    internal static Delegate CreateUdfWrapper(Func`1<TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`2<T, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`3<T1, T2, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`4<T1, T2, T3, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`5<T1, T2, T3, T4, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`6<T1, T2, T3, T4, T5, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`7<T1, T2, T3, T4, T5, T6, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> udf);
    internal static Delegate CreateUdfWrapper(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`2<T, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`3<T1, T2, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`4<T1, T2, T3, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`5<T1, T2, T3, T4, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`6<T1, T2, T3, T4, T5, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`7<T1, T2, T3, T4, T5, T6, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`8<T1, T2, T3, T4, T5, T6, T7, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`9<T1, T2, T3, T4, T5, T6, T7, T8, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`10<T1, T2, T3, T4, T5, T6, T7, T8, T9, TResult> udf);
    internal static Delegate CreateVectorUdfWrapper(Func`11<T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, TResult> udf);
}
public abstract class Microsoft.Spark.VersionAttribute : Attribute {
    [CompilerGeneratedAttribute]
private Version <Version>k__BackingField;
    public Version Version { get; }
    protected VersionAttribute(string version);
    [CompilerGeneratedAttribute]
public Version get_Version();
}
internal static class Microsoft.Spark.Versions : object {
    internal static string V2_4_0;
    internal static string V2_4_2;
    internal static string V3_0_0;
    internal static string V3_1_0;
    internal static string V3_1_1;
    internal static string V3_2_0;
}
[ExtensionAttribute]
public static class System.ArrayExtensions : object {
    [ExtensionAttribute]
internal static ArrayList ToJavaArrayList(T[] array);
}
[ExtensionAttribute]
public static class System.Collections.Generic.Dictionary : object {
    [ExtensionAttribute]
internal static HashMap ToJavaHashMap(Dictionary`2<string, string> dictionary);
    [ExtensionAttribute]
internal static HashMap ToJavaHashMap(Dictionary`2<string, object> dictionary);
}
