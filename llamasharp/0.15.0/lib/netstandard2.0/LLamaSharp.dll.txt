[NullableContextAttribute("1")]
public interface LLama.Abstractions.IContextParams {
    public Nullable`1<UInt32> ContextSize { get; }
    public UInt32 BatchSize { get; }
    public UInt32 UBatchSize { get; }
    public UInt32 SeqMax { get; }
    public Nullable`1<UInt32> Seed { get; }
    public bool Embeddings { get; }
    public Nullable`1<float> RopeFrequencyBase { get; }
    public Nullable`1<float> RopeFrequencyScale { get; }
    public Encoding Encoding { get; }
    public Nullable`1<UInt32> Threads { get; }
    public Nullable`1<UInt32> BatchThreads { get; }
    public Nullable`1<float> YarnExtrapolationFactor { get; }
    public Nullable`1<float> YarnAttentionFactor { get; }
    public Nullable`1<float> YarnBetaFast { get; }
    public Nullable`1<float> YarnBetaSlow { get; }
    public Nullable`1<UInt32> YarnOriginalContext { get; }
    public Nullable`1<RopeScalingType> YarnScalingType { get; }
    public Nullable`1<GGMLType> TypeK { get; }
    public Nullable`1<GGMLType> TypeV { get; }
    public bool NoKqvOffload { get; }
    public bool FlashAttention { get; }
    public Nullable`1<float> DefragThreshold { get; }
    public LLamaPoolingType PoolingType { get; }
    public LLamaAttentionType AttentionType { get; }
    public abstract virtual Nullable`1<UInt32> get_ContextSize();
    public abstract virtual UInt32 get_BatchSize();
    public abstract virtual UInt32 get_UBatchSize();
    public abstract virtual UInt32 get_SeqMax();
    public abstract virtual Nullable`1<UInt32> get_Seed();
    public abstract virtual bool get_Embeddings();
    public abstract virtual Nullable`1<float> get_RopeFrequencyBase();
    public abstract virtual Nullable`1<float> get_RopeFrequencyScale();
    public abstract virtual Encoding get_Encoding();
    public abstract virtual Nullable`1<UInt32> get_Threads();
    public abstract virtual Nullable`1<UInt32> get_BatchThreads();
    public abstract virtual Nullable`1<float> get_YarnExtrapolationFactor();
    public abstract virtual Nullable`1<float> get_YarnAttentionFactor();
    public abstract virtual Nullable`1<float> get_YarnBetaFast();
    public abstract virtual Nullable`1<float> get_YarnBetaSlow();
    public abstract virtual Nullable`1<UInt32> get_YarnOriginalContext();
    public abstract virtual Nullable`1<RopeScalingType> get_YarnScalingType();
    public abstract virtual Nullable`1<GGMLType> get_TypeK();
    public abstract virtual Nullable`1<GGMLType> get_TypeV();
    public abstract virtual bool get_NoKqvOffload();
    public abstract virtual bool get_FlashAttention();
    public abstract virtual Nullable`1<float> get_DefragThreshold();
    public abstract virtual LLamaPoolingType get_PoolingType();
    public abstract virtual LLamaAttentionType get_AttentionType();
}
[NullableContextAttribute("1")]
[JsonConverterAttribute("LLama.Common.PolymorphicJSONConverter`1<LLama.Abstractions.IHistoryTransform>")]
public interface LLama.Abstractions.IHistoryTransform {
    public abstract virtual string HistoryToText(ChatHistory history);
    public abstract virtual ChatHistory TextToHistory(AuthorRole role, string text);
    public abstract virtual IHistoryTransform Clone();
}
[ExtensionAttribute]
internal static class LLama.Abstractions.IInferanceParamsExtensions : object {
    [NullableContextAttribute("1")]
[ExtensionAttribute]
public static ISamplingPipeline Create(IInferenceParams params, ISamplingPipeline& pipeline);
}
[NullableContextAttribute("2")]
public interface LLama.Abstractions.IInferenceParams {
    public int TokensKeep { get; public set; }
    public int MaxTokens { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public Dictionary`2<LLamaToken, float> LogitBias { get; public set; }
    [NullableAttribute("1")]
public IReadOnlyList`1<string> AntiPrompts { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public int TopK { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float TopP { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float MinP { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float TfsZ { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float TypicalP { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float Temperature { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float RepeatPenalty { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public int RepeatLastTokensCount { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float FrequencyPenalty { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float PresencePenalty { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. MirostatSamplingPipeline or Mirostat2SamplingPipeline")]
public MirostatType Mirostat { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. MirostatSamplingPipeline or Mirostat2SamplingPipeline")]
public float MirostatTau { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. MirostatSamplingPipeline or Mirostat2SamplingPipeline")]
public float MirostatEta { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public bool PenalizeNL { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public SafeLLamaGrammarHandle Grammar { get; public set; }
    public ISamplingPipeline SamplingPipeline { get; public set; }
    public abstract virtual int get_TokensKeep();
    public abstract virtual void set_TokensKeep(int value);
    public abstract virtual int get_MaxTokens();
    public abstract virtual void set_MaxTokens(int value);
    public abstract virtual Dictionary`2<LLamaToken, float> get_LogitBias();
    public abstract virtual void set_LogitBias(Dictionary`2<LLamaToken, float> value);
    [NullableContextAttribute("1")]
public abstract virtual IReadOnlyList`1<string> get_AntiPrompts();
    [NullableContextAttribute("1")]
public abstract virtual void set_AntiPrompts(IReadOnlyList`1<string> value);
    public abstract virtual int get_TopK();
    public abstract virtual void set_TopK(int value);
    public abstract virtual float get_TopP();
    public abstract virtual void set_TopP(float value);
    public abstract virtual float get_MinP();
    public abstract virtual void set_MinP(float value);
    public abstract virtual float get_TfsZ();
    public abstract virtual void set_TfsZ(float value);
    public abstract virtual float get_TypicalP();
    public abstract virtual void set_TypicalP(float value);
    public abstract virtual float get_Temperature();
    public abstract virtual void set_Temperature(float value);
    public abstract virtual float get_RepeatPenalty();
    public abstract virtual void set_RepeatPenalty(float value);
    public abstract virtual int get_RepeatLastTokensCount();
    public abstract virtual void set_RepeatLastTokensCount(int value);
    public abstract virtual float get_FrequencyPenalty();
    public abstract virtual void set_FrequencyPenalty(float value);
    public abstract virtual float get_PresencePenalty();
    public abstract virtual void set_PresencePenalty(float value);
    public abstract virtual MirostatType get_Mirostat();
    public abstract virtual void set_Mirostat(MirostatType value);
    public abstract virtual float get_MirostatTau();
    public abstract virtual void set_MirostatTau(float value);
    public abstract virtual float get_MirostatEta();
    public abstract virtual void set_MirostatEta(float value);
    public abstract virtual bool get_PenalizeNL();
    public abstract virtual void set_PenalizeNL(bool value);
    public abstract virtual SafeLLamaGrammarHandle get_Grammar();
    public abstract virtual void set_Grammar(SafeLLamaGrammarHandle value);
    public abstract virtual ISamplingPipeline get_SamplingPipeline();
    public abstract virtual void set_SamplingPipeline(ISamplingPipeline value);
}
[NullableContextAttribute("1")]
public interface LLama.Abstractions.ILLamaExecutor {
    public LLamaContext Context { get; }
    public bool IsMultiModal { get; }
    [NullableAttribute("2")]
public LLavaWeights ClipModel { get; }
    public List`1<Byte[]> Images { get; }
    public abstract virtual LLamaContext get_Context();
    public abstract virtual bool get_IsMultiModal();
    [NullableContextAttribute("2")]
public abstract virtual LLavaWeights get_ClipModel();
    public abstract virtual List`1<Byte[]> get_Images();
    public abstract virtual IAsyncEnumerable`1<string> InferAsync(string text, IInferenceParams inferenceParams, CancellationToken token);
}
public interface LLama.Abstractions.ILLamaParams {
}
[NullableContextAttribute("1")]
public interface LLama.Abstractions.IModelParams {
    public int MainGpu { get; public set; }
    public GPUSplitMode SplitMode { get; }
    public int GpuLayerCount { get; }
    public bool UseMemorymap { get; }
    public bool UseMemoryLock { get; }
    public string ModelPath { get; }
    public TensorSplitsCollection TensorSplits { get; }
    public bool VocabOnly { get; }
    public List`1<MetadataOverride> MetadataOverrides { get; }
    public abstract virtual int get_MainGpu();
    public abstract virtual void set_MainGpu(int value);
    public abstract virtual GPUSplitMode get_SplitMode();
    public abstract virtual int get_GpuLayerCount();
    public abstract virtual bool get_UseMemorymap();
    public abstract virtual bool get_UseMemoryLock();
    public abstract virtual string get_ModelPath();
    public abstract virtual TensorSplitsCollection get_TensorSplits();
    public abstract virtual bool get_VocabOnly();
    public abstract virtual List`1<MetadataOverride> get_MetadataOverrides();
}
[NullableContextAttribute("2")]
public interface LLama.Abstractions.INativeLibrary {
    public NativeLibraryMetadata Metadata { get; }
    public abstract virtual NativeLibraryMetadata get_Metadata();
    [NullableContextAttribute("1")]
public abstract virtual IEnumerable`1<string> Prepare(SystemInfo systemInfo, LLamaLogCallback logCallback);
}
[NullableContextAttribute("1")]
[JsonConverterAttribute("LLama.Common.PolymorphicJSONConverter`1<LLama.Abstractions.ITextStreamTransform>")]
public interface LLama.Abstractions.ITextStreamTransform {
    public abstract virtual IAsyncEnumerable`1<string> TransformAsync(IAsyncEnumerable`1<string> tokens);
    public abstract virtual ITextStreamTransform Clone();
}
[NullableContextAttribute("1")]
[JsonConverterAttribute("LLama.Common.PolymorphicJSONConverter`1<LLama.Abstractions.ITextTransform>")]
public interface LLama.Abstractions.ITextTransform {
    public abstract virtual string Transform(string text);
    public abstract virtual ITextTransform Clone();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[JsonConverterAttribute("LLama.Abstractions.MetadataOverrideConverter")]
public class LLama.Abstractions.MetadataOverride : object {
    [CompilerGeneratedAttribute]
private string <Key>k__BackingField;
    [CompilerGeneratedAttribute]
private LLamaModelKvOverrideType <Type>k__BackingField;
    private int _valueInt;
    private float _valueFloat;
    private bool _valueBool;
    [NullableAttribute("2")]
private Byte[] _valueString;
    [CompilerGeneratedAttribute]
private Type EqualityContract { get; }
    public string Key { get; }
    internal LLamaModelKvOverrideType Type { get; }
    public MetadataOverride(string key, int value);
    public MetadataOverride(string key, float value);
    public MetadataOverride(string key, bool value);
    public MetadataOverride(string key, string value);
    [CompilerGeneratedAttribute]
private MetadataOverride(MetadataOverride original);
    [CompilerGeneratedAttribute]
private Type get_EqualityContract();
    [CompilerGeneratedAttribute]
public string get_Key();
    [CompilerGeneratedAttribute]
internal LLamaModelKvOverrideType get_Type();
    internal void WriteValue(LLamaModelMetadataOverride& dest);
    internal void WriteValue(Utf8JsonWriter writer);
    [CompilerGeneratedAttribute]
public virtual string ToString();
    [CompilerGeneratedAttribute]
private bool PrintMembers(StringBuilder builder);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Inequality(MetadataOverride left, MetadataOverride right);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Equality(MetadataOverride left, MetadataOverride right);
    [CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public sealed virtual bool Equals(MetadataOverride other);
    [CompilerGeneratedAttribute]
public MetadataOverride <Clone>$();
}
[NullableContextAttribute("1")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
public class LLama.Abstractions.MetadataOverrideConverter : JsonConverter`1<MetadataOverride> {
    public virtual MetadataOverride Read(Utf8JsonReader& reader, Type typeToConvert, JsonSerializerOptions options);
    public virtual void Write(Utf8JsonWriter writer, MetadataOverride value, JsonSerializerOptions options);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[DefaultMemberAttribute("Item")]
[JsonConverterAttribute("LLama.Abstractions.TensorSplitsCollectionConverter")]
public class LLama.Abstractions.TensorSplitsCollection : object {
    internal Single[] Splits;
    public int Length { get; }
    public float Item { get; public set; }
    public TensorSplitsCollection(Single[] splits);
    public int get_Length();
    public float get_Item(int index);
    public void set_Item(int index, float value);
    public void Clear();
    internal MemoryHandle Pin();
    public sealed virtual IEnumerator`1<float> GetEnumerator();
    private sealed virtual override IEnumerator System.Collections.IEnumerable.GetEnumerator();
}
[NullableContextAttribute("1")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
public class LLama.Abstractions.TensorSplitsCollectionConverter : JsonConverter`1<TensorSplitsCollection> {
    public virtual TensorSplitsCollection Read(Utf8JsonReader& reader, Type typeToConvert, JsonSerializerOptions options);
    public virtual void Write(Utf8JsonWriter writer, TensorSplitsCollection value, JsonSerializerOptions options);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.AntipromptProcessor : object {
    private int _longestAntiprompt;
    private List`1<string> _antiprompts;
    [NullableAttribute("2")]
private string _string;
    public AntipromptProcessor(IEnumerable`1<string> antiprompts);
    public void AddAntiprompt(string antiprompt);
    public void SetAntiprompts(IEnumerable`1<string> antiprompts);
    public bool Add(string text);
}
public class LLama.Batched.AlreadyPromptedConversationException : ExperimentalBatchedExecutorException {
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Batched.BatchedExecutor : object {
    private int _nextSequenceId;
    private List`1<IBatch> _batchQueue;
    private int _inferenceLock;
    [CompilerGeneratedAttribute]
private ulong <Epoch>k__BackingField;
    [CompilerGeneratedAttribute]
private LLamaContext <Context>k__BackingField;
    [CompilerGeneratedAttribute]
private LLamaWeights <Model>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <IsDisposed>k__BackingField;
    internal ulong Epoch { get; private set; }
    public LLamaContext Context { get; }
    public LLamaWeights Model { get; }
    public int BatchedTokenCount { get; }
    public int BatchQueueCount { get; }
    public bool IsDisposed { get; private set; }
    public BatchedExecutor(LLamaWeights model, IContextParams contextParams);
    [CompilerGeneratedAttribute]
internal ulong get_Epoch();
    [CompilerGeneratedAttribute]
private void set_Epoch(ulong value);
    [CompilerGeneratedAttribute]
public LLamaContext get_Context();
    [CompilerGeneratedAttribute]
public LLamaWeights get_Model();
    public int get_BatchedTokenCount();
    public int get_BatchQueueCount();
    [CompilerGeneratedAttribute]
public bool get_IsDisposed();
    [CompilerGeneratedAttribute]
private void set_IsDisposed(bool value);
    public Conversation Create();
    public Conversation Load(string filepath);
    public Conversation Load(State state);
    [AsyncStateMachineAttribute("LLama.Batched.BatchedExecutor/<Infer>d__25")]
public Task`1<DecodeResult> Infer(CancellationToken cancellation);
    public sealed virtual void Dispose();
    internal LLamaSeqId GetNextSequenceId();
    internal ValueTuple`2<LLamaBatch, ulong> GetTokenBatch(int minCapacity);
    internal ValueTuple`2<LLamaBatchEmbeddings, ulong> GetEmbeddingBatch(int minCapacity);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
private IBatch <Infer>g__GetNextBatch|25_0();
}
public class LLama.Batched.CannotModifyWhileRequiresInferenceException : ExperimentalBatchedExecutorException {
}
public class LLama.Batched.CannotSampleRequiresInferenceException : ExperimentalBatchedExecutorException {
}
public class LLama.Batched.CannotSampleRequiresPromptException : ExperimentalBatchedExecutorException {
}
public class LLama.Batched.CannotSaveWhileRequiresInferenceException : ExperimentalBatchedExecutorException {
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Batched.Conversation : object {
    private ulong _requiredEpoch;
    private LLamaPos _end;
    private bool _disposed;
    private bool _forked;
    private Int32[] _batchSampleIndices;
    private int _batchSampleCount;
    [CompilerGeneratedAttribute]
private BatchedExecutor <Executor>k__BackingField;
    [CompilerGeneratedAttribute]
private LLamaSeqId <ConversationId>k__BackingField;
    public BatchedExecutor Executor { get; }
    public LLamaSeqId ConversationId { get; }
    public int TokenCount { get; }
    public bool IsDisposed { get; }
    public bool RequiresInference { get; }
    public bool RequiresSampling { get; }
    internal Conversation(BatchedExecutor batch, LLamaSeqId id);
    [CompilerGeneratedAttribute]
public BatchedExecutor get_Executor();
    [CompilerGeneratedAttribute]
public LLamaSeqId get_ConversationId();
    public int get_TokenCount();
    public bool get_IsDisposed();
    public bool get_RequiresInference();
    public bool get_RequiresSampling();
    protected virtual override void Finalize();
    public sealed virtual void Dispose();
    private void AssertNotDisposed();
    public Conversation Fork();
    [NullableContextAttribute("0")]
public Span`1<float> Sample(int offset);
    private void AssertCanBePrompted();
    public void Prompt(List`1<LLamaToken> tokens, bool allLogits);
    [NullableContextAttribute("0")]
public void Prompt(ReadOnlySpan`1<LLamaToken> tokens, bool allLogits);
    public void Prompt(LLamaToken token);
    public void Prompt(SafeLlavaImageEmbedHandle embedding);
    [NullableContextAttribute("0")]
public void Prompt(ReadOnlySpan`1<float> embeddings);
    public void Modify(ModifyKvCache modifier);
    private void AssertCanLoad();
    private void AssertCanSave();
    public void Save(string filepath);
    public State Save();
    internal void Load(string filepath);
    internal void Load(State state);
    private void Load(SerializableConversationState state);
    private SerializableConversationState GetState();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
public static class LLama.Batched.ConversationExtensions : object {
    [ExtensionAttribute]
public static void Rewind(Conversation conversation, int tokens);
    [ExtensionAttribute]
public static void ShiftLeft(Conversation conversation, int count, int keep);
}
public class LLama.Batched.ExperimentalBatchedExecutorException : Exception {
    [NullableContextAttribute("1")]
internal ExperimentalBatchedExecutorException(string message);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
internal static class LLama.Batched.LLamaContextExtensions : object {
    private static UInt32 FileHeaderMagic;
    [ExtensionAttribute]
internal static void SaveState(LLamaContext context, string filename, LLamaSeqId sequence, ReadOnlySpan`1<byte> header);
    [ExtensionAttribute]
internal static void LoadState(LLamaContext context, string filename, LLamaSeqId sequence, Byte[]& header);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.ChatSession : object {
    public static string MODEL_STATE_FILENAME;
    public static string EXECUTOR_STATE_FILENAME;
    public static string HISTORY_STATE_FILENAME;
    public static string INPUT_TRANSFORM_FILENAME;
    public static string OUTPUT_TRANSFORM_FILENAME;
    public static string HISTORY_TRANSFORM_FILENAME;
    [CompilerGeneratedAttribute]
private ILLamaExecutor <Executor>k__BackingField;
    [CompilerGeneratedAttribute]
private ChatHistory <History>k__BackingField;
    [CompilerGeneratedAttribute]
private IHistoryTransform <HistoryTransform>k__BackingField;
    [CompilerGeneratedAttribute]
private List`1<ITextTransform> <InputTransformPipeline>k__BackingField;
    public ITextStreamTransform OutputTransform;
    public ILLamaExecutor Executor { get; private set; }
    public ChatHistory History { get; private set; }
    public IHistoryTransform HistoryTransform { get; public set; }
    public List`1<ITextTransform> InputTransformPipeline { get; public set; }
    public ChatSession(ILLamaExecutor executor);
    public ChatSession(ILLamaExecutor executor, ChatHistory history);
    [CompilerGeneratedAttribute]
public ILLamaExecutor get_Executor();
    [CompilerGeneratedAttribute]
private void set_Executor(ILLamaExecutor value);
    [CompilerGeneratedAttribute]
public ChatHistory get_History();
    [CompilerGeneratedAttribute]
private void set_History(ChatHistory value);
    [CompilerGeneratedAttribute]
public IHistoryTransform get_HistoryTransform();
    [CompilerGeneratedAttribute]
public void set_HistoryTransform(IHistoryTransform value);
    [CompilerGeneratedAttribute]
public List`1<ITextTransform> get_InputTransformPipeline();
    [CompilerGeneratedAttribute]
public void set_InputTransformPipeline(List`1<ITextTransform> value);
    [AsyncStateMachineAttribute("LLama.ChatSession/<InitializeSessionFromHistoryAsync>d__23")]
public static Task`1<ChatSession> InitializeSessionFromHistoryAsync(ILLamaExecutor executor, ChatHistory history, IHistoryTransform transform);
    public ChatSession WithHistoryTransform(IHistoryTransform transform);
    public ChatSession AddInputTransform(ITextTransform transform);
    public ChatSession WithOutputTransform(ITextStreamTransform transform);
    public void SaveSession(string path);
    public SessionState GetSessionState();
    public void LoadSession(SessionState state, bool loadTransforms);
    public void LoadSession(string path, bool loadTransforms);
    public ChatSession AddMessage(Message message);
    public ChatSession AddSystemMessage(string content);
    public ChatSession AddAssistantMessage(string content);
    public ChatSession AddUserMessage(string content);
    public ChatSession RemoveLastMessage();
    [AsyncStateMachineAttribute("LLama.ChatSession/<AddAndProcessMessage>d__38")]
public Task`1<ChatSession> AddAndProcessMessage(Message message);
    public Task`1<ChatSession> AddAndProcessSystemMessage(string content);
    public Task`1<ChatSession> AddAndProcessUserMessage(string content);
    public Task`1<ChatSession> AddAndProcessAssistantMessage(string content);
    public ChatSession ReplaceUserMessage(Message oldMessage, Message newMessage);
    [AsyncIteratorStateMachineAttribute("LLama.ChatSession/<ChatAsync>d__43")]
public IAsyncEnumerable`1<string> ChatAsync(Message message, bool applyInputTransformPipeline, IInferenceParams inferenceParams, CancellationToken cancellationToken);
    public IAsyncEnumerable`1<string> ChatAsync(Message message, IInferenceParams inferenceParams, CancellationToken cancellationToken);
    public IAsyncEnumerable`1<string> ChatAsync(ChatHistory history, bool applyInputTransformPipeline, IInferenceParams inferenceParams, CancellationToken cancellationToken);
    public IAsyncEnumerable`1<string> ChatAsync(ChatHistory history, IInferenceParams inferenceParams, CancellationToken cancellationToken);
    [AsyncIteratorStateMachineAttribute("LLama.ChatSession/<RegenerateAssistantMessageAsync>d__47")]
public IAsyncEnumerable`1<string> RegenerateAssistantMessageAsync(InferenceParams inferenceParams, CancellationToken cancellationToken);
    [AsyncIteratorStateMachineAttribute("LLama.ChatSession/<ChatAsyncInternal>d__48")]
private IAsyncEnumerable`1<string> ChatAsyncInternal(string prompt, IInferenceParams inferenceParams, CancellationToken cancellationToken);
}
public enum LLama.Common.AuthorRole : Enum {
    public int value__;
    public static AuthorRole Unknown;
    public static AuthorRole System;
    public static AuthorRole User;
    public static AuthorRole Assistant;
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Common.ChatHistory : object {
    private static JsonSerializerOptions _jsonOptions;
    [CompilerGeneratedAttribute]
private List`1<Message> <Messages>k__BackingField;
    [JsonPropertyNameAttribute("messages")]
public List`1<Message> Messages { get; public set; }
    public ChatHistory(Message[] messageHistory);
    private static ChatHistory();
    [CompilerGeneratedAttribute]
public List`1<Message> get_Messages();
    [CompilerGeneratedAttribute]
public void set_Messages(List`1<Message> value);
    public void AddMessage(AuthorRole authorRole, string content);
    public string ToJson();
    public static ChatHistory FromJson(string json);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[DefaultMemberAttribute("Item")]
public class LLama.Common.FixedSizeQueue`1 : object {
    private List`1<T> _storage;
    [CompilerGeneratedAttribute]
private int <Capacity>k__BackingField;
    public T Item { get; }
    public int Count { get; }
    public int Capacity { get; }
    public FixedSizeQueue`1(int size);
    public FixedSizeQueue`1(int size, IEnumerable`1<T> data);
    public sealed virtual T get_Item(int index);
    public sealed virtual int get_Count();
    [CompilerGeneratedAttribute]
public int get_Capacity();
    public void Enqueue(T item);
    public sealed virtual IEnumerator`1<T> GetEnumerator();
    private sealed virtual override IEnumerator System.Collections.IEnumerable.GetEnumerator();
    internal ReadOnlySpan`1<T> AsSpan(int count);
}
[NullableContextAttribute("2")]
[NullableAttribute("0")]
public class LLama.Common.InferenceParams : object {
    [CompilerGeneratedAttribute]
private int <TokensKeep>k__BackingField;
    [CompilerGeneratedAttribute]
private int <MaxTokens>k__BackingField;
    [CompilerGeneratedAttribute]
private Dictionary`2<LLamaToken, float> <LogitBias>k__BackingField;
    [NullableAttribute("1")]
[CompilerGeneratedAttribute]
private IReadOnlyList`1<string> <AntiPrompts>k__BackingField;
    [CompilerGeneratedAttribute]
private int <TopK>k__BackingField;
    [CompilerGeneratedAttribute]
private float <TopP>k__BackingField;
    [CompilerGeneratedAttribute]
private float <MinP>k__BackingField;
    [CompilerGeneratedAttribute]
private float <TfsZ>k__BackingField;
    [CompilerGeneratedAttribute]
private float <TypicalP>k__BackingField;
    [CompilerGeneratedAttribute]
private float <Temperature>k__BackingField;
    [CompilerGeneratedAttribute]
private float <RepeatPenalty>k__BackingField;
    [CompilerGeneratedAttribute]
private int <RepeatLastTokensCount>k__BackingField;
    [CompilerGeneratedAttribute]
private float <FrequencyPenalty>k__BackingField;
    [CompilerGeneratedAttribute]
private float <PresencePenalty>k__BackingField;
    [CompilerGeneratedAttribute]
private MirostatType <Mirostat>k__BackingField;
    [CompilerGeneratedAttribute]
private float <MirostatTau>k__BackingField;
    [CompilerGeneratedAttribute]
private float <MirostatEta>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <PenalizeNL>k__BackingField;
    [CompilerGeneratedAttribute]
private SafeLLamaGrammarHandle <Grammar>k__BackingField;
    [CompilerGeneratedAttribute]
private ISamplingPipeline <SamplingPipeline>k__BackingField;
    [NullableAttribute("1")]
[CompilerGeneratedAttribute]
protected Type EqualityContract { get; }
    public int TokensKeep { get; public set; }
    public int MaxTokens { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public Dictionary`2<LLamaToken, float> LogitBias { get; public set; }
    [NullableAttribute("1")]
public IReadOnlyList`1<string> AntiPrompts { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public int TopK { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float TopP { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float MinP { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float TfsZ { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float TypicalP { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float Temperature { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float RepeatPenalty { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public int RepeatLastTokensCount { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float FrequencyPenalty { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public float PresencePenalty { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. MirostatSamplingPipeline or Mirostat2SamplingPipeline")]
public MirostatType Mirostat { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. MirostatSamplingPipeline or Mirostat2SamplingPipeline")]
public float MirostatTau { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. MirostatSamplingPipeline or Mirostat2SamplingPipeline")]
public float MirostatEta { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public bool PenalizeNL { get; public set; }
    [ObsoleteAttribute("Use the SamplingPipeline property instead with a configured pipeline e.g. DefaultSamplingPipeline")]
public SafeLLamaGrammarHandle Grammar { get; public set; }
    public ISamplingPipeline SamplingPipeline { get; public set; }
    [CompilerGeneratedAttribute]
protected InferenceParams(InferenceParams original);
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
protected virtual Type get_EqualityContract();
    [CompilerGeneratedAttribute]
public sealed virtual int get_TokensKeep();
    [CompilerGeneratedAttribute]
public sealed virtual void set_TokensKeep(int value);
    [CompilerGeneratedAttribute]
public sealed virtual int get_MaxTokens();
    [CompilerGeneratedAttribute]
public sealed virtual void set_MaxTokens(int value);
    [CompilerGeneratedAttribute]
public sealed virtual Dictionary`2<LLamaToken, float> get_LogitBias();
    [CompilerGeneratedAttribute]
public sealed virtual void set_LogitBias(Dictionary`2<LLamaToken, float> value);
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
public sealed virtual IReadOnlyList`1<string> get_AntiPrompts();
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
public sealed virtual void set_AntiPrompts(IReadOnlyList`1<string> value);
    [CompilerGeneratedAttribute]
public sealed virtual int get_TopK();
    [CompilerGeneratedAttribute]
public sealed virtual void set_TopK(int value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_TopP();
    [CompilerGeneratedAttribute]
public sealed virtual void set_TopP(float value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_MinP();
    [CompilerGeneratedAttribute]
public sealed virtual void set_MinP(float value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_TfsZ();
    [CompilerGeneratedAttribute]
public sealed virtual void set_TfsZ(float value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_TypicalP();
    [CompilerGeneratedAttribute]
public sealed virtual void set_TypicalP(float value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_Temperature();
    [CompilerGeneratedAttribute]
public sealed virtual void set_Temperature(float value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_RepeatPenalty();
    [CompilerGeneratedAttribute]
public sealed virtual void set_RepeatPenalty(float value);
    [CompilerGeneratedAttribute]
public sealed virtual int get_RepeatLastTokensCount();
    [CompilerGeneratedAttribute]
public sealed virtual void set_RepeatLastTokensCount(int value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_FrequencyPenalty();
    [CompilerGeneratedAttribute]
public sealed virtual void set_FrequencyPenalty(float value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_PresencePenalty();
    [CompilerGeneratedAttribute]
public sealed virtual void set_PresencePenalty(float value);
    [CompilerGeneratedAttribute]
public sealed virtual MirostatType get_Mirostat();
    [CompilerGeneratedAttribute]
public sealed virtual void set_Mirostat(MirostatType value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_MirostatTau();
    [CompilerGeneratedAttribute]
public sealed virtual void set_MirostatTau(float value);
    [CompilerGeneratedAttribute]
public sealed virtual float get_MirostatEta();
    [CompilerGeneratedAttribute]
public sealed virtual void set_MirostatEta(float value);
    [CompilerGeneratedAttribute]
public sealed virtual bool get_PenalizeNL();
    [CompilerGeneratedAttribute]
public sealed virtual void set_PenalizeNL(bool value);
    [CompilerGeneratedAttribute]
public sealed virtual SafeLLamaGrammarHandle get_Grammar();
    [CompilerGeneratedAttribute]
public sealed virtual void set_Grammar(SafeLLamaGrammarHandle value);
    [CompilerGeneratedAttribute]
public sealed virtual ISamplingPipeline get_SamplingPipeline();
    [CompilerGeneratedAttribute]
public sealed virtual void set_SamplingPipeline(ISamplingPipeline value);
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
public virtual string ToString();
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
protected virtual bool PrintMembers(StringBuilder builder);
    [CompilerGeneratedAttribute]
public static bool op_Inequality(InferenceParams left, InferenceParams right);
    [CompilerGeneratedAttribute]
public static bool op_Equality(InferenceParams left, InferenceParams right);
    [CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [CompilerGeneratedAttribute]
public virtual bool Equals(InferenceParams other);
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
public virtual InferenceParams <Clone>$();
}
public enum LLama.Common.MirostatType : Enum {
    public int value__;
    public static MirostatType Disable;
    public static MirostatType Mirostat;
    public static MirostatType Mirostat2;
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Common.ModelParams : object {
    [CompilerGeneratedAttribute]
private Nullable`1<UInt32> <ContextSize>k__BackingField;
    [CompilerGeneratedAttribute]
private int <MainGpu>k__BackingField;
    [CompilerGeneratedAttribute]
private GPUSplitMode <SplitMode>k__BackingField;
    [CompilerGeneratedAttribute]
private int <GpuLayerCount>k__BackingField;
    [CompilerGeneratedAttribute]
private UInt32 <SeqMax>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<UInt32> <Seed>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <UseMemorymap>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <UseMemoryLock>k__BackingField;
    [CompilerGeneratedAttribute]
private string <ModelPath>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<UInt32> <Threads>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<UInt32> <BatchThreads>k__BackingField;
    [CompilerGeneratedAttribute]
private UInt32 <BatchSize>k__BackingField;
    [CompilerGeneratedAttribute]
private UInt32 <UBatchSize>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <Embeddings>k__BackingField;
    [CompilerGeneratedAttribute]
private TensorSplitsCollection <TensorSplits>k__BackingField;
    [CompilerGeneratedAttribute]
private List`1<MetadataOverride> <MetadataOverrides>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<float> <RopeFrequencyBase>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<float> <RopeFrequencyScale>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<float> <YarnExtrapolationFactor>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<float> <YarnAttentionFactor>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<float> <YarnBetaFast>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<float> <YarnBetaSlow>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<UInt32> <YarnOriginalContext>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<RopeScalingType> <YarnScalingType>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<GGMLType> <TypeK>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<GGMLType> <TypeV>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <NoKqvOffload>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <FlashAttention>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<float> <DefragThreshold>k__BackingField;
    [CompilerGeneratedAttribute]
private LLamaPoolingType <PoolingType>k__BackingField;
    [CompilerGeneratedAttribute]
private LLamaAttentionType <AttentionType>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <VocabOnly>k__BackingField;
    [CompilerGeneratedAttribute]
private string <EncodingName>k__BackingField;
    [CompilerGeneratedAttribute]
protected Type EqualityContract { get; }
    public Nullable`1<UInt32> ContextSize { get; public set; }
    public int MainGpu { get; public set; }
    public GPUSplitMode SplitMode { get; public set; }
    public int GpuLayerCount { get; public set; }
    public UInt32 SeqMax { get; public set; }
    public Nullable`1<UInt32> Seed { get; public set; }
    public bool UseMemorymap { get; public set; }
    public bool UseMemoryLock { get; public set; }
    public string ModelPath { get; public set; }
    public Nullable`1<UInt32> Threads { get; public set; }
    public Nullable`1<UInt32> BatchThreads { get; public set; }
    public UInt32 BatchSize { get; public set; }
    public UInt32 UBatchSize { get; public set; }
    public bool Embeddings { get; public set; }
    public TensorSplitsCollection TensorSplits { get; public set; }
    public List`1<MetadataOverride> MetadataOverrides { get; public set; }
    public Nullable`1<float> RopeFrequencyBase { get; public set; }
    public Nullable`1<float> RopeFrequencyScale { get; public set; }
    public Nullable`1<float> YarnExtrapolationFactor { get; public set; }
    public Nullable`1<float> YarnAttentionFactor { get; public set; }
    public Nullable`1<float> YarnBetaFast { get; public set; }
    public Nullable`1<float> YarnBetaSlow { get; public set; }
    public Nullable`1<UInt32> YarnOriginalContext { get; public set; }
    public Nullable`1<RopeScalingType> YarnScalingType { get; public set; }
    public Nullable`1<GGMLType> TypeK { get; public set; }
    public Nullable`1<GGMLType> TypeV { get; public set; }
    public bool NoKqvOffload { get; public set; }
    public bool FlashAttention { get; public set; }
    public Nullable`1<float> DefragThreshold { get; public set; }
    public LLamaPoolingType PoolingType { get; public set; }
    public LLamaAttentionType AttentionType { get; public set; }
    public bool VocabOnly { get; public set; }
    [JsonPropertyNameAttribute("Encoding")]
[JsonIncludeAttribute]
private string EncodingName { get; private set; }
    [JsonIgnoreAttribute]
public Encoding Encoding { get; public set; }
    [JsonConstructorAttribute]
public ModelParams(string modelPath);
    [CompilerGeneratedAttribute]
protected ModelParams(ModelParams original);
    [CompilerGeneratedAttribute]
protected virtual Type get_EqualityContract();
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<UInt32> get_ContextSize();
    [CompilerGeneratedAttribute]
public void set_ContextSize(Nullable`1<UInt32> value);
    [CompilerGeneratedAttribute]
public sealed virtual int get_MainGpu();
    [CompilerGeneratedAttribute]
public sealed virtual void set_MainGpu(int value);
    [CompilerGeneratedAttribute]
public sealed virtual GPUSplitMode get_SplitMode();
    [CompilerGeneratedAttribute]
public void set_SplitMode(GPUSplitMode value);
    [CompilerGeneratedAttribute]
public sealed virtual int get_GpuLayerCount();
    [CompilerGeneratedAttribute]
public void set_GpuLayerCount(int value);
    [CompilerGeneratedAttribute]
public sealed virtual UInt32 get_SeqMax();
    [CompilerGeneratedAttribute]
public void set_SeqMax(UInt32 value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<UInt32> get_Seed();
    [CompilerGeneratedAttribute]
public void set_Seed(Nullable`1<UInt32> value);
    [CompilerGeneratedAttribute]
public sealed virtual bool get_UseMemorymap();
    [CompilerGeneratedAttribute]
public void set_UseMemorymap(bool value);
    [CompilerGeneratedAttribute]
public sealed virtual bool get_UseMemoryLock();
    [CompilerGeneratedAttribute]
public void set_UseMemoryLock(bool value);
    [CompilerGeneratedAttribute]
public sealed virtual string get_ModelPath();
    [CompilerGeneratedAttribute]
public void set_ModelPath(string value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<UInt32> get_Threads();
    [CompilerGeneratedAttribute]
public void set_Threads(Nullable`1<UInt32> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<UInt32> get_BatchThreads();
    [CompilerGeneratedAttribute]
public void set_BatchThreads(Nullable`1<UInt32> value);
    [CompilerGeneratedAttribute]
public sealed virtual UInt32 get_BatchSize();
    [CompilerGeneratedAttribute]
public void set_BatchSize(UInt32 value);
    [CompilerGeneratedAttribute]
public sealed virtual UInt32 get_UBatchSize();
    [CompilerGeneratedAttribute]
public void set_UBatchSize(UInt32 value);
    [CompilerGeneratedAttribute]
public sealed virtual bool get_Embeddings();
    [CompilerGeneratedAttribute]
public void set_Embeddings(bool value);
    [CompilerGeneratedAttribute]
public sealed virtual TensorSplitsCollection get_TensorSplits();
    [CompilerGeneratedAttribute]
public void set_TensorSplits(TensorSplitsCollection value);
    [CompilerGeneratedAttribute]
public sealed virtual List`1<MetadataOverride> get_MetadataOverrides();
    [CompilerGeneratedAttribute]
public void set_MetadataOverrides(List`1<MetadataOverride> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<float> get_RopeFrequencyBase();
    [CompilerGeneratedAttribute]
public void set_RopeFrequencyBase(Nullable`1<float> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<float> get_RopeFrequencyScale();
    [CompilerGeneratedAttribute]
public void set_RopeFrequencyScale(Nullable`1<float> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<float> get_YarnExtrapolationFactor();
    [CompilerGeneratedAttribute]
public void set_YarnExtrapolationFactor(Nullable`1<float> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<float> get_YarnAttentionFactor();
    [CompilerGeneratedAttribute]
public void set_YarnAttentionFactor(Nullable`1<float> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<float> get_YarnBetaFast();
    [CompilerGeneratedAttribute]
public void set_YarnBetaFast(Nullable`1<float> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<float> get_YarnBetaSlow();
    [CompilerGeneratedAttribute]
public void set_YarnBetaSlow(Nullable`1<float> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<UInt32> get_YarnOriginalContext();
    [CompilerGeneratedAttribute]
public void set_YarnOriginalContext(Nullable`1<UInt32> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<RopeScalingType> get_YarnScalingType();
    [CompilerGeneratedAttribute]
public void set_YarnScalingType(Nullable`1<RopeScalingType> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<GGMLType> get_TypeK();
    [CompilerGeneratedAttribute]
public void set_TypeK(Nullable`1<GGMLType> value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<GGMLType> get_TypeV();
    [CompilerGeneratedAttribute]
public void set_TypeV(Nullable`1<GGMLType> value);
    [CompilerGeneratedAttribute]
public sealed virtual bool get_NoKqvOffload();
    [CompilerGeneratedAttribute]
public void set_NoKqvOffload(bool value);
    [CompilerGeneratedAttribute]
public sealed virtual bool get_FlashAttention();
    [CompilerGeneratedAttribute]
public void set_FlashAttention(bool value);
    [CompilerGeneratedAttribute]
public sealed virtual Nullable`1<float> get_DefragThreshold();
    [CompilerGeneratedAttribute]
public void set_DefragThreshold(Nullable`1<float> value);
    [CompilerGeneratedAttribute]
public sealed virtual LLamaPoolingType get_PoolingType();
    [CompilerGeneratedAttribute]
public void set_PoolingType(LLamaPoolingType value);
    [CompilerGeneratedAttribute]
public sealed virtual LLamaAttentionType get_AttentionType();
    [CompilerGeneratedAttribute]
public void set_AttentionType(LLamaAttentionType value);
    [CompilerGeneratedAttribute]
public sealed virtual bool get_VocabOnly();
    [CompilerGeneratedAttribute]
public void set_VocabOnly(bool value);
    [CompilerGeneratedAttribute]
private string get_EncodingName();
    [CompilerGeneratedAttribute]
private void set_EncodingName(string value);
    public sealed virtual Encoding get_Encoding();
    public void set_Encoding(Encoding value);
    [CompilerGeneratedAttribute]
public virtual string ToString();
    [CompilerGeneratedAttribute]
protected virtual bool PrintMembers(StringBuilder builder);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Inequality(ModelParams left, ModelParams right);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Equality(ModelParams left, ModelParams right);
    [CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public virtual bool Equals(ModelParams other);
    [CompilerGeneratedAttribute]
public virtual ModelParams <Clone>$();
}
[NullableContextAttribute("1")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
internal class LLama.Common.PolymorphicJSONConverter`1 : JsonConverter`1<T> {
    public virtual T Read(Utf8JsonReader& reader, Type typeToConvert, JsonSerializerOptions options);
    public virtual void Write(Utf8JsonWriter writer, T value, JsonSerializerOptions options);
}
public class LLama.Exceptions.GrammarExpectedName : GrammarFormatException {
    [NullableContextAttribute("1")]
internal GrammarExpectedName(string source);
}
public class LLama.Exceptions.GrammarExpectedNext : GrammarFormatException {
    [NullableContextAttribute("1")]
internal GrammarExpectedNext(string expected, string source);
}
public class LLama.Exceptions.GrammarExpectedPrevious : GrammarFormatException {
    [NullableContextAttribute("1")]
internal GrammarExpectedPrevious(string expected, string source);
}
public abstract class LLama.Exceptions.GrammarFormatException : Exception {
    [NullableContextAttribute("1")]
internal GrammarFormatException(string message);
}
public class LLama.Exceptions.GrammarUnexpectedCharAltElement : GrammarFormatException {
    [NullableContextAttribute("1")]
internal GrammarUnexpectedCharAltElement(string ruleId, int index);
}
public class LLama.Exceptions.GrammarUnexpectedCharRngElement : GrammarFormatException {
    [NullableContextAttribute("1")]
internal GrammarUnexpectedCharRngElement(string ruleId, int index);
}
public class LLama.Exceptions.GrammarUnexpectedEndElement : GrammarFormatException {
    [NullableContextAttribute("1")]
internal GrammarUnexpectedEndElement(string ruleId, int index);
}
public class LLama.Exceptions.GrammarUnexpectedEndOfInput : GrammarFormatException {
}
public class LLama.Exceptions.GrammarUnexpectedHexCharsCount : GrammarFormatException {
    [NullableContextAttribute("1")]
internal GrammarUnexpectedHexCharsCount(int size, string source);
}
public class LLama.Exceptions.GrammarUnknownEscapeCharacter : GrammarFormatException {
    [NullableContextAttribute("1")]
internal GrammarUnknownEscapeCharacter(string source);
}
public class LLama.Exceptions.LLamaDecodeError : RuntimeError {
    [CompilerGeneratedAttribute]
private DecodeResult <ReturnCode>k__BackingField;
    public DecodeResult ReturnCode { get; }
    public LLamaDecodeError(DecodeResult returnCode);
    [CompilerGeneratedAttribute]
public DecodeResult get_ReturnCode();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Exceptions.LoadWeightsFailedException : RuntimeError {
    [CompilerGeneratedAttribute]
private string <ModelPath>k__BackingField;
    public string ModelPath { get; }
    public LoadWeightsFailedException(string modelPath);
    [CompilerGeneratedAttribute]
public string get_ModelPath();
}
public class LLama.Exceptions.RuntimeError : Exception {
    [NullableContextAttribute("1")]
public RuntimeError(string message);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
internal static class LLama.Extensions.DictionaryExtensions : object {
    [ExtensionAttribute]
public static TValue GetValueOrDefault(IReadOnlyDictionary`2<TKey, TValue> dictionary, TKey key, TValue defaultValue);
    internal static TValue GetValueOrDefaultImpl(IReadOnlyDictionary`2<TKey, TValue> dictionary, TKey key, TValue defaultValue);
    [ExtensionAttribute]
internal static void CopyTo(IReadOnlyDictionary`2<TKey, TValue> source, IDictionary`2<TKey, TValue> dest);
}
[ExtensionAttribute]
internal static class LLama.Extensions.EncodingExtensions : object {
    [ExtensionAttribute]
public static int GetBytes(Encoding encoding, ReadOnlySpan`1<char> chars, Span`1<byte> output);
    [ExtensionAttribute]
public static int GetChars(Encoding encoding, ReadOnlySpan`1<byte> bytes, Span`1<char> output);
    [ExtensionAttribute]
public static int GetCharCount(Encoding encoding, ReadOnlySpan`1<byte> bytes);
    internal static int GetBytesImpl(Encoding encoding, ReadOnlySpan`1<char> chars, Span`1<byte> output);
    internal static int GetCharsImpl(Encoding encoding, ReadOnlySpan`1<byte> bytes, Span`1<char> output);
    internal static int GetCharCountImpl(Encoding encoding, ReadOnlySpan`1<byte> bytes);
    [NullableContextAttribute("1")]
[ExtensionAttribute]
internal static string GetStringFromSpan(Encoding encoding, ReadOnlySpan`1<byte> bytes);
}
[ExtensionAttribute]
public static class LLama.Extensions.IContextParamsExtensions : object {
    [NullableContextAttribute("1")]
[ExtensionAttribute]
public static void ToLlamaContextParams(IContextParams params, LLamaContextParams& result);
    private static UInt32 Threads(Nullable`1<UInt32> value);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
internal static class LLama.Extensions.IEnumerableExtensions : object {
    [ExtensionAttribute]
public static IEnumerable`1<T> TakeLast(IEnumerable`1<T> source, int count);
    internal static IEnumerable`1<T> TakeLastImpl(IEnumerable`1<T> source, int count);
}
[ExtensionAttribute]
public static class LLama.Extensions.IModelParamsExtensions : object {
    [NullableContextAttribute("1")]
[ExtensionAttribute]
public static IDisposable ToLlamaModelParams(IModelParams params, LLamaModelParams& result);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
internal static class LLama.Extensions.IReadOnlyListExtensions : object {
    [ExtensionAttribute]
public static Nullable`1<int> IndexOf(IReadOnlyList`1<T> list, T item);
    [ExtensionAttribute]
[ObsoleteAttribute("Use an Antiprompt processor instead")]
internal static bool TokensEndsWithAnyString(TTokens tokens, TQueries queries, SafeLlamaModelHandle model, Encoding encoding);
    [ExtensionAttribute]
[ObsoleteAttribute("Use an Antiprompt processor instead")]
internal static bool TokensEndsWithAnyString(TTokens tokens, IList`1<string> queries, SafeLlamaModelHandle model, Encoding encoding);
}
[ExtensionAttribute]
internal static class LLama.Extensions.KeyValuePairExtensions : object {
    [NullableContextAttribute("1")]
[ExtensionAttribute]
public static void Deconstruct(KeyValuePair`2<TKey, TValue> pair, TKey& first, TValue& second);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
internal static class LLama.Extensions.ListExtensions : object {
    [ExtensionAttribute]
public static void EnsureCapacity(List`1<T> list, int capacity);
    [ExtensionAttribute]
public static void AddSpan(List`1<T> list, ReadOnlySpan`1<T> items);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
internal static class LLama.Extensions.ProcessExtensions : object {
    [ExtensionAttribute]
public static void SafeKill(Process process, bool entireProcessTree);
    [ExtensionAttribute]
public static ValueTuple`4<int, string, string, bool> SafeRun(Process process, TimeSpan timeout);
}
internal class LLama.Grammars.GBNFGrammarParser : object {
    private static UInt32 DecodeUTF8(ReadOnlySpan`1& src);
    private static bool IsWordChar(byte c);
    private static UInt32 ParseHex(ReadOnlySpan`1& src, int size);
    private static ReadOnlySpan`1<byte> ParseSpace(ReadOnlySpan`1<byte> src, bool newlineOk);
    private static ReadOnlySpan`1<byte> ParseName(ReadOnlySpan`1<byte> src);
    private static UInt32 ParseChar(ReadOnlySpan`1& src);
    [NullableContextAttribute("1")]
private ReadOnlySpan`1<byte> ParseSequence(ParseState state, ReadOnlySpan`1<byte> pos, string ruleName, List`1<LLamaGrammarElement> outElements, bool isNested);
    private ReadOnlySpan`1<byte> ParseAlternates(ParseState state, ReadOnlySpan`1<byte> src, string ruleName, UInt32 ruleId, bool isNested);
    private ReadOnlySpan`1<byte> ParseRule(ParseState state, ReadOnlySpan`1<byte> src);
    [NullableContextAttribute("1")]
public Grammar Parse(string input, string startRule);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Grammars.Grammar : object {
    [CompilerGeneratedAttribute]
private ulong <StartRuleIndex>k__BackingField;
    [CompilerGeneratedAttribute]
private IReadOnlyList`1<GrammarRule> <Rules>k__BackingField;
    public ulong StartRuleIndex { get; }
    public IReadOnlyList`1<GrammarRule> Rules { get; }
    public Grammar(IReadOnlyList`1<GrammarRule> rules, ulong startRuleIndex);
    [CompilerGeneratedAttribute]
public ulong get_StartRuleIndex();
    [CompilerGeneratedAttribute]
public IReadOnlyList`1<GrammarRule> get_Rules();
    public SafeLLamaGrammarHandle CreateInstance();
    public static Grammar Parse(string gbnf, string startRule);
    public virtual string ToString();
    private void PrintGrammar(StringBuilder output);
    private void PrintRule(StringBuilder output, GrammarRule rule);
    private static void PrintGrammarChar(StringBuilder output, UInt32 c);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Grammars.GrammarRule : object {
    [CompilerGeneratedAttribute]
private string <Name>k__BackingField;
    [CompilerGeneratedAttribute]
private IReadOnlyList`1<LLamaGrammarElement> <Elements>k__BackingField;
    [CompilerGeneratedAttribute]
private Type EqualityContract { get; }
    public string Name { get; }
    public IReadOnlyList`1<LLamaGrammarElement> Elements { get; }
    public GrammarRule(string name, IReadOnlyList`1<LLamaGrammarElement> elements);
    [CompilerGeneratedAttribute]
private GrammarRule(GrammarRule original);
    [CompilerGeneratedAttribute]
private Type get_EqualityContract();
    [CompilerGeneratedAttribute]
public string get_Name();
    [CompilerGeneratedAttribute]
public IReadOnlyList`1<LLamaGrammarElement> get_Elements();
    private static void Validate(IReadOnlyList`1<LLamaGrammarElement> elements, string name);
    [CompilerGeneratedAttribute]
public virtual string ToString();
    [CompilerGeneratedAttribute]
private bool PrintMembers(StringBuilder builder);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Inequality(GrammarRule left, GrammarRule right);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Equality(GrammarRule left, GrammarRule right);
    [CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public sealed virtual bool Equals(GrammarRule other);
    [CompilerGeneratedAttribute]
public GrammarRule <Clone>$();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.InstructExecutor : StatefulExecutorBase {
    private bool _is_prompt_run;
    private string _instructionPrefix;
    private LLamaToken[] _inp_pfx;
    private LLamaToken[] _inp_sfx;
    [NullableAttribute("2")]
private ISamplingPipeline _pipeline;
    public InstructExecutor(LLamaContext context, string instructionPrefix, string instructionSuffix, ILogger logger);
    public virtual ExecutorBaseState GetStateData();
    public virtual Task LoadState(ExecutorBaseState data);
    [AsyncStateMachineAttribute("LLama.InstructExecutor/<SaveState>d__8")]
public virtual Task SaveState(string filename);
    [AsyncStateMachineAttribute("LLama.InstructExecutor/<LoadState>d__9")]
public virtual Task LoadState(string filename);
    protected virtual Task`1<bool> GetLoopCondition(InferStateArgs args);
    protected virtual Task PreprocessInputs(string text, InferStateArgs args);
    [AsyncStateMachineAttribute("LLama.InstructExecutor/<PostProcess>d__12")]
protected virtual Task`1<ValueTuple`2<bool, IReadOnlyList`1<string>>> PostProcess(IInferenceParams inferenceParams, InferStateArgs args);
    [AsyncStateMachineAttribute("LLama.InstructExecutor/<InferInternal>d__13")]
protected virtual Task InferInternal(IInferenceParams inferenceParams, InferStateArgs args);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.InteractiveExecutor : StatefulExecutorBase {
    private bool _is_prompt_run;
    private int _EmbedImagePosition;
    private List`1<SafeLlavaImageEmbedHandle> _imageEmbedHandles;
    private bool _imageInPrompt;
    [NullableAttribute("2")]
private ISamplingPipeline _pipeline;
    public InteractiveExecutor(LLamaContext context, ILogger logger);
    public InteractiveExecutor(LLamaContext context, LLavaWeights clipModel, ILogger logger);
    public virtual ExecutorBaseState GetStateData();
    public virtual Task LoadState(ExecutorBaseState data);
    [AsyncStateMachineAttribute("LLama.InteractiveExecutor/<SaveState>d__9")]
public virtual Task SaveState(string filename);
    [AsyncStateMachineAttribute("LLama.InteractiveExecutor/<LoadState>d__10")]
public virtual Task LoadState(string filename);
    protected virtual Task`1<bool> GetLoopCondition(InferStateArgs args);
    protected virtual Task PreprocessInputs(string text, InferStateArgs args);
    private Task PreprocessLlava(string text, InferStateArgs args, bool addBos);
    [AsyncStateMachineAttribute("LLama.InteractiveExecutor/<PostProcess>d__14")]
protected virtual Task`1<ValueTuple`2<bool, IReadOnlyList`1<string>>> PostProcess(IInferenceParams inferenceParams, InferStateArgs args);
    [AsyncStateMachineAttribute("LLama.InteractiveExecutor/<InferInternal>d__15")]
protected virtual Task InferInternal(IInferenceParams inferenceParams, InferStateArgs args);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.LLamaContext : object {
    [NullableAttribute("2")]
private ILogger _logger;
    [CompilerGeneratedAttribute]
private IContextParams <Params>k__BackingField;
    [CompilerGeneratedAttribute]
private SafeLLamaContextHandle <NativeHandle>k__BackingField;
    [CompilerGeneratedAttribute]
private Encoding <Encoding>k__BackingField;
    [CompilerGeneratedAttribute]
private ModelTokens <Tokens>k__BackingField;
    public int VocabCount { get; }
    public UInt32 ContextSize { get; }
    public int EmbeddingSize { get; }
    public IContextParams Params { get; }
    public SafeLLamaContextHandle NativeHandle { get; }
    public Encoding Encoding { get; }
    public UInt32 GenerationThreads { get; public set; }
    public UInt32 BatchThreads { get; public set; }
    public UInt32 BatchSize { get; }
    public ModelTokens Tokens { get; }
    public LLamaContext(LLamaWeights model, IContextParams params, ILogger logger);
    public int get_VocabCount();
    public UInt32 get_ContextSize();
    public int get_EmbeddingSize();
    [CompilerGeneratedAttribute]
public IContextParams get_Params();
    [CompilerGeneratedAttribute]
public SafeLLamaContextHandle get_NativeHandle();
    [CompilerGeneratedAttribute]
public Encoding get_Encoding();
    public UInt32 get_GenerationThreads();
    public void set_GenerationThreads(UInt32 value);
    public UInt32 get_BatchThreads();
    public void set_BatchThreads(UInt32 value);
    public UInt32 get_BatchSize();
    [CompilerGeneratedAttribute]
public ModelTokens get_Tokens();
    public void SetSeed(UInt32 seed);
    public LLamaToken[] Tokenize(string text, bool addBos, bool special);
    [ObsoleteAttribute("Use a `StreamingTokenDecoder` instead")]
public string DeTokenize(IReadOnlyList`1<LLamaToken> tokens);
    public void SaveState(string filename);
    public void SaveState(string filename, LLamaSeqId sequence);
    public State GetState();
    public SequenceState GetState(LLamaSeqId sequence);
    public void LoadState(string filename);
    public void LoadState(string filename, LLamaSeqId sequence);
    public void LoadState(State state);
    public void LoadState(SequenceState state, LLamaSeqId sequence);
    public bool ShouldAddBosToken();
    public DecodeResult Decode(LLamaBatch batch);
    public Task`1<DecodeResult> DecodeAsync(LLamaBatch batch, CancellationToken cancellationToken);
    public DecodeResult Decode(LLamaBatchEmbeddings batch);
    public Task`1<DecodeResult> DecodeAsync(LLamaBatchEmbeddings batch, CancellationToken cancellationToken);
    public Task`1<ValueTuple`3<DecodeResult, int, int>> DecodeAsync(List`1<LLamaToken> tokens, LLamaSeqId id, LLamaBatch batch, int n_past);
    public sealed virtual void Dispose();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.LLamaEmbedder : object {
    [CompilerGeneratedAttribute]
private LLamaContext <Context>k__BackingField;
    public int EmbeddingSize { get; }
    public LLamaContext Context { get; }
    public LLamaEmbedder(LLamaWeights weights, IContextParams params, ILogger logger);
    public int get_EmbeddingSize();
    [CompilerGeneratedAttribute]
public LLamaContext get_Context();
    public Task`1<Single[]> GetEmbeddings(string text, CancellationToken cancellationToken);
    [AsyncStateMachineAttribute("LLama.LLamaEmbedder/<GetEmbeddings>d__7")]
public Task`1<Single[]> GetEmbeddings(string text, bool addBos, CancellationToken cancellationToken);
    private Single[] GetEmbeddingsArray();
    [NullableContextAttribute("0")]
private static void Normalize(Span`1<float> embeddings);
    public sealed virtual void Dispose();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public static class LLama.LLamaQuantizer : object {
    public static bool Quantize(string srcFileName, string dstFilename, LLamaFtype ftype, int nthread, bool allowRequantize, bool quantizeOutputTensor);
    public static bool Quantize(string srcFileName, string dstFilename, string ftype, int nthread, bool allowRequantize, bool quantizeOutputTensor);
    private static bool ValidateFtype(LLamaFtype ftype);
    private static LLamaFtype StringToFtype(string str);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[DefaultMemberAttribute("Item")]
public class LLama.LLamaTemplate : object {
    [NullableAttribute("2")]
private SafeLlamaModelHandle _model;
    [NullableAttribute("2")]
private Byte[] _customTemplate;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<string, ReadOnlyMemory`1<byte>> _roleCache;
    private TextMessage[] _messages;
    private bool _addAssistant;
    private LLamaChatMessage[] _nativeChatMessages;
    private int _resultLength;
    private Byte[] _result;
    private bool _dirty;
    public static Encoding Encoding;
    [CompilerGeneratedAttribute]
private int <Count>k__BackingField;
    public int Count { get; private set; }
    public TextMessage Item { get; }
    public bool AddAssistant { get; public set; }
    public LLamaTemplate(SafeLlamaModelHandle model);
    public LLamaTemplate(LLamaWeights weights);
    public LLamaTemplate(string customTemplate);
    private static LLamaTemplate();
    [CompilerGeneratedAttribute]
public int get_Count();
    [CompilerGeneratedAttribute]
private void set_Count(int value);
    public TextMessage get_Item(int index);
    public bool get_AddAssistant();
    public void set_AddAssistant(bool value);
    public LLamaTemplate Add(string role, string content);
    public LLamaTemplate Add(TextMessage message);
    public LLamaTemplate RemoveAt(int index);
    public void Clear();
    [NullableContextAttribute("0")]
public ReadOnlySpan`1<byte> Apply();
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private int <Apply>g__ApplyInternal|26_0(Span`1<LLamaChatMessage> messages, Byte[] output);
}
public class LLama.LLamaTransforms : object {
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.LLamaWeights : object {
    [CompilerGeneratedAttribute]
private SafeLlamaModelHandle <NativeHandle>k__BackingField;
    [CompilerGeneratedAttribute]
private IReadOnlyDictionary`2<string, string> <Metadata>k__BackingField;
    public SafeLlamaModelHandle NativeHandle { get; }
    public int VocabCount { get; }
    public int ContextSize { get; }
    public ulong SizeInBytes { get; }
    public ulong ParameterCount { get; }
    public int EmbeddingSize { get; }
    public ModelTokens Tokens { get; }
    public IReadOnlyDictionary`2<string, string> Metadata { get; public set; }
    private LLamaWeights(SafeLlamaModelHandle weights);
    [CompilerGeneratedAttribute]
public SafeLlamaModelHandle get_NativeHandle();
    public int get_VocabCount();
    public int get_ContextSize();
    public ulong get_SizeInBytes();
    public ulong get_ParameterCount();
    public int get_EmbeddingSize();
    public ModelTokens get_Tokens();
    [CompilerGeneratedAttribute]
public IReadOnlyDictionary`2<string, string> get_Metadata();
    [CompilerGeneratedAttribute]
public void set_Metadata(IReadOnlyDictionary`2<string, string> value);
    public static LLamaWeights LoadFromFile(IModelParams params);
    [AsyncStateMachineAttribute("LLama.LLamaWeights/<LoadFromFileAsync>d__21")]
public static Task`1<LLamaWeights> LoadFromFileAsync(IModelParams params, CancellationToken token, IProgress`1<float> progressReporter);
    public sealed virtual void Dispose();
    public LLamaContext CreateContext(IContextParams params, ILogger logger);
    public LLamaToken[] Tokenize(string text, bool add_bos, bool special, Encoding encoding);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.LLavaWeights : object {
    [CompilerGeneratedAttribute]
private SafeLlavaModelHandle <NativeHandle>k__BackingField;
    public SafeLlavaModelHandle NativeHandle { get; }
    private LLavaWeights(SafeLlavaModelHandle weights);
    [CompilerGeneratedAttribute]
public SafeLlavaModelHandle get_NativeHandle();
    public static LLavaWeights LoadFromFile(string mmProject);
    public static Task`1<LLavaWeights> LoadFromFileAsync(string mmProject, CancellationToken token);
    public SafeLlavaImageEmbedHandle CreateImageEmbeddings(LLamaContext ctxLlama, Byte[] image);
    public SafeLlavaImageEmbedHandle CreateImageEmbeddings(Byte[] image, int threads);
    public SafeLlavaImageEmbedHandle CreateImageEmbeddings(LLamaContext ctxLlama, string image);
    public SafeLlavaImageEmbedHandle CreateImageEmbeddings(string image, int threads);
    public bool EvalImageEmbed(LLamaContext ctxLlama, SafeLlavaImageEmbedHandle imageEmbed, Int32& n_past);
    public sealed virtual void Dispose();
}
public enum LLama.Native.AvxLevel : Enum {
    public int value__;
    public static AvxLevel None;
    public static AvxLevel Avx;
    public static AvxLevel Avx2;
    public static AvxLevel Avx512;
}
public enum LLama.Native.DecodeResult : Enum {
    public int value__;
    public static DecodeResult Error;
    public static DecodeResult Ok;
    public static DecodeResult NoKvSlot;
}
public enum LLama.Native.GGMLType : Enum {
    public int value__;
    public static GGMLType GGML_TYPE_F32;
    public static GGMLType GGML_TYPE_F16;
    public static GGMLType GGML_TYPE_Q4_0;
    public static GGMLType GGML_TYPE_Q4_1;
    public static GGMLType GGML_TYPE_Q5_0;
    public static GGMLType GGML_TYPE_Q5_1;
    public static GGMLType GGML_TYPE_Q8_0;
    public static GGMLType GGML_TYPE_Q8_1;
    public static GGMLType GGML_TYPE_Q2_K;
    public static GGMLType GGML_TYPE_Q3_K;
    public static GGMLType GGML_TYPE_Q4_K;
    public static GGMLType GGML_TYPE_Q5_K;
    public static GGMLType GGML_TYPE_Q6_K;
    public static GGMLType GGML_TYPE_Q8_K;
    public static GGMLType GGML_TYPE_I8;
    public static GGMLType GGML_TYPE_I16;
    public static GGMLType GGML_TYPE_I32;
    public static GGMLType GGML_TYPE_COUNT;
}
public enum LLama.Native.GPUSplitMode : Enum {
    public int value__;
    public static GPUSplitMode None;
    public static GPUSplitMode Layer;
    public static GPUSplitMode Row;
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal class LLama.Native.GroupDisposable : object {
    private bool _disposed;
    private List`1<MemoryHandle> _handles;
    private List`1<IDisposable> _disposables;
    protected virtual override void Finalize();
    public MemoryHandle Add(MemoryHandle handle);
    public T Add(T disposable);
    public sealed virtual void Dispose();
}
[ExtensionAttribute]
internal static class LLama.Native.LibraryNameExtensions : object {
    [NullableContextAttribute("1")]
[ExtensionAttribute]
public static string GetLibraryName(NativeLibraryName name);
}
public enum LLama.Native.LLamaAttentionType : Enum {
    public int value__;
    public static LLamaAttentionType Unspecified;
    public static LLamaAttentionType Causal;
    public static LLamaAttentionType NonCausal;
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.LLamaBatch : object {
    private Byte[] _logits;
    private LLamaToken[] _tokens;
    private LLamaPos[] _positions;
    private Int32[] _sequenceIdCount;
    private LLamaSeqId[][] _sequenceIds;
    private IntPtr[] _sequenceIdsPtrs;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<ValueTuple`2<LLamaToken, LLamaPos>, int> _index;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private List`1<ValueTuple`2<LLamaSeqId, int>> _logitPositions;
    [CompilerGeneratedAttribute]
private int <TokenCount>k__BackingField;
    [CompilerGeneratedAttribute]
private int <TokenCapacity>k__BackingField;
    [CompilerGeneratedAttribute]
private int <SequenceCapacity>k__BackingField;
    internal int LogitPositionCount { get; }
    public int TokenCount { get; private set; }
    private int TokenCapacity { get; private set; }
    public int SequenceCapacity { get; private set; }
    internal int get_LogitPositionCount();
    [CompilerGeneratedAttribute]
public int get_TokenCount();
    [CompilerGeneratedAttribute]
private void set_TokenCount(int value);
    [CompilerGeneratedAttribute]
private int get_TokenCapacity();
    [CompilerGeneratedAttribute]
private void set_TokenCapacity(int value);
    [CompilerGeneratedAttribute]
public int get_SequenceCapacity();
    [CompilerGeneratedAttribute]
private void set_SequenceCapacity(int value);
    private void GrowTokenCapacity();
    private void GrowMaxSequences(int atLeast);
    internal GroupDisposable ToNativeBatch(LLamaNativeBatch& batch);
    [NullableContextAttribute("0")]
public int Add(LLamaToken token, LLamaPos pos, ReadOnlySpan`1<LLamaSeqId> sequences, bool logits);
    public int Add(LLamaToken token, LLamaPos pos, List`1<LLamaSeqId> sequences, bool logits);
    public int Add(LLamaToken token, LLamaPos pos, LLamaSeqId sequence, bool logits);
    [NullableContextAttribute("0")]
public int AddRange(ReadOnlySpan`1<LLamaToken> tokens, LLamaPos start, LLamaSeqId sequence, bool logitsLast);
    public void Clear();
    [NullableContextAttribute("0")]
internal Span`1<ValueTuple`2<LLamaSeqId, int>> GetLogitPositions(Span`1<ValueTuple`2<LLamaSeqId, int>> dest);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.LLamaBatchEmbeddings : object {
    private Byte[] _logits;
    private Single[] _embeddings;
    private LLamaPos[] _positions;
    private Int32[] _sequenceIdCount;
    private LLamaSeqId[][] _sequenceIds;
    private IntPtr[] _sequenceIdsPtrs;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private List`1<ValueTuple`2<LLamaSeqId, int>> _logitPositions;
    [CompilerGeneratedAttribute]
private int <EmbeddingDimensions>k__BackingField;
    [CompilerGeneratedAttribute]
private int <EmbeddingsCount>k__BackingField;
    [CompilerGeneratedAttribute]
private int <EmbeddingsCapacity>k__BackingField;
    [CompilerGeneratedAttribute]
private int <SequenceCapacity>k__BackingField;
    internal int LogitPositionCount { get; }
    public int EmbeddingDimensions { get; }
    public int EmbeddingsCount { get; private set; }
    private int EmbeddingsCapacity { get; private set; }
    public int SequenceCapacity { get; private set; }
    public LLamaBatchEmbeddings(int embeddingDimensions);
    internal int get_LogitPositionCount();
    [CompilerGeneratedAttribute]
public int get_EmbeddingDimensions();
    [CompilerGeneratedAttribute]
public int get_EmbeddingsCount();
    [CompilerGeneratedAttribute]
private void set_EmbeddingsCount(int value);
    [CompilerGeneratedAttribute]
private int get_EmbeddingsCapacity();
    [CompilerGeneratedAttribute]
private void set_EmbeddingsCapacity(int value);
    [CompilerGeneratedAttribute]
public int get_SequenceCapacity();
    [CompilerGeneratedAttribute]
private void set_SequenceCapacity(int value);
    private void GrowEmbeddingsCapacity();
    private void GrowMaxSequences(int atLeast);
    internal GroupDisposable ToNativeBatch(LLamaNativeBatch& batch);
    [NullableContextAttribute("0")]
public int Add(ReadOnlySpan`1<float> embedding, LLamaPos pos, ReadOnlySpan`1<LLamaSeqId> sequences, bool logits);
    [NullableContextAttribute("0")]
public int Add(ReadOnlySpan`1<float> embedding, LLamaPos pos, LLamaSeqId sequence, bool logits);
    public int Add(TParam parameter, WriteEmbeddingsDelegate`1<TParam> write, LLamaPos pos, ReadOnlySpan`1<LLamaSeqId> sequences, bool logits);
    public int Add(TParam parameter, WriteEmbeddingsDelegate`1<TParam> write, LLamaPos pos, LLamaSeqId sequence, bool logits);
    public void Clear();
    [NullableContextAttribute("0")]
internal Span`1<ValueTuple`2<LLamaSeqId, int>> GetLogitPositions(Span`1<ValueTuple`2<LLamaSeqId, int>> dest);
}
public class LLama.Native.LLamaChatMessage : ValueType {
    public Byte* role;
    public Byte* content;
}
public class LLama.Native.LLamaContextParams : ValueType {
    public UInt32 seed;
    public UInt32 n_ctx;
    public UInt32 n_batch;
    public UInt32 n_ubatch;
    public UInt32 n_seq_max;
    public UInt32 n_threads;
    public UInt32 n_threads_batch;
    public RopeScalingType rope_scaling_type;
    public LLamaPoolingType llama_pooling_type;
    public LLamaAttentionType attention_type;
    public float rope_freq_base;
    public float rope_freq_scale;
    public float yarn_ext_factor;
    public float yarn_attn_factor;
    public float yarn_beta_fast;
    public float yarn_beta_slow;
    public UInt32 yarn_orig_ctx;
    public float defrag_threshold;
    public IntPtr cb_eval;
    public IntPtr cb_eval_user_data;
    public GGMLType type_k;
    public GGMLType type_v;
    private sbyte _logits_all;
    private sbyte _embeddings;
    private sbyte _offload_kqv;
    private sbyte _flash_attention;
    public IntPtr abort_callback;
    public IntPtr abort_callback_user_data;
    public bool embeddings { get; public set; }
    public bool offload_kqv { get; public set; }
    public bool flash_attention { get; public set; }
    [IsReadOnlyAttribute]
public bool get_embeddings();
    public void set_embeddings(bool value);
    [IsReadOnlyAttribute]
public bool get_offload_kqv();
    public void set_offload_kqv(bool value);
    [IsReadOnlyAttribute]
public bool get_flash_attention();
    public void set_flash_attention(bool value);
    public static LLamaContextParams Default();
    [CompilerGeneratedAttribute]
internal static LLamaContextParams <Default>g__llama_context_default_params|37_0();
}
public enum LLama.Native.LLamaFtype : Enum {
    public int value__;
    public static LLamaFtype ALL_F32;
    public static LLamaFtype MOSTLY_F16;
    public static LLamaFtype MOSTLY_Q8_0;
    public static LLamaFtype MOSTLY_Q4_0;
    public static LLamaFtype MOSTLY_Q4_1;
    public static LLamaFtype MOSTLY_Q5_0;
    public static LLamaFtype MOSTLY_Q5_1;
    public static LLamaFtype MOSTLY_Q2_K;
    public static LLamaFtype MOSTLY_Q3_K_S;
    public static LLamaFtype MOSTLY_Q3_K_M;
    public static LLamaFtype MOSTLY_Q3_K_L;
    public static LLamaFtype MOSTLY_Q4_K_S;
    public static LLamaFtype MOSTLY_Q4_K_M;
    public static LLamaFtype MOSTLY_Q5_K_S;
    public static LLamaFtype MOSTLY_Q5_K_M;
    public static LLamaFtype MOSTLY_Q6_K;
    public static LLamaFtype MOSTLY_IQ2_XXS;
    public static LLamaFtype MOSTLY_IQ2_XS;
    public static LLamaFtype MOSTLY_Q2_K_S;
    public static LLamaFtype MOSTLY_IQ3_K_XS;
    public static LLamaFtype MOSTLY_IQ3_XXS;
    public static LLamaFtype MOSTLY_IQ1_S;
    public static LLamaFtype MOSTLY_IQ4_NL;
    public static LLamaFtype MOSTLY_IQ3_S;
    public static LLamaFtype MOSTLY_IQ3_M;
    public static LLamaFtype MOSTLY_IQ2_S;
    public static LLamaFtype MOSTLY_IQ2_M;
    public static LLamaFtype MOSTLY_IQ4_XS;
    public static LLamaFtype MOSTLY_IQ1_M;
    public static LLamaFtype MOSTLY_BF16;
    public static LLamaFtype MOSTLY_Q4_0_4_4;
    public static LLamaFtype MOSTLY_Q4_0_4_8;
    public static LLamaFtype MOSTLY_Q4_0_8_8;
    public static LLamaFtype GUESSED;
}
[DebuggerDisplayAttribute("{Type} {Value}")]
public class LLama.Native.LLamaGrammarElement : ValueType {
    public LLamaGrammarElementType Type;
    public UInt32 Value;
    public LLamaGrammarElement(LLamaGrammarElementType type, UInt32 value);
    internal bool IsCharElement();
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public virtual string ToString();
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
private bool PrintMembers(StringBuilder builder);
    [CompilerGeneratedAttribute]
public static bool op_Inequality(LLamaGrammarElement left, LLamaGrammarElement right);
    [CompilerGeneratedAttribute]
public static bool op_Equality(LLamaGrammarElement left, LLamaGrammarElement right);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public sealed virtual bool Equals(LLamaGrammarElement other);
}
public enum LLama.Native.LLamaGrammarElementType : Enum {
    public int value__;
    public static LLamaGrammarElementType END;
    public static LLamaGrammarElementType ALT;
    public static LLamaGrammarElementType RULE_REF;
    public static LLamaGrammarElementType CHAR;
    public static LLamaGrammarElementType CHAR_NOT;
    public static LLamaGrammarElementType CHAR_RNG_UPPER;
    public static LLamaGrammarElementType CHAR_ALT;
    public static LLamaGrammarElementType CHAR_ANY;
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.LLamaKvCacheViewSafeHandle : SafeLLamaHandleBase {
    private SafeLLamaContextHandle _ctx;
    private NativeLLamaKvCacheView _view;
    public int CellCount { get; }
    public int TokenCount { get; }
    public int MaxSequenceCount { get; }
    public int UsedCellCount { get; }
    public int MaxContiguous { get; }
    public int MaxContiguousIdx { get; }
    private LLamaKvCacheViewSafeHandle(SafeLLamaContextHandle ctx, NativeLLamaKvCacheView view);
    public int get_CellCount();
    public int get_TokenCount();
    public int get_MaxSequenceCount();
    public int get_UsedCellCount();
    public int get_MaxContiguous();
    public int get_MaxContiguousIdx();
    public static LLamaKvCacheViewSafeHandle Allocate(SafeLLamaContextHandle ctx, int maxSequences);
    protected virtual bool ReleaseHandle();
    public void Update();
    private NativeLLamaKvCacheView& GetNativeView();
    public LLamaPos GetCell(int index);
    [NullableContextAttribute("0")]
public Span`1<LLamaSeqId> GetCellSequences(int index);
    private static NativeLLamaKvCacheView llama_kv_cache_view_init(SafeLLamaContextHandle ctx, int n_seq_max);
    private static void llama_kv_cache_view_free(NativeLLamaKvCacheView& view);
    private static void llama_kv_cache_view_update(SafeLLamaContextHandle ctx, NativeLLamaKvCacheView& view);
}
public enum LLama.Native.LLamaLogLevel : Enum {
    public int value__;
    public static LLamaLogLevel Error;
    public static LLamaLogLevel Warning;
    public static LLamaLogLevel Info;
    public static LLamaLogLevel Debug;
}
[ExtensionAttribute]
internal static class LLama.Native.LLamaLogLevelExtensions : object {
    [ExtensionAttribute]
public static LogLevel ToLogLevel(LLamaLogLevel llama);
}
public enum LLama.Native.LLamaModelKvOverrideType : Enum {
    public int value__;
    public static LLamaModelKvOverrideType Int;
    public static LLamaModelKvOverrideType Float;
    public static LLamaModelKvOverrideType Bool;
    public static LLamaModelKvOverrideType String;
}
public class LLama.Native.LLamaModelMetadataOverride : ValueType {
    [FixedBufferAttribute("System.Byte", "128")]
public <key>e__FixedBuffer key;
    public LLamaModelKvOverrideType Tag;
    private int PADDING;
    public long IntValue;
    public double FloatValue;
    public long BoolValue;
    [FixedBufferAttribute("System.Byte", "128")]
public <StringValue>e__FixedBuffer StringValue;
}
public class LLama.Native.LLamaModelParams : ValueType {
    public int n_gpu_layers;
    public GPUSplitMode split_mode;
    public int main_gpu;
    public Single* tensor_split;
    public Byte* rpc_servers;
    public IntPtr progress_callback;
    public Void* progress_callback_user_data;
    public LLamaModelMetadataOverride* kv_overrides;
    private sbyte _vocab_only;
    private sbyte _use_mmap;
    private sbyte _use_mlock;
    private sbyte _check_tensors;
    public bool vocab_only { get; public set; }
    public bool use_mmap { get; public set; }
    public bool use_mlock { get; public set; }
    public bool check_tensors { get; public set; }
    [IsReadOnlyAttribute]
public bool get_vocab_only();
    public void set_vocab_only(bool value);
    [IsReadOnlyAttribute]
public bool get_use_mmap();
    public void set_use_mmap(bool value);
    [IsReadOnlyAttribute]
public bool get_use_mlock();
    public void set_use_mlock(bool value);
    [IsReadOnlyAttribute]
public bool get_check_tensors();
    public void set_check_tensors(bool value);
    public static LLamaModelParams Default();
    [CompilerGeneratedAttribute]
internal static LLamaModelParams <Default>g__llama_model_default_params|24_0();
}
public class LLama.Native.LLamaModelQuantizeParams : ValueType {
    public int nthread;
    public LLamaFtype ftype;
    public GGMLType output_tensor_type;
    public GGMLType token_embedding_type;
    private sbyte _allow_requantize;
    private sbyte _quantize_output_tensor;
    private sbyte _only_copy;
    private sbyte _pure;
    private sbyte _keep_split;
    public IntPtr imatrix;
    public IntPtr kv_overrides;
    public bool allow_requantize { get; public set; }
    public bool quantize_output_tensor { get; public set; }
    public bool only_copy { get; public set; }
    public bool pure { get; public set; }
    public bool keep_split { get; public set; }
    public bool get_allow_requantize();
    public void set_allow_requantize(bool value);
    public bool get_quantize_output_tensor();
    public void set_quantize_output_tensor(bool value);
    public bool get_only_copy();
    public void set_only_copy(bool value);
    public bool get_pure();
    public void set_pure(bool value);
    public bool get_keep_split();
    public void set_keep_split(bool value);
    public static LLamaModelQuantizeParams Default();
    [CompilerGeneratedAttribute]
internal static LLamaModelQuantizeParams <Default>g__llama_model_quantize_default_params|26_0();
}
public class LLama.Native.LLamaNativeBatch : ValueType {
    public int n_tokens;
    public LLamaToken* tokens;
    public Single* embd;
    public LLamaPos* pos;
    public Int32* n_seq_id;
    public LLamaSeqId** seq_id;
    public Byte* logits;
    private LLamaPos _all_pos_0;
    private LLamaPos _all_pos_1;
    private LLamaSeqId _all_seq_id;
}
public enum LLama.Native.LLamaPoolingType : Enum {
    public int value__;
    public static LLamaPoolingType Unspecified;
    public static LLamaPoolingType None;
    public static LLamaPoolingType Mean;
    public static LLamaPoolingType CLS;
    public static LLamaPoolingType Last;
}
public class LLama.Native.LLamaPos : ValueType {
    public int Value;
    private LLamaPos(int value);
    public static int op_Explicit(LLamaPos pos);
    public static LLamaPos op_Implicit(int value);
    public static LLamaPos op_Increment(LLamaPos pos);
    public static LLamaPos op_Decrement(LLamaPos pos);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public virtual string ToString();
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
private bool PrintMembers(StringBuilder builder);
    [CompilerGeneratedAttribute]
public static bool op_Inequality(LLamaPos left, LLamaPos right);
    [CompilerGeneratedAttribute]
public static bool op_Equality(LLamaPos left, LLamaPos right);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public sealed virtual bool Equals(LLamaPos other);
}
public class LLama.Native.LlamaProgressCallback : MulticastDelegate {
    public LlamaProgressCallback(object object, IntPtr method);
    public virtual bool Invoke(float progress, IntPtr ctx);
    public virtual IAsyncResult BeginInvoke(float progress, IntPtr ctx, AsyncCallback callback, object object);
    public virtual bool EndInvoke(IAsyncResult result);
}
public enum LLama.Native.LLamaRopeType : Enum {
    public int value__;
    public static LLamaRopeType None;
    public static LLamaRopeType Norm;
    public static LLamaRopeType NEOX;
    public static LLamaRopeType GLM;
}
public class LLama.Native.LLamaSeqId : ValueType {
    public static LLamaSeqId Zero;
    public int Value;
    private LLamaSeqId(int value);
    private static LLamaSeqId();
    public static int op_Explicit(LLamaSeqId pos);
    public static LLamaSeqId op_Explicit(int value);
    [IsReadOnlyAttribute]
[NullableContextAttribute("1")]
public virtual string ToString();
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
private bool PrintMembers(StringBuilder builder);
    [CompilerGeneratedAttribute]
public static bool op_Inequality(LLamaSeqId left, LLamaSeqId right);
    [CompilerGeneratedAttribute]
public static bool op_Equality(LLamaSeqId left, LLamaSeqId right);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public sealed virtual bool Equals(LLamaSeqId other);
}
public class LLama.Native.LLamaTimings : ValueType {
    private double t_start_ms;
    private double t_end_ms;
    private double t_load_ms;
    private double t_sample_ms;
    private double t_p_eval_ms;
    private double t_eval_ms;
    private int n_sample;
    private int n_p_eval;
    private int n_eval;
    public TimeSpan ResetTimestamp { get; }
    public TimeSpan ReadTimestamp { get; }
    public TimeSpan Loading { get; }
    public TimeSpan Sampling { get; }
    public TimeSpan PromptEval { get; }
    public TimeSpan Eval { get; }
    public int TokensSampled { get; }
    public int PrompTokensEvaluated { get; }
    public int TokensEvaluated { get; }
    [IsReadOnlyAttribute]
public TimeSpan get_ResetTimestamp();
    [IsReadOnlyAttribute]
public TimeSpan get_ReadTimestamp();
    [IsReadOnlyAttribute]
public TimeSpan get_Loading();
    [IsReadOnlyAttribute]
public TimeSpan get_Sampling();
    public TimeSpan get_PromptEval();
    [IsReadOnlyAttribute]
public TimeSpan get_Eval();
    [IsReadOnlyAttribute]
public int get_TokensSampled();
    [IsReadOnlyAttribute]
public int get_PrompTokensEvaluated();
    [IsReadOnlyAttribute]
public int get_TokensEvaluated();
}
[IsReadOnlyAttribute]
[DebuggerDisplayAttribute("{Value}")]
public class LLama.Native.LLamaToken : ValueType {
    public static LLamaToken InvalidToken;
    private int Value;
    private LLamaToken(int value);
    private static LLamaToken();
    public static int op_Explicit(LLamaToken pos);
    public static LLamaToken op_Implicit(int value);
    [NullableContextAttribute("1")]
public LLamaTokenAttr GetAttributes(SafeLlamaModelHandle model);
    [NullableContextAttribute("1")]
public bool IsControl(SafeLlamaModelHandle model);
    [NullableContextAttribute("1")]
public bool IsEndOfGeneration(SafeLlamaModelHandle model);
    [NullableContextAttribute("1")]
public virtual string ToString();
    [CompilerGeneratedAttribute]
private bool PrintMembers(StringBuilder builder);
    [CompilerGeneratedAttribute]
public static bool op_Inequality(LLamaToken left, LLamaToken right);
    [CompilerGeneratedAttribute]
public static bool op_Equality(LLamaToken left, LLamaToken right);
    [CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [CompilerGeneratedAttribute]
public sealed virtual bool Equals(LLamaToken other);
}
[FlagsAttribute]
public enum LLama.Native.LLamaTokenAttr : Enum {
    public int value__;
    public static LLamaTokenAttr Undefined;
    public static LLamaTokenAttr Unknown;
    public static LLamaTokenAttr Unused;
    public static LLamaTokenAttr Normal;
    public static LLamaTokenAttr Control;
    public static LLamaTokenAttr UserDefined;
    public static LLamaTokenAttr Byte;
    public static LLamaTokenAttr Normalized;
    public static LLamaTokenAttr LStrip;
    public static LLamaTokenAttr RStrip;
    public static LLamaTokenAttr SingleWord;
}
public class LLama.Native.LLamaTokenData : ValueType {
    public LLamaToken id;
    public float logit;
    public float p;
    public LLamaTokenData(LLamaToken id, float logit, float p);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.LLamaTokenDataArray : ValueType {
    [NullableAttribute("0")]
public Memory`1<LLamaTokenData> Data;
    public bool Sorted;
    [NullableContextAttribute("0")]
public LLamaTokenDataArray(Memory`1<LLamaTokenData> tokens, bool isSorted);
    [NullableContextAttribute("0")]
public static LLamaTokenDataArray Create(ReadOnlySpan`1<float> logits);
    [NullableContextAttribute("0")]
public static LLamaTokenDataArray Create(ReadOnlySpan`1<float> logits, Memory`1<LLamaTokenData> buffer);
    [NullableContextAttribute("0")]
public void OverwriteLogits(ReadOnlySpan`1<ValueTuple`2<LLamaToken, float>> values);
    public void ApplyGrammar(SafeLLamaContextHandle ctx, SafeLLamaGrammarHandle grammar);
    public void TopK(SafeLLamaContextHandle context, int k, ulong minKeep);
    public void TopP(SafeLLamaContextHandle context, float p, ulong minKeep);
    public void MinP(SafeLLamaContextHandle context, float p, ulong minKeep);
    public void TailFree(SafeLLamaContextHandle context, float z, ulong minKeep);
    public void LocallyTypical(SafeLLamaContextHandle context, float p, ulong minKeep);
    [NullableContextAttribute("0")]
public void RepetitionPenalty(SafeLLamaContextHandle context, ReadOnlySpan`1<LLamaToken> lastTokens, float penaltyRepeat, float penaltyFreq, float penaltyPresent);
    [NullableContextAttribute("0")]
public void Guidance(SafeLLamaContextHandle context, ReadOnlySpan`1<float> guidanceLogits, float guidance);
    public void Temperature(SafeLLamaContextHandle context, float temp);
    public void Softmax(SafeLLamaContextHandle context);
    public LLamaToken SampleToken(SafeLLamaContextHandle context);
    public LLamaToken SampleTokenGreedy(SafeLLamaContextHandle context);
    public LLamaToken SampleTokenMirostat(SafeLLamaContextHandle context, float tau, float eta, int m, Single& mu);
    public LLamaToken SampleTokenMirostat2(SafeLLamaContextHandle context, float tau, float eta, Single& mu);
}
public class LLama.Native.LLamaTokenDataArrayNative : ValueType {
    private LLamaTokenData* _data;
    public ulong size;
    private sbyte _sorted;
    public Span`1<LLamaTokenData> data { get; }
    public bool sorted { get; public set; }
    public Span`1<LLamaTokenData> get_data();
    public bool get_sorted();
    public void set_sorted(bool value);
    public static MemoryHandle Create(LLamaTokenDataArray array, LLamaTokenDataArrayNative& native);
}
internal enum LLama.Native.LLamaVocabPreType : Enum {
    public int value__;
    public static LLamaVocabPreType Default;
    public static LLamaVocabPreType LLAMA3;
    public static LLamaVocabPreType DEEPSEEK_LLM;
    public static LLamaVocabPreType DEEPSEEK_CODER;
    public static LLamaVocabPreType FALCON;
    public static LLamaVocabPreType MPT;
    public static LLamaVocabPreType STARCODER;
    public static LLamaVocabPreType GPT2;
    public static LLamaVocabPreType REFACT;
    public static LLamaVocabPreType COMMAND_R;
    public static LLamaVocabPreType STABLELM2;
    public static LLamaVocabPreType QWEN2;
    public static LLamaVocabPreType OLMO;
    public static LLamaVocabPreType DBRX;
    public static LLamaVocabPreType SMAUG;
    public static LLamaVocabPreType PORO;
    public static LLamaVocabPreType CHATGLM3;
    public static LLamaVocabPreType CHATGLM4;
    public static LLamaVocabPreType VIKING;
    public static LLamaVocabPreType JAIS;
    public static LLamaVocabPreType TEKKEN;
    public static LLamaVocabPreType SMOLLM;
    public static LLamaVocabPreType CODESHELL;
}
public enum LLama.Native.LLamaVocabType : Enum {
    public int value__;
    public static LLamaVocabType None;
    public static LLamaVocabType SentencePiece;
    public static LLamaVocabType BytePairEncoding;
    public static LLamaVocabType WordPiece;
    public static LLamaVocabType Unigram;
}
public class LLama.Native.LLavaImageEmbed : ValueType {
    public Single* embed;
    public int n_image_pos;
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.LoraAdapter : object {
    [CompilerGeneratedAttribute]
private SafeLlamaModelHandle <Model>k__BackingField;
    [CompilerGeneratedAttribute]
private string <Path>k__BackingField;
    [CompilerGeneratedAttribute]
private IntPtr <Pointer>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <Loaded>k__BackingField;
    public SafeLlamaModelHandle Model { get; }
    public string Path { get; }
    internal IntPtr Pointer { get; }
    internal bool Loaded { get; private set; }
    internal LoraAdapter(SafeLlamaModelHandle model, string path, IntPtr nativePtr);
    [CompilerGeneratedAttribute]
public SafeLlamaModelHandle get_Model();
    [CompilerGeneratedAttribute]
public string get_Path();
    [CompilerGeneratedAttribute]
internal IntPtr get_Pointer();
    [CompilerGeneratedAttribute]
internal bool get_Loaded();
    [CompilerGeneratedAttribute]
private void set_Loaded(bool value);
    public void Unload();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public static class LLama.Native.NativeApi : object {
    internal static string libraryName;
    internal static string llavaLibraryName;
    [NullableAttribute("2")]
private static INativeLibrary _loadedLLamaLibrary;
    [NullableAttribute("2")]
private static INativeLibrary _loadedLLavaLibrary;
    private static NativeApi();
    public static void llama_empty_call();
    public static long llama_max_devices();
    public static bool llama_supports_mmap();
    public static bool llama_supports_mlock();
    public static bool llama_supports_gpu_offload();
    private static void llama_backend_init();
    public static bool llama_state_load_file(SafeLLamaContextHandle ctx, string path_session, LLamaToken[] tokens_out, ulong n_token_capacity, UInt64& n_token_count_out);
    public static bool llama_state_save_file(SafeLLamaContextHandle ctx, string path_session, LLamaToken[] tokens, ulong n_token_count);
    public static UIntPtr llama_state_seq_save_file(SafeLLamaContextHandle ctx, string filepath, LLamaSeqId seq_id, LLamaToken* tokens, UIntPtr n_token_count);
    public static UIntPtr llama_state_seq_load_file(SafeLLamaContextHandle ctx, string filepath, LLamaSeqId dest_seq_id, LLamaToken* tokens_out, UIntPtr n_token_capacity, UIntPtr& n_token_count_out);
    [NullableContextAttribute("0")]
public static Byte* llama_token_get_text(SafeLlamaModelHandle model, LLamaToken token);
    public static void llama_set_causal_attn(SafeLLamaContextHandle ctx, bool causalAttn);
    public static void llama_set_embeddings(SafeLLamaContextHandle ctx, bool embeddings);
    public static void llama_set_abort_callback(SafeLlamaModelHandle ctx, IntPtr abort_callback, IntPtr abort_callback_data);
    public static float llama_token_get_score(SafeLlamaModelHandle model, LLamaToken token);
    public static UInt32 llama_n_seq_max(SafeLLamaContextHandle ctx);
    public static LLamaPoolingType llama_pooling_type(SafeLLamaContextHandle ctx);
    [NullableContextAttribute("0")]
public static Single* llama_get_embeddings_seq(SafeLLamaContextHandle ctx, LLamaSeqId id);
    [NullableContextAttribute("0")]
public static Single* llama_get_embeddings_ith(SafeLLamaContextHandle ctx, int i);
    [NullableContextAttribute("0")]
public static Single* llama_get_embeddings(SafeLLamaContextHandle ctx);
    [NullableContextAttribute("0")]
public static int llama_chat_apply_template(SafeLlamaModelHandle model, Byte* tmpl, LLamaChatMessage* chat, UIntPtr n_msg, bool add_ass, Byte* buf, int length);
    public static int llama_add_bos_token(SafeLlamaModelHandle model);
    public static int llama_add_eos_token(SafeLlamaModelHandle model);
    public static void llama_print_timings(SafeLLamaContextHandle ctx);
    public static IntPtr llama_print_system_info();
    [NullableContextAttribute("0")]
public static int llama_token_to_piece(SafeLlamaModelHandle model, LLamaToken llamaToken, Span`1<byte> buffer, int lstrip, bool special);
    [NullableContextAttribute("0")]
public static int llama_tokenize(SafeLlamaModelHandle model, Byte* text, int text_len, LLamaToken* tokens, int n_max_tokens, bool add_special, bool parse_special);
    [NullableContextAttribute("0")]
public static int llama_detokenize(SafeLlamaModelHandle model, LLamaToken* tokens, int nTokens, Byte* textOut, int textLengthMax, bool removeSpecial, bool unparseSpecial);
    [ObsoleteAttribute("Use `NativeLogConfig.llama_log_set` instead")]
public static void llama_log_set(LLamaLogCallback logCallback);
    public static int llama_get_kv_cache_token_count(SafeLLamaContextHandle ctx);
    public static int llama_get_kv_cache_used_cells(SafeLLamaContextHandle ctx);
    public static void llama_kv_cache_clear(SafeLLamaContextHandle ctx);
    public static bool llama_kv_cache_seq_rm(SafeLLamaContextHandle ctx, LLamaSeqId seq, LLamaPos p0, LLamaPos p1);
    public static void llama_kv_cache_seq_cp(SafeLLamaContextHandle ctx, LLamaSeqId src, LLamaSeqId dest, LLamaPos p0, LLamaPos p1);
    public static void llama_kv_cache_seq_keep(SafeLLamaContextHandle ctx, LLamaSeqId seq);
    public static void llama_kv_cache_seq_add(SafeLLamaContextHandle ctx, LLamaSeqId seq, LLamaPos p0, LLamaPos p1, int delta);
    public static void llama_kv_cache_seq_div(SafeLLamaContextHandle ctx, LLamaSeqId seq, LLamaPos p0, LLamaPos p1, int d);
    public static LLamaPos llama_kv_cache_seq_pos_max(SafeLLamaContextHandle ctx, LLamaSeqId seq);
    public static LLamaNativeBatch llama_batch_init(int n_tokens, int embd, int n_seq_max);
    public static void llama_batch_free(LLamaNativeBatch batch);
    [NullableContextAttribute("0")]
public static int llama_control_vector_apply(SafeLLamaContextHandle ctx, Single* data, UIntPtr len, int n_embd, int il_start, int il_end);
    public static int llama_split_path(string split_path, UIntPtr maxlen, string path_prefix, int split_no, int split_count);
    public static int llama_split_prefix(string split_prefix, UIntPtr maxlen, string split_path, int split_no, int split_count);
    public static void llama_lora_adapter_free(IntPtr adapter);
    [NullableContextAttribute("0")]
public static SafeLLamaGrammarHandle llama_grammar_init(LLamaGrammarElement** rules, ulong nRules, ulong startRuleIndex);
    public static void llama_grammar_free(IntPtr grammar);
    public static SafeLLamaGrammarHandle llama_grammar_copy(SafeLLamaGrammarHandle grammar);
    public static void llama_grammar_sample(SafeLLamaGrammarHandle grammar, SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates);
    public static void llama_grammar_accept_token(SafeLLamaGrammarHandle grammar, SafeLLamaContextHandle ctx, LLamaToken token);
    public static bool llava_validate_embed_size(SafeLLamaContextHandle ctxLlama, SafeLlavaModelHandle ctxClip);
    public static SafeLlavaImageEmbedHandle llava_image_embed_make_with_bytes(SafeLlavaModelHandle ctx_clip, int n_threads, Byte[] image_bytes, int image_bytes_length);
    public static SafeLlavaImageEmbedHandle llava_image_embed_make_with_filename(SafeLlavaModelHandle ctx_clip, int n_threads, string image_path);
    public static void llava_image_embed_free(IntPtr embed);
    public static bool llava_eval_image_embed(SafeLLamaContextHandle ctx_llama, SafeLlavaImageEmbedHandle embed, int n_batch, Int32& n_past);
    private static void SetDllImportResolver();
    [NullableContextAttribute("2")]
public static INativeLibrary GetLoadedNativeLibrary(NativeLibraryName name);
    public static UInt32 llama_model_quantize(string fname_inp, string fname_out, LLamaModelQuantizeParams& param);
    [NullableContextAttribute("0")]
public static void llama_sample_repetition_penalties(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, LLamaToken* last_tokens, ulong last_tokens_size, float penalty_repeat, float penalty_freq, float penalty_present);
    [NullableContextAttribute("0")]
public static void llama_sample_apply_guidance(SafeLLamaContextHandle ctx, Span`1<float> logits, ReadOnlySpan`1<float> logits_guidance, float scale);
    [NullableContextAttribute("0")]
public static void llama_sample_apply_guidance(SafeLLamaContextHandle ctx, Single* logits, Single* logits_guidance, float scale);
    public static void llama_sample_softmax(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates);
    public static void llama_sample_top_k(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, int k, ulong min_keep);
    public static void llama_sample_top_p(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, float p, ulong min_keep);
    public static void llama_sample_min_p(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, float p, ulong min_keep);
    public static void llama_sample_tail_free(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, float z, ulong min_keep);
    public static void llama_sample_typical(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, float p, ulong min_keep);
    public static void llama_sample_typical(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, float min_temp, float max_temp, float exponent_val);
    public static void llama_sample_temp(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, float temp);
    public static LLamaToken llama_sample_token_mirostat(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, float tau, float eta, int m, Single& mu);
    public static LLamaToken llama_sample_token_mirostat_v2(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates, float tau, float eta, Single& mu);
    public static LLamaToken llama_sample_token_greedy(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates);
    public static LLamaToken llama_sample_token(SafeLLamaContextHandle ctx, LLamaTokenDataArrayNative& candidates);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
internal static int <llama_chat_apply_template>g__internal_llama_chat_apply_template|20_0(IntPtr model, Byte* tmpl, LLamaChatMessage* chat, UIntPtr n_msg, bool add_ass, Byte* buf, int length);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
internal static int <llama_token_to_piece>g__llama_token_to_piece_native|25_0(SafeLlamaModelHandle model, LLamaToken llamaToken, Byte* buffer, int length, int lstrip, bool special);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.NativeLibraryConfig : object {
    [CompilerGeneratedAttribute]
private static NativeLibraryConfigContainer <All>k__BackingField;
    [CompilerGeneratedAttribute]
private static NativeLibraryConfig <LLama>k__BackingField;
    [CompilerGeneratedAttribute]
private static NativeLibraryConfig <LLava>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <LibraryHasLoaded>k__BackingField;
    [CompilerGeneratedAttribute]
private NativeLibraryName <NativeLibraryName>k__BackingField;
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private LLamaLogCallback <LogCallback>k__BackingField;
    [ObsoleteAttribute("Please use NativeLibraryConfig.All instead, or set configurations for NativeLibraryConfig.LLama and NativeLibraryConfig.LLavaShared respectively.")]
public static NativeLibraryConfigContainer Instance { get; }
    public static NativeLibraryConfigContainer All { get; }
    public static NativeLibraryConfig LLama { get; }
    public static NativeLibraryConfig LLava { get; }
    public bool LibraryHasLoaded { get; internal set; }
    internal NativeLibraryName NativeLibraryName { get; }
    [NullableAttribute("2")]
internal LLamaLogCallback LogCallback { get; private set; }
    private static NativeLibraryConfig();
    private NativeLibraryConfig(NativeLibraryName nativeLibraryName);
    public static NativeLibraryConfigContainer get_Instance();
    [CompilerGeneratedAttribute]
public static NativeLibraryConfigContainer get_All();
    [CompilerGeneratedAttribute]
public static NativeLibraryConfig get_LLama();
    [CompilerGeneratedAttribute]
public static NativeLibraryConfig get_LLava();
    [CompilerGeneratedAttribute]
public bool get_LibraryHasLoaded();
    [CompilerGeneratedAttribute]
internal void set_LibraryHasLoaded(bool value);
    [CompilerGeneratedAttribute]
internal NativeLibraryName get_NativeLibraryName();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
internal LLamaLogCallback get_LogCallback();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
private void set_LogCallback(LLamaLogCallback value);
    private void ThrowIfLoaded();
    public NativeLibraryConfig WithLogCallback(LLamaLogCallback callback);
    public NativeLibraryConfig WithLogCallback(ILogger logger);
    [NullableContextAttribute("2")]
public bool DryRun(INativeLibrary& loadedLibrary);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.NativeLibraryConfigContainer : object {
    private NativeLibraryConfig[] _configs;
    internal NativeLibraryConfigContainer(NativeLibraryConfig[] configs);
    public void ForEach(Action`1<NativeLibraryConfig> action);
    public NativeLibraryConfigContainer WithLogCallback(LLamaLogCallback callback);
    public NativeLibraryConfigContainer WithLogCallback(ILogger logger);
    [NullableContextAttribute("2")]
public bool DryRun(INativeLibrary& loadedLLamaNativeLibrary, INativeLibrary& loadedLLavaNativeLibrary);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.NativeLibraryFromPath : object {
    private string _path;
    [NullableAttribute("2")]
public NativeLibraryMetadata Metadata { get; }
    public NativeLibraryFromPath(string path);
    [NullableContextAttribute("2")]
public sealed virtual NativeLibraryMetadata get_Metadata();
    public sealed virtual IEnumerable`1<string> Prepare(SystemInfo systemInfo, LLamaLogCallback logCallback);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.NativeLibraryMetadata : object {
    [CompilerGeneratedAttribute]
private NativeLibraryName <NativeLibraryName>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <UseCuda>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <UseVulkan>k__BackingField;
    [CompilerGeneratedAttribute]
private AvxLevel <AvxLevel>k__BackingField;
    [CompilerGeneratedAttribute]
protected Type EqualityContract { get; }
    public NativeLibraryName NativeLibraryName { get; public set; }
    public bool UseCuda { get; public set; }
    public bool UseVulkan { get; public set; }
    public AvxLevel AvxLevel { get; public set; }
    public NativeLibraryMetadata(NativeLibraryName NativeLibraryName, bool UseCuda, bool UseVulkan, AvxLevel AvxLevel);
    [CompilerGeneratedAttribute]
protected NativeLibraryMetadata(NativeLibraryMetadata original);
    [CompilerGeneratedAttribute]
protected virtual Type get_EqualityContract();
    [CompilerGeneratedAttribute]
public NativeLibraryName get_NativeLibraryName();
    [CompilerGeneratedAttribute]
public Void modreq(System.Runtime.CompilerServices.IsExternalInit) set_NativeLibraryName(NativeLibraryName value);
    [CompilerGeneratedAttribute]
public bool get_UseCuda();
    [CompilerGeneratedAttribute]
public Void modreq(System.Runtime.CompilerServices.IsExternalInit) set_UseCuda(bool value);
    [CompilerGeneratedAttribute]
public bool get_UseVulkan();
    [CompilerGeneratedAttribute]
public Void modreq(System.Runtime.CompilerServices.IsExternalInit) set_UseVulkan(bool value);
    [CompilerGeneratedAttribute]
public AvxLevel get_AvxLevel();
    [CompilerGeneratedAttribute]
public Void modreq(System.Runtime.CompilerServices.IsExternalInit) set_AvxLevel(AvxLevel value);
    public virtual string ToString();
    [CompilerGeneratedAttribute]
protected virtual bool PrintMembers(StringBuilder builder);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Inequality(NativeLibraryMetadata left, NativeLibraryMetadata right);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Equality(NativeLibraryMetadata left, NativeLibraryMetadata right);
    [CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public virtual bool Equals(NativeLibraryMetadata other);
    [CompilerGeneratedAttribute]
public virtual NativeLibraryMetadata <Clone>$();
    [CompilerGeneratedAttribute]
public void Deconstruct(NativeLibraryName& NativeLibraryName, Boolean& UseCuda, Boolean& UseVulkan, AvxLevel& AvxLevel);
}
public enum LLama.Native.NativeLibraryName : Enum {
    public int value__;
    public static NativeLibraryName LLama;
    public static NativeLibraryName LLava;
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal static class LLama.Native.NativeLibraryUtils : object {
    internal static IntPtr TryLoadLibrary(NativeLibraryConfig config, INativeLibrary& loadedLibrary);
    private static string TryFindPath(string filename, IEnumerable`1<string> searchDirectories);
    private static void Log(string message, LLamaLogLevel level, LLamaLogCallback logCallback);
}
[NullableContextAttribute("2")]
[NullableAttribute("0")]
public static class LLama.Native.NativeLogConfig : object {
    private static Nullable`1<GCHandle> _currentLogCallbackHandle;
    private static void native_llama_log_set(LLamaLogCallback logCallback);
    public static void llama_log_set(LLamaLogCallback logCallback);
    public static void llama_log_set(ILogger logger);
}
public enum LLama.Native.RopeScalingType : Enum {
    public int value__;
    public static RopeScalingType Unspecified;
    public static RopeScalingType None;
    public static RopeScalingType Linear;
    public static RopeScalingType Yarn;
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.SafeLLamaContextHandle : SafeLLamaHandleBase {
    [NullableAttribute("2")]
private SafeLlamaModelHandle _model;
    private static object GlobalInferenceLock;
    public int VocabCount { get; }
    public LLamaVocabType LLamaVocabType { get; }
    public UInt32 ContextSize { get; }
    public int EmbeddingSize { get; }
    public UInt32 BatchSize { get; }
    public UInt32 UBatchSize { get; }
    public UInt32 GenerationThreads { get; public set; }
    public UInt32 BatchThreads { get; public set; }
    public SafeLlamaModelHandle ModelHandle { get; }
    private static SafeLLamaContextHandle();
    public int get_VocabCount();
    public LLamaVocabType get_LLamaVocabType();
    public UInt32 get_ContextSize();
    public int get_EmbeddingSize();
    public UInt32 get_BatchSize();
    public UInt32 get_UBatchSize();
    public UInt32 get_GenerationThreads();
    public void set_GenerationThreads(UInt32 value);
    public UInt32 get_BatchThreads();
    public void set_BatchThreads(UInt32 value);
    public SafeLlamaModelHandle get_ModelHandle();
    protected virtual bool ReleaseHandle();
    private SafeLlamaModelHandle ThrowIfDisposed();
    public static SafeLLamaContextHandle Create(SafeLlamaModelHandle model, LLamaContextParams lparams);
    private static SafeLLamaContextHandle llama_new_context_with_model(SafeLlamaModelHandle model, LLamaContextParams params);
    private static void llama_free(IntPtr ctx);
    private static void llama_set_abort_callback(SafeLLamaContextHandle ctx, GgmlAbortCallback abort_callback, Void* abort_callback_data);
    private static int llama_decode(SafeLLamaContextHandle ctx, LLamaNativeBatch batch);
    private static int llama_encode(SafeLLamaContextHandle ctx, LLamaNativeBatch batch);
    private static void llama_set_n_threads(SafeLLamaContextHandle ctx, UInt32 n_threads, UInt32 n_threads_batch);
    private static UInt32 llama_n_threads(SafeLLamaContextHandle ctx);
    private static UInt32 llama_n_threads_batch(SafeLLamaContextHandle ctx);
    [NullableContextAttribute("0")]
private static Single* llama_get_logits(SafeLLamaContextHandle ctx);
    [NullableContextAttribute("0")]
private static Single* llama_get_logits_ith(SafeLLamaContextHandle ctx, int i);
    private static UInt32 llama_n_ctx(SafeLLamaContextHandle ctx);
    private static UInt32 llama_n_batch(SafeLLamaContextHandle ctx);
    private static UInt32 llama_n_ubatch(SafeLLamaContextHandle ctx);
    private static void llama_set_rng_seed(SafeLLamaContextHandle ctx, UInt32 seed);
    private static ulong llama_state_get_size(SafeLLamaContextHandle ctx);
    [NullableContextAttribute("0")]
private static ulong llama_state_get_data(SafeLLamaContextHandle ctx, Byte* dest);
    [NullableContextAttribute("0")]
private static ulong llama_state_set_data(SafeLLamaContextHandle ctx, Byte* src);
    private static UIntPtr llama_state_seq_get_size(SafeLLamaContextHandle ctx, LLamaSeqId seq_id);
    [NullableContextAttribute("0")]
private static UIntPtr llama_state_seq_get_data(SafeLLamaContextHandle ctx, Byte* dst, LLamaSeqId seq_id);
    [NullableContextAttribute("0")]
private static UIntPtr llama_state_seq_set_data(SafeLLamaContextHandle ctx, Byte* src, LLamaSeqId dest_seq_id);
    private static void llama_kv_cache_defrag(SafeLLamaContextHandle ctx);
    private static void llama_kv_cache_update(SafeLLamaContextHandle ctx);
    private static LLamaTimings llama_get_timings(SafeLLamaContextHandle ctx);
    private static void llama_reset_timings(SafeLLamaContextHandle ctx);
    private static void llama_synchronize(SafeLLamaContextHandle ctx);
    private static int llama_lora_adapter_set(SafeLLamaContextHandle context, IntPtr adapter, float scale);
    private static int llama_lora_adapter_remove(SafeLLamaContextHandle context, IntPtr adapter);
    private static int llama_lora_adapter_clear(SafeLLamaContextHandle context);
    public void AddLoraAdapter(LoraAdapter lora, float scale);
    public bool RemoveLoraAdapter(LoraAdapter lora);
    public void ClearLoraAdapters();
    [NullableContextAttribute("0")]
public Span`1<float> GetLogits();
    [NullableContextAttribute("0")]
public Span`1<float> GetLogitsIth(int i);
    public LLamaToken[] Tokenize(string text, bool add_bos, bool special, Encoding encoding);
    [NullableContextAttribute("0")]
public UInt32 TokenToSpan(LLamaToken token, Span`1<byte> dest);
    public void Synchronize();
    public DecodeResult Decode(LLamaBatch batch);
    internal ValueTuple`2<DecodeResult, int> Decode(List`1<LLamaToken> tokens, LLamaSeqId id, LLamaBatch batch, Int32& n_past);
    public DecodeResult Decode(LLamaBatchEmbeddings batch);
    public ulong GetStateSize();
    public ulong GetStateSize(LLamaSeqId sequence);
    [NullableContextAttribute("0")]
public ulong GetState(Byte* dest, ulong size);
    [NullableContextAttribute("0")]
public ulong GetState(Byte* dest, ulong size, LLamaSeqId sequence);
    [NullableContextAttribute("0")]
public ulong SetState(Byte* src);
    [NullableContextAttribute("0")]
public ulong SetState(Byte* src, LLamaSeqId sequence);
    public void SetSeed(UInt32 seed);
    public LLamaTimings GetTimings();
    public void ResetTimings();
    public void KvCacheUpdate();
    public void KvCacheDefrag();
    public LLamaKvCacheViewSafeHandle KvCacheGetDebugView(int maxSequences);
    public int KvCacheCountCells();
    public int KvCacheCountTokens();
    public void KvCacheClear();
    public void KvCacheRemove(LLamaSeqId seq, LLamaPos p0, LLamaPos p1);
    public void KvCacheSequenceCopy(LLamaSeqId src, LLamaSeqId dest, LLamaPos p0, LLamaPos p1);
    public void KvCacheSequenceKeep(LLamaSeqId seq);
    public void KvCacheSequenceAdd(LLamaSeqId seq, LLamaPos p0, LLamaPos p1, int delta);
    public void KvCacheSequenceDivide(LLamaSeqId seq, LLamaPos p0, LLamaPos p1, int divisor);
    public LLamaPos KvCacheMaxPosition(LLamaSeqId seq);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.SafeLLamaGrammarHandle : SafeLLamaHandleBase {
    protected virtual bool ReleaseHandle();
    public static SafeLLamaGrammarHandle Create(IReadOnlyList`1<GrammarRule> rules, ulong startRuleIndex);
    [NullableContextAttribute("0")]
public static SafeLLamaGrammarHandle Create(LLamaGrammarElement** rules, ulong nrules, ulong startRuleIndex);
    public SafeLLamaGrammarHandle Clone();
    public void AcceptToken(SafeLLamaContextHandle ctx, LLamaToken token);
}
public abstract class LLama.Native.SafeLLamaHandleBase : SafeHandle {
    public bool IsInvalid { get; }
    private protected SafeLLamaHandleBase(IntPtr handle, bool ownsHandle);
    public virtual bool get_IsInvalid();
    [NullableContextAttribute("1")]
public virtual string ToString();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.SafeLlamaModelHandle : SafeLLamaHandleBase {
    [NullableAttribute("2")]
private ModelTokens _tokens;
    public int VocabCount { get; }
    public LLamaVocabType VocabType { get; }
    public LLamaRopeType RopeType { get; }
    public int ContextSize { get; }
    public float RopeFrequency { get; }
    public int EmbeddingSize { get; }
    public ulong SizeInBytes { get; }
    public ulong ParameterCount { get; }
    public int LayerCount { get; }
    public bool HasEncoder { get; }
    public string Description { get; }
    public int MetadataCount { get; }
    public ModelTokens Tokens { get; }
    private static SafeLlamaModelHandle();
    public int get_VocabCount();
    public LLamaVocabType get_VocabType();
    public LLamaRopeType get_RopeType();
    public int get_ContextSize();
    public float get_RopeFrequency();
    public int get_EmbeddingSize();
    public ulong get_SizeInBytes();
    public ulong get_ParameterCount();
    public int get_LayerCount();
    public bool get_HasEncoder();
    public string get_Description();
    public int get_MetadataCount();
    public ModelTokens get_Tokens();
    protected virtual bool ReleaseHandle();
    public static SafeLlamaModelHandle LoadFromFile(string modelPath, LLamaModelParams lparams);
    private static SafeLlamaModelHandle llama_load_model_from_file(string path, LLamaModelParams params);
    private static int llama_model_apply_lora_from_file(SafeLlamaModelHandle model, string path, float scale, string pathBase, int threads);
    private static void llama_free_model(IntPtr model);
    private static int llama_model_meta_count(SafeLlamaModelHandle model);
    [NullableContextAttribute("0")]
private static int llama_model_meta_key_by_index(SafeLlamaModelHandle model, int index, Span`1<byte> dest);
    [NullableContextAttribute("0")]
private static int llama_model_meta_val_str_by_index(SafeLlamaModelHandle model, int index, Span`1<byte> dest);
    private static int llama_model_meta_val_str(SafeLlamaModelHandle model, string key, Span`1<byte> dest);
    private static int llama_n_vocab(SafeLlamaModelHandle model);
    private static LLamaVocabType llama_vocab_type(SafeLlamaModelHandle model);
    private static LLamaRopeType llama_rope_type(SafeLlamaModelHandle model);
    private static int llama_n_ctx_train(SafeLlamaModelHandle model);
    private static int llama_n_embd(SafeLlamaModelHandle model);
    private static int llama_n_layers(SafeLlamaModelHandle model);
    [NullableContextAttribute("0")]
private static int llama_model_desc(SafeLlamaModelHandle model, Byte* buf, IntPtr bufSize);
    private static ulong llama_model_size(SafeLlamaModelHandle model);
    private static ulong llama_model_n_params(SafeLlamaModelHandle model);
    private static float llama_rope_freq_scale_train(SafeLlamaModelHandle model);
    private static LLamaToken llama_token_bos(SafeLlamaModelHandle model);
    private static LLamaToken llama_token_eos(SafeLlamaModelHandle model);
    private static LLamaToken llama_token_cls(SafeLlamaModelHandle model);
    private static LLamaToken llama_token_sep(SafeLlamaModelHandle model);
    private static LLamaToken llama_token_nl(SafeLlamaModelHandle model);
    private static LLamaToken llama_token_pad(SafeLlamaModelHandle model);
    private static int llama_token_prefix(SafeLlamaModelHandle model);
    private static int llama_token_middle(SafeLlamaModelHandle model);
    private static int llama_token_suffix(SafeLlamaModelHandle model);
    private static int llama_token_eot(SafeLlamaModelHandle model);
    private static int llama_model_decoder_start_token(SafeLlamaModelHandle model);
    private static bool llama_token_is_eog(SafeLlamaModelHandle model, LLamaToken token);
    private static bool llama_token_is_control(SafeLlamaModelHandle model, LLamaToken token);
    private static LLamaTokenAttr llama_token_get_attr(SafeLlamaModelHandle model, LLamaToken token);
    private static bool llama_model_has_encoder(SafeLlamaModelHandle model);
    private static IntPtr llama_lora_adapter_init(SafeLlamaModelHandle model, string path);
    public LoraAdapter LoadLoraFromFile(string path);
    [NullableContextAttribute("0")]
public UInt32 TokenToSpan(LLamaToken token, Span`1<byte> dest, int lstrip, bool special);
    [NullableContextAttribute("0")]
[ObsoleteAttribute("Use a StreamingTokenDecoder instead")]
internal Span`1<char> TokensToSpan(IReadOnlyList`1<LLamaToken> tokens, Span`1<char> dest, Encoding encoding);
    public LLamaToken[] Tokenize(string text, bool addBos, bool special, Encoding encoding);
    public SafeLLamaContextHandle CreateContext(LLamaContextParams params);
    [NullableContextAttribute("0")]
public Nullable`1<Memory`1<byte>> MetadataValueByKey(string key);
    [NullableContextAttribute("0")]
public Nullable`1<Memory`1<byte>> MetadataKeyByIndex(int index);
    [NullableContextAttribute("0")]
public Nullable`1<Memory`1<byte>> MetadataValueByIndex(int index);
    internal IReadOnlyDictionary`2<string, string> ReadMetadata();
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
internal static int <llama_model_meta_key_by_index>g__llama_model_meta_key_by_index_native|34_0(SafeLlamaModelHandle model, int index, Byte* buf, IntPtr bufSize);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
internal static int <llama_model_meta_val_str_by_index>g__llama_model_meta_val_str_by_index_native|35_0(SafeLlamaModelHandle model, int index, Byte* buf, IntPtr bufSize);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
internal static int <llama_model_meta_val_str>g__llama_model_meta_val_str_native|36_0(SafeLlamaModelHandle model, Byte* key, Byte* buf, IntPtr bufSize);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.SafeLlavaImageEmbedHandle : SafeLLamaHandleBase {
    [CompilerGeneratedAttribute]
private SafeLlavaModelHandle <Model>k__BackingField;
    public SafeLlavaModelHandle Model { get; private set; }
    public int EmbeddingDimensions { get; }
    public int PatchCount { get; }
    [CompilerGeneratedAttribute]
public SafeLlavaModelHandle get_Model();
    [CompilerGeneratedAttribute]
private void set_Model(SafeLlavaModelHandle value);
    public int get_EmbeddingDimensions();
    public int get_PatchCount();
    public static SafeLlavaImageEmbedHandle CreateFromFileName(SafeLlavaModelHandle clip, LLamaContext ctx, string image);
    public static SafeLlavaImageEmbedHandle CreateFromFileName(SafeLlavaModelHandle clip, string image, int threads);
    public static SafeLlavaImageEmbedHandle CreateFromMemory(SafeLlavaModelHandle clip, LLamaContext ctx, Byte[] image);
    public static SafeLlavaImageEmbedHandle CreateFromMemory(SafeLlavaModelHandle clip, Byte[] image, int threads);
    protected virtual bool ReleaseHandle();
    [NullableContextAttribute("0")]
public void GetEmbedding(Span`1<float> dest, int index);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Native.SafeLlavaModelHandle : SafeLLamaHandleBase {
    public int EmbeddingDimensions { get; }
    public int PatchCount { get; }
    public int get_EmbeddingDimensions();
    public int get_PatchCount();
    protected virtual bool ReleaseHandle();
    public static SafeLlavaModelHandle LoadFromFile(string modelPath, int verbosity);
    public SafeLlavaImageEmbedHandle CreateImageEmbeddings(LLamaContext ctxLlama, string image);
    public SafeLlavaImageEmbedHandle CreateImageEmbeddings(string image, int threads);
    public SafeLlavaImageEmbedHandle CreateImageEmbeddings(LLamaContext ctxLlama, Byte[] image);
    public SafeLlavaImageEmbedHandle CreateImageEmbeddings(Byte[] image, int threads);
    public bool EvalImageEmbed(LLamaContext ctxLlama, SafeLlavaImageEmbedHandle imageEmbed, Int32& n_past);
    private static SafeLlavaModelHandle clip_model_load(string mmProj, int verbosity);
    private static void clip_free(IntPtr ctx);
    private static int clip_n_mmproj_embd(SafeLlavaModelHandle ctx);
    private static int clip_n_patches(SafeLlavaModelHandle ctx);
}
[NullableContextAttribute("2")]
[NullableAttribute("0")]
public class LLama.Native.SystemInfo : object {
    [CompilerGeneratedAttribute]
private OSPlatform <OSPlatform>k__BackingField;
    [CompilerGeneratedAttribute]
private int <CudaMajorVersion>k__BackingField;
    [CompilerGeneratedAttribute]
private string <VulkanVersion>k__BackingField;
    [NullableAttribute("1")]
private static string cudaVersionFile;
    [NullableAttribute("1")]
[CompilerGeneratedAttribute]
protected Type EqualityContract { get; }
    public OSPlatform OSPlatform { get; public set; }
    public int CudaMajorVersion { get; public set; }
    public string VulkanVersion { get; public set; }
    public SystemInfo(OSPlatform OSPlatform, int CudaMajorVersion, string VulkanVersion);
    [CompilerGeneratedAttribute]
protected SystemInfo(SystemInfo original);
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
protected virtual Type get_EqualityContract();
    [CompilerGeneratedAttribute]
public OSPlatform get_OSPlatform();
    [CompilerGeneratedAttribute]
public Void modreq(System.Runtime.CompilerServices.IsExternalInit) set_OSPlatform(OSPlatform value);
    [CompilerGeneratedAttribute]
public int get_CudaMajorVersion();
    [CompilerGeneratedAttribute]
public Void modreq(System.Runtime.CompilerServices.IsExternalInit) set_CudaMajorVersion(int value);
    [CompilerGeneratedAttribute]
public string get_VulkanVersion();
    [CompilerGeneratedAttribute]
public Void modreq(System.Runtime.CompilerServices.IsExternalInit) set_VulkanVersion(string value);
    [NullableContextAttribute("1")]
public static SystemInfo Get();
    private static string GetVulkanVersion();
    private static string GetVulkanSummary();
    [NullableContextAttribute("1")]
private static string ExtractVulkanVersionFromSummary(string vulkanSummary);
    private static int GetCudaMajorVersion();
    [NullableContextAttribute("1")]
private static string GetCudaVersionFromPath(string cudaPath);
    [NullableContextAttribute("1")]
internal static int AddDllDirectory(string NewDirectory);
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
public virtual string ToString();
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
protected virtual bool PrintMembers(StringBuilder builder);
    [CompilerGeneratedAttribute]
public static bool op_Inequality(SystemInfo left, SystemInfo right);
    [CompilerGeneratedAttribute]
public static bool op_Equality(SystemInfo left, SystemInfo right);
    [CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [CompilerGeneratedAttribute]
public virtual bool Equals(SystemInfo other);
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
public virtual SystemInfo <Clone>$();
    [CompilerGeneratedAttribute]
public void Deconstruct(OSPlatform& OSPlatform, Int32& CudaMajorVersion, String& VulkanVersion);
}
public class LLama.Native.UnknownNativeLibrary : object {
    [NullableAttribute("2")]
public NativeLibraryMetadata Metadata { get; }
    [NullableContextAttribute("2")]
public sealed virtual NativeLibraryMetadata get_Metadata();
    [NullableContextAttribute("1")]
public sealed virtual IEnumerable`1<string> Prepare(SystemInfo systemInfo, LLamaLogCallback logCallback);
}
public abstract class LLama.Sampling.BaseSamplingPipeline : object {
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private SafeLLamaGrammarHandle <Grammar>k__BackingField;
    [NullableAttribute("2")]
private LLamaTokenData[] _temporarySampling;
    [NullableAttribute("2")]
public SafeLLamaGrammarHandle Grammar { get; public set; }
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public SafeLLamaGrammarHandle get_Grammar();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public void set_Grammar(SafeLLamaGrammarHandle value);
    public sealed virtual LLamaToken Sample(SafeLLamaContextHandle ctx, Span`1<float> logits, ReadOnlySpan`1<LLamaToken> lastTokens);
    [NullableContextAttribute("1")]
public virtual void Accept(SafeLLamaContextHandle ctx, LLamaToken token);
    protected abstract virtual void ProcessLogits(SafeLLamaContextHandle ctx, Span`1<float> logits, ReadOnlySpan`1<LLamaToken> lastTokens);
    protected abstract virtual LLamaToken ProcessTokenDataArray(SafeLLamaContextHandle ctx, LLamaTokenDataArray candidates, ReadOnlySpan`1<LLamaToken> lastTokens);
    public virtual void Reset();
    [NullableContextAttribute("1")]
public abstract virtual ISamplingPipeline Clone();
    public virtual void Dispose();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Sampling.DefaultSamplingPipeline : BaseSamplingPipeline {
    [CompilerGeneratedAttribute]
private Dictionary`2<LLamaToken, float> <LogitBias>k__BackingField;
    [CompilerGeneratedAttribute]
private float <RepeatPenalty>k__BackingField;
    private float _alphaFreq;
    private float _alphaPresence;
    [CompilerGeneratedAttribute]
private float <Temperature>k__BackingField;
    [CompilerGeneratedAttribute]
private int <TopK>k__BackingField;
    [CompilerGeneratedAttribute]
private float <TailFreeZ>k__BackingField;
    [CompilerGeneratedAttribute]
private float <TypicalP>k__BackingField;
    [CompilerGeneratedAttribute]
private float <TopP>k__BackingField;
    [CompilerGeneratedAttribute]
private float <MinP>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <PenalizeNewline>k__BackingField;
    public Dictionary`2<LLamaToken, float> LogitBias { get; }
    public float RepeatPenalty { get; public set; }
    public float AlphaFrequency { get; public set; }
    public float AlphaPresence { get; public set; }
    public float Temperature { get; public set; }
    public int TopK { get; public set; }
    public float TailFreeZ { get; public set; }
    public float TypicalP { get; public set; }
    public float TopP { get; public set; }
    public float MinP { get; public set; }
    public bool PenalizeNewline { get; public set; }
    [CompilerGeneratedAttribute]
public Dictionary`2<LLamaToken, float> get_LogitBias();
    [CompilerGeneratedAttribute]
public float get_RepeatPenalty();
    [CompilerGeneratedAttribute]
public void set_RepeatPenalty(float value);
    public float get_AlphaFrequency();
    public void set_AlphaFrequency(float value);
    public float get_AlphaPresence();
    public void set_AlphaPresence(float value);
    [CompilerGeneratedAttribute]
public float get_Temperature();
    [CompilerGeneratedAttribute]
public void set_Temperature(float value);
    [CompilerGeneratedAttribute]
public int get_TopK();
    [CompilerGeneratedAttribute]
public void set_TopK(int value);
    [CompilerGeneratedAttribute]
public float get_TailFreeZ();
    [CompilerGeneratedAttribute]
public void set_TailFreeZ(float value);
    [CompilerGeneratedAttribute]
public float get_TypicalP();
    [CompilerGeneratedAttribute]
public void set_TypicalP(float value);
    [CompilerGeneratedAttribute]
public float get_TopP();
    [CompilerGeneratedAttribute]
public void set_TopP(float value);
    [CompilerGeneratedAttribute]
public float get_MinP();
    [CompilerGeneratedAttribute]
public void set_MinP(float value);
    [CompilerGeneratedAttribute]
public bool get_PenalizeNewline();
    [CompilerGeneratedAttribute]
public void set_PenalizeNewline(bool value);
    [NullableContextAttribute("0")]
protected virtual void ProcessLogits(SafeLLamaContextHandle ctx, Span`1<float> logits, ReadOnlySpan`1<LLamaToken> lastTokens);
    [NullableContextAttribute("0")]
protected virtual LLamaToken ProcessTokenDataArray(SafeLLamaContextHandle ctx, LLamaTokenDataArray candidates, ReadOnlySpan`1<LLamaToken> lastTokens);
    [NullableContextAttribute("0")]
private static ValueTuple`2<int, float> GetNewlineLogit(SafeLLamaContextHandle ctx, LLamaTokenDataArray candidates);
    private static void SetNewlineLogit(SafeLLamaContextHandle ctx, LLamaTokenDataArray candidates, int indexHint, float logit);
    public virtual void Accept(SafeLLamaContextHandle ctx, LLamaToken token);
    public virtual ISamplingPipeline Clone();
}
public class LLama.Sampling.GreedySamplingPipeline : BaseSamplingPipeline {
    protected virtual void ProcessLogits(SafeLLamaContextHandle ctx, Span`1<float> logits, ReadOnlySpan`1<LLamaToken> lastTokens);
    protected virtual LLamaToken ProcessTokenDataArray(SafeLLamaContextHandle ctx, LLamaTokenDataArray candidates, ReadOnlySpan`1<LLamaToken> lastTokens);
    [NullableContextAttribute("1")]
public virtual ISamplingPipeline Clone();
}
public interface LLama.Sampling.ISamplingPipeline {
    public abstract virtual LLamaToken Sample(SafeLLamaContextHandle ctx, Span`1<float> logits, ReadOnlySpan`1<LLamaToken> lastTokens);
    [NullableContextAttribute("1")]
public abstract virtual void Accept(SafeLLamaContextHandle ctx, LLamaToken token);
    public abstract virtual void Reset();
    [NullableContextAttribute("1")]
public abstract virtual ISamplingPipeline Clone();
}
[ExtensionAttribute]
public static class LLama.Sampling.ISamplingPipelineExtensions : object {
    [NullableContextAttribute("1")]
[ExtensionAttribute]
public static LLamaToken Sample(ISamplingPipeline pipeline, SafeLLamaContextHandle ctx, Span`1<float> logits, List`1<LLamaToken> lastTokens);
}
public class LLama.Sampling.Mirostat2SamplingPipeline : BaseSamplingPipeline {
    private static float DefaultTau;
    private float _mu;
    private float _tau;
    [CompilerGeneratedAttribute]
private float <Eta>k__BackingField;
    public float Mu { get; }
    public float Tau { get; public set; }
    public float Eta { get; public set; }
    public float get_Mu();
    public float get_Tau();
    public void set_Tau(float value);
    [CompilerGeneratedAttribute]
public float get_Eta();
    [CompilerGeneratedAttribute]
public void set_Eta(float value);
    protected virtual void ProcessLogits(SafeLLamaContextHandle ctx, Span`1<float> logits, ReadOnlySpan`1<LLamaToken> lastTokens);
    protected virtual LLamaToken ProcessTokenDataArray(SafeLLamaContextHandle ctx, LLamaTokenDataArray candidates, ReadOnlySpan`1<LLamaToken> lastTokens);
    public virtual void Reset();
    [NullableContextAttribute("1")]
public virtual ISamplingPipeline Clone();
}
public class LLama.Sampling.MirostatSamplingPipeline : BaseSamplingPipeline {
    private static int MIROSTAT_M;
    private static float DEFAULT_TAU;
    private float _mu;
    private float _tau;
    [CompilerGeneratedAttribute]
private float <Eta>k__BackingField;
    public float Mu { get; }
    public float Tau { get; public set; }
    public float Eta { get; public set; }
    public float get_Mu();
    public float get_Tau();
    public void set_Tau(float value);
    [CompilerGeneratedAttribute]
public float get_Eta();
    [CompilerGeneratedAttribute]
public void set_Eta(float value);
    protected virtual void ProcessLogits(SafeLLamaContextHandle ctx, Span`1<float> logits, ReadOnlySpan`1<LLamaToken> lastTokens);
    protected virtual LLamaToken ProcessTokenDataArray(SafeLLamaContextHandle ctx, LLamaTokenDataArray candidates, ReadOnlySpan`1<LLamaToken> lastTokens);
    public virtual void Reset();
    [NullableContextAttribute("1")]
public virtual ISamplingPipeline Clone();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.SessionState : object {
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private ExecutorBaseState <ExecutorState>k__BackingField;
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private State <ContextState>k__BackingField;
    [CompilerGeneratedAttribute]
private ITextTransform[] <InputTransformPipeline>k__BackingField;
    [CompilerGeneratedAttribute]
private ITextStreamTransform <OutputTransform>k__BackingField;
    [CompilerGeneratedAttribute]
private IHistoryTransform <HistoryTransform>k__BackingField;
    [CompilerGeneratedAttribute]
private Message[] <History>k__BackingField;
    [CompilerGeneratedAttribute]
protected Type EqualityContract { get; }
    [NullableAttribute("2")]
public ExecutorBaseState ExecutorState { get; public set; }
    [NullableAttribute("2")]
public State ContextState { get; public set; }
    public ITextTransform[] InputTransformPipeline { get; public set; }
    public ITextStreamTransform OutputTransform { get; public set; }
    public IHistoryTransform HistoryTransform { get; public set; }
    public Message[] History { get; public set; }
    public SessionState(State contextState, ExecutorBaseState executorState, ChatHistory history, List`1<ITextTransform> inputTransformPipeline, ITextStreamTransform outputTransform, IHistoryTransform historyTransform);
    [CompilerGeneratedAttribute]
protected SessionState(SessionState original);
    [CompilerGeneratedAttribute]
protected virtual Type get_EqualityContract();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public ExecutorBaseState get_ExecutorState();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public void set_ExecutorState(ExecutorBaseState value);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public State get_ContextState();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public void set_ContextState(State value);
    [CompilerGeneratedAttribute]
public ITextTransform[] get_InputTransformPipeline();
    [CompilerGeneratedAttribute]
public void set_InputTransformPipeline(ITextTransform[] value);
    [CompilerGeneratedAttribute]
public ITextStreamTransform get_OutputTransform();
    [CompilerGeneratedAttribute]
public void set_OutputTransform(ITextStreamTransform value);
    [CompilerGeneratedAttribute]
public IHistoryTransform get_HistoryTransform();
    [CompilerGeneratedAttribute]
public void set_HistoryTransform(IHistoryTransform value);
    [CompilerGeneratedAttribute]
public Message[] get_History();
    [CompilerGeneratedAttribute]
public void set_History(Message[] value);
    public void Save(string path);
    public static SessionState Load(string path);
    [CompilerGeneratedAttribute]
public virtual string ToString();
    [CompilerGeneratedAttribute]
protected virtual bool PrintMembers(StringBuilder builder);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Inequality(SessionState left, SessionState right);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public static bool op_Equality(SessionState left, SessionState right);
    [CompilerGeneratedAttribute]
public virtual int GetHashCode();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public virtual bool Equals(object obj);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public virtual bool Equals(SessionState other);
    [CompilerGeneratedAttribute]
public virtual SessionState <Clone>$();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public abstract class LLama.StatefulExecutorBase : object {
    [NullableAttribute("2")]
protected ILogger _logger;
    protected int _pastTokensCount;
    protected int _consumedTokensCount;
    protected int _n_session_consumed;
    protected int _n_matching_session_tokens;
    [NullableAttribute("2")]
protected string _pathSession;
    protected List`1<LLamaToken> _embeds;
    protected List`1<LLamaToken> _embed_inps;
    protected List`1<LLamaToken> _session_tokens;
    protected FixedSizeQueue`1<LLamaToken> _last_n_tokens;
    [CompilerGeneratedAttribute]
private LLamaContext <Context>k__BackingField;
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private LLavaWeights <ClipModel>k__BackingField;
    [CompilerGeneratedAttribute]
private List`1<Byte[]> <Images>k__BackingField;
    private StreamingTokenDecoder _decoder;
    public LLamaContext Context { get; }
    public bool IsMultiModal { get; }
    [NullableAttribute("2")]
public LLavaWeights ClipModel { get; }
    public List`1<Byte[]> Images { get; }
    protected StatefulExecutorBase(LLamaContext context, ILogger logger);
    public StatefulExecutorBase(LLamaContext context, LLavaWeights lLavaWeights, ILogger logger);
    [CompilerGeneratedAttribute]
public sealed virtual LLamaContext get_Context();
    public sealed virtual bool get_IsMultiModal();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public sealed virtual LLavaWeights get_ClipModel();
    [CompilerGeneratedAttribute]
public sealed virtual List`1<Byte[]> get_Images();
    public StatefulExecutorBase WithSessionFile(string filename);
    public void SaveSessionFile(string filename);
    protected virtual void HandleRunOutOfContext(int tokensToKeep);
    protected virtual void TryReuseMatchingPrefix();
    protected abstract virtual Task`1<bool> GetLoopCondition(InferStateArgs args);
    protected abstract virtual Task PreprocessInputs(string text, InferStateArgs args);
    protected abstract virtual Task`1<ValueTuple`2<bool, IReadOnlyList`1<string>>> PostProcess(IInferenceParams inferenceParams, InferStateArgs args);
    protected abstract virtual Task InferInternal(IInferenceParams inferenceParams, InferStateArgs args);
    public abstract virtual Task SaveState(string filename);
    public abstract virtual ExecutorBaseState GetStateData();
    public abstract virtual Task LoadState(ExecutorBaseState data);
    public abstract virtual Task LoadState(string filename);
    [NullableContextAttribute("2")]
[AsyncIteratorStateMachineAttribute("LLama.StatefulExecutorBase/<InferAsync>d__36")]
public virtual IAsyncEnumerable`1<string> InferAsync(string text, IInferenceParams inferenceParams, CancellationToken cancellationToken);
    [AsyncStateMachineAttribute("LLama.StatefulExecutorBase/<PrefillPromptAsync>d__37")]
public virtual Task PrefillPromptAsync(string prompt);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.StatelessExecutor : object {
    private LLamaWeights _weights;
    private IContextParams _params;
    [NullableAttribute("2")]
private ILogger _logger;
    private LLamaBatch _batch;
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private LLavaWeights <ClipModel>k__BackingField;
    [CompilerGeneratedAttribute]
private List`1<Byte[]> <Images>k__BackingField;
    [CompilerGeneratedAttribute]
private LLamaContext <Context>k__BackingField;
    public bool IsMultiModal { get; }
    [NullableAttribute("2")]
public LLavaWeights ClipModel { get; }
    public List`1<Byte[]> Images { get; public set; }
    public LLamaContext Context { get; private set; }
    public StatelessExecutor(LLamaWeights weights, IContextParams params, ILogger logger);
    public sealed virtual bool get_IsMultiModal();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public sealed virtual LLavaWeights get_ClipModel();
    [CompilerGeneratedAttribute]
public sealed virtual List`1<Byte[]> get_Images();
    [CompilerGeneratedAttribute]
public void set_Images(List`1<Byte[]> value);
    [CompilerGeneratedAttribute]
public sealed virtual LLamaContext get_Context();
    [CompilerGeneratedAttribute]
private void set_Context(LLamaContext value);
    [AsyncIteratorStateMachineAttribute("LLama.StatelessExecutor/<InferAsync>d__18")]
public sealed virtual IAsyncEnumerable`1<string> InferAsync(string prompt, IInferenceParams inferenceParams, CancellationToken cancellationToken);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.StreamingTokenDecoder : object {
    private SafeLlamaModelHandle _weights;
    private Decoder _decoder;
    private List`1<char> _characters;
    [CompilerGeneratedAttribute]
private bool <DecodeSpecialTokens>k__BackingField;
    public int AvailableCharacters { get; }
    public bool DecodeSpecialTokens { get; public set; }
    public StreamingTokenDecoder(Encoding encoding, LLamaWeights weights);
    public StreamingTokenDecoder(LLamaContext context);
    public StreamingTokenDecoder(Encoding encoding, SafeLLamaContextHandle context);
    public StreamingTokenDecoder(Encoding encoding, SafeLlamaModelHandle weights);
    public int get_AvailableCharacters();
    [CompilerGeneratedAttribute]
public bool get_DecodeSpecialTokens();
    [CompilerGeneratedAttribute]
public void set_DecodeSpecialTokens(bool value);
    public void Add(LLamaToken token);
    public void Add(int token);
    public void AddRange(T tokens);
    [NullableContextAttribute("0")]
public void AddRange(ReadOnlySpan`1<LLamaToken> tokens);
    public void Read(List`1<char> dest);
    public string Read();
    public void Reset();
    [CompilerGeneratedAttribute]
internal static Span`1<byte> <Add>g__TokenToBytes|13_0(Byte[]& bytes, LLamaToken token, SafeLlamaModelHandle model, bool special);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLama.Transformers.PromptTemplateTransformer : object {
    private LLamaWeights _model;
    private bool _withAssistant;
    public PromptTemplateTransformer(LLamaWeights model, bool withAssistant);
    public sealed virtual string HistoryToText(ChatHistory history);
    public sealed virtual ChatHistory TextToHistory(AuthorRole role, string text);
    public sealed virtual IHistoryTransform Clone();
    public static string ToModelPrompt(LLamaTemplate template);
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
internal class Microsoft.CodeAnalysis.EmbeddedAttribute : Attribute {
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
internal class System.Runtime.CompilerServices.IsByRefLikeAttribute : Attribute {
}
[ExcludeFromCodeCoverageAttribute]
[DebuggerNonUserCodeAttribute]
internal static class System.Runtime.CompilerServices.IsExternalInit : object {
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
internal class System.Runtime.CompilerServices.IsReadOnlyAttribute : Attribute {
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
[AttributeUsageAttribute("27524")]
internal class System.Runtime.CompilerServices.NativeIntegerAttribute : Attribute {
    public Boolean[] TransformFlags;
    public NativeIntegerAttribute(Boolean[] );
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
[AttributeUsageAttribute("27524")]
internal class System.Runtime.CompilerServices.NullableAttribute : Attribute {
    public Byte[] NullableFlags;
    public NullableAttribute(byte );
    public NullableAttribute(Byte[] );
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
[AttributeUsageAttribute("5196")]
internal class System.Runtime.CompilerServices.NullableContextAttribute : Attribute {
    public byte Flag;
    public NullableContextAttribute(byte );
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
[AttributeUsageAttribute("2")]
internal class System.Runtime.CompilerServices.RefSafetyRulesAttribute : Attribute {
    public int Version;
    public RefSafetyRulesAttribute(int );
}
