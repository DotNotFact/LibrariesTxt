[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
public static class LLamaSharp.KernelMemory.BuilderExtensions : object {
    [ExtensionAttribute]
public static IKernelMemoryBuilder WithLLamaSharpTextEmbeddingGeneration(IKernelMemoryBuilder builder, LLamaSharpConfig config);
    [ExtensionAttribute]
public static IKernelMemoryBuilder WithLLamaSharpTextEmbeddingGeneration(IKernelMemoryBuilder builder, LLamaSharpTextEmbeddingGenerator textEmbeddingGenerator);
    [ExtensionAttribute]
public static IKernelMemoryBuilder WithLLamaSharpTextGeneration(IKernelMemoryBuilder builder, LLamaSharpConfig config);
    [ExtensionAttribute]
public static IKernelMemoryBuilder WithLLamaSharpTextGeneration(IKernelMemoryBuilder builder, LlamaSharpTextGenerator textGenerator);
    [ExtensionAttribute]
public static IKernelMemoryBuilder WithLLamaSharpDefaults(IKernelMemoryBuilder builder, LLamaSharpConfig config, LLamaWeights weights, LLamaContext context);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLamaSharp.KernelMemory.LLamaSharpConfig : object {
    [CompilerGeneratedAttribute]
private string <ModelPath>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<UInt32> <ContextSize>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<UInt32> <Seed>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<int> <GpuLayerCount>k__BackingField;
    [CompilerGeneratedAttribute]
private int <MainGpu>k__BackingField;
    [CompilerGeneratedAttribute]
private GPUSplitMode <SplitMode>k__BackingField;
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private InferenceParams <DefaultInferenceParams>k__BackingField;
    public string ModelPath { get; public set; }
    public Nullable`1<UInt32> ContextSize { get; public set; }
    public Nullable`1<UInt32> Seed { get; public set; }
    public Nullable`1<int> GpuLayerCount { get; public set; }
    public int MainGpu { get; public set; }
    public GPUSplitMode SplitMode { get; public set; }
    [NullableAttribute("2")]
public InferenceParams DefaultInferenceParams { get; public set; }
    public LLamaSharpConfig(string modelPath);
    [CompilerGeneratedAttribute]
public string get_ModelPath();
    [CompilerGeneratedAttribute]
public void set_ModelPath(string value);
    [CompilerGeneratedAttribute]
public Nullable`1<UInt32> get_ContextSize();
    [CompilerGeneratedAttribute]
public void set_ContextSize(Nullable`1<UInt32> value);
    [CompilerGeneratedAttribute]
public Nullable`1<UInt32> get_Seed();
    [CompilerGeneratedAttribute]
public void set_Seed(Nullable`1<UInt32> value);
    [CompilerGeneratedAttribute]
public Nullable`1<int> get_GpuLayerCount();
    [CompilerGeneratedAttribute]
public void set_GpuLayerCount(Nullable`1<int> value);
    [CompilerGeneratedAttribute]
public int get_MainGpu();
    [CompilerGeneratedAttribute]
public void set_MainGpu(int value);
    [CompilerGeneratedAttribute]
public GPUSplitMode get_SplitMode();
    [CompilerGeneratedAttribute]
public void set_SplitMode(GPUSplitMode value);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public InferenceParams get_DefaultInferenceParams();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public void set_DefaultInferenceParams(InferenceParams value);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLamaSharp.KernelMemory.LLamaSharpTextEmbeddingGenerator : object {
    [NullableAttribute("2")]
private LLamaWeights _weights;
    private bool _ownsWeights;
    private LLamaEmbedder _embedder;
    private bool _ownsEmbedder;
    [CompilerGeneratedAttribute]
private int <MaxTokens>k__BackingField;
    public int MaxTokens { get; }
    public LLamaSharpTextEmbeddingGenerator(LLamaSharpConfig config);
    public LLamaSharpTextEmbeddingGenerator(LLamaSharpConfig config, LLamaWeights weights);
    public LLamaSharpTextEmbeddingGenerator(LLamaEmbedder embedder);
    [CompilerGeneratedAttribute]
public sealed virtual int get_MaxTokens();
    public sealed virtual void Dispose();
    [AsyncStateMachineAttribute("LLamaSharp.KernelMemory.LLamaSharpTextEmbeddingGenerator/<GenerateEmbeddingAsync>d__11")]
public sealed virtual Task`1<Embedding> GenerateEmbeddingAsync(string text, CancellationToken cancellationToken);
    public sealed virtual int CountTokens(string text);
    public sealed virtual IReadOnlyList`1<string> GetTokens(string text);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class LLamaSharp.KernelMemory.LlamaSharpTextGenerator : object {
    private StatelessExecutor _executor;
    private LLamaWeights _weights;
    private bool _ownsWeights;
    private LLamaContext _context;
    private bool _ownsContext;
    [NullableAttribute("2")]
private InferenceParams _defaultInferenceParams;
    [CompilerGeneratedAttribute]
private int <MaxTokenTotal>k__BackingField;
    public int MaxTokenTotal { get; }
    public LlamaSharpTextGenerator(LLamaSharpConfig config);
    public LlamaSharpTextGenerator(LLamaWeights weights, LLamaContext context, StatelessExecutor executor, InferenceParams inferenceParams);
    [CompilerGeneratedAttribute]
public sealed virtual int get_MaxTokenTotal();
    public sealed virtual void Dispose();
    public sealed virtual IAsyncEnumerable`1<string> GenerateTextAsync(string prompt, TextGenerationOptions options, CancellationToken cancellationToken);
    private static InferenceParams OptionsToParams(TextGenerationOptions options, InferenceParams defaultParams);
    public sealed virtual int CountTokens(string text);
    public sealed virtual IReadOnlyList`1<string> GetTokens(string text);
}
