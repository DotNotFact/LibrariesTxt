[NullableContextAttribute("2")]
[NullableAttribute("0")]
public class Microsoft.ML.Tokenizers.Bpe : Tokenizer {
    private static int MaxWordLengthToCache;
    private string _unknownToken;
    private Nullable`1<int> _unknownTokenId;
    private PreTokenizer _preTokenizer;
    private Normalizer _normalizer;
    [CompilerGeneratedAttribute]
private string <ContinuingSubwordPrefix>k__BackingField;
    [CompilerGeneratedAttribute]
private string <EndOfWordSuffix>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <FuseUnknownTokens>k__BackingField;
    [NullableAttribute("1")]
private Dictionary`2<StringSpanOrdinalKey, int> _vocab;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<string, int> _vocabOriginal;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[CompilerGeneratedAttribute]
private Dictionary`2<Pair`1<int>, ValueTuple`2<int, int>> <Merges>k__BackingField;
    [CompilerGeneratedAttribute]
private StringSpanOrdinalKeyCache`1<Word> <Cache>k__BackingField;
    internal static int DefaultCacheCapacity;
    [NullableAttribute("1")]
[CompilerGeneratedAttribute]
private SortedDictionary`2<int, string> <VocabReverse>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<float> <Dropout>k__BackingField;
    [NullableAttribute("1")]
private Dictionary`2<char, string> _charToString;
    public string UnknownToken { get; private set; }
    public string ContinuingSubwordPrefix { get; }
    public string EndOfWordSuffix { get; }
    public bool FuseUnknownTokens { get; }
    public PreTokenizer PreTokenizer { get; }
    public Normalizer Normalizer { get; }
    [NullableAttribute("1")]
public IReadOnlyDictionary`2<string, int> Vocab { get; }
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
internal Dictionary`2<Pair`1<int>, ValueTuple`2<int, int>> Merges { get; }
    internal StringSpanOrdinalKeyCache`1<Word> Cache { get; }
    [NullableAttribute("1")]
internal SortedDictionary`2<int, string> VocabReverse { get; }
    internal Nullable`1<float> Dropout { get; }
    public Bpe(string vocabFile, string mergesFile, PreTokenizer preTokenizer, Normalizer normalizer, string unknownToken, string continuingSubwordPrefix, string endOfWordSuffix, bool fuseUnknownTokens);
    public Bpe(Stream vocabStream, Stream mergesStream, PreTokenizer preTokenizer, Normalizer normalizer, string unknownToken, string continuingSubwordPrefix, string endOfWordSuffix, bool fuseUnknownTokens);
    private Bpe(Stream vocabStream, Stream mergesStream, PreTokenizer preTokenizer, Normalizer normalizer, string unknownToken, string continuingSubwordPrefix, string endOfWordSuffix, bool fuseUnknownTokens, bool disposeStreams);
    private static Bpe();
    public string get_UnknownToken();
    private void set_UnknownToken(string value);
    [CompilerGeneratedAttribute]
public string get_ContinuingSubwordPrefix();
    [CompilerGeneratedAttribute]
public string get_EndOfWordSuffix();
    [CompilerGeneratedAttribute]
public bool get_FuseUnknownTokens();
    public virtual PreTokenizer get_PreTokenizer();
    public virtual Normalizer get_Normalizer();
    [NullableContextAttribute("1")]
public virtual IReadOnlyList`1<Token> Encode(string text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<Token> Encode(ReadOnlySpan`1<char> text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    private IReadOnlyList`1<Token> Encode(string text, ReadOnlySpan`1<char> textSpan, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("1")]
public virtual IReadOnlyList`1<int> EncodeToIds(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("1")]
public virtual IReadOnlyList`1<int> EncodeToIds(string text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    private IReadOnlyList`1<int> EncodeToIds(string text, ReadOnlySpan`1<char> textSpan, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    [NullableContextAttribute("1")]
public virtual int CountTokens(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int CountTokens(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("1")]
public virtual int IndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int IndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    private int CountTokens(string text, ReadOnlySpan`1<char> textSpan, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    [NullableContextAttribute("1")]
public virtual int LastIndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int LastIndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    private int LastIndexOf(string text, ReadOnlySpan`1<char> textSpan, int maxTokenCount, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& tokenCount);
    [NullableContextAttribute("0")]
public virtual Nullable`1<int> MapTokenToId(ReadOnlySpan`1<char> token);
    public virtual string MapIdToToken(int id);
    [NullableContextAttribute("1")]
public IReadOnlyDictionary`2<string, int> get_Vocab();
    [NullableContextAttribute("1")]
public virtual string Decode(IEnumerable`1<int> ids);
    [NullableContextAttribute("1")]
public string Decode(IEnumerable`1<int> ids, bool considerSpecialTokens);
    [NullableContextAttribute("1")]
internal static ValueTuple`2<Dictionary`2<StringSpanOrdinalKey, int>, Vec`1<ValueTuple`2<string, string>>> ReadModelData(Stream vocab, Stream merges);
    [CompilerGeneratedAttribute]
internal Dictionary`2<Pair`1<int>, ValueTuple`2<int, int>> get_Merges();
    [CompilerGeneratedAttribute]
internal StringSpanOrdinalKeyCache`1<Word> get_Cache();
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
internal SortedDictionary`2<int, string> get_VocabReverse();
    [CompilerGeneratedAttribute]
internal Nullable`1<float> get_Dropout();
    internal static Vec`1<ValueTuple`2<string, string>> ConvertMergesToHashmap(Stream mergesStream);
    [NullableContextAttribute("1")]
internal string CharToString(char c);
    [NullableContextAttribute("0")]
internal Word MergeWord(ReadOnlySpan`1<char> w, PriorityQueue`1& priorityQueue);
    [NullableContextAttribute("1")]
internal void WordToTokens(Word& word, List`1<Token> tokens, int offset);
    [NullableContextAttribute("0")]
internal void EncodeWithCache(ReadOnlySpan`1<char> text, List`1<Token> tokens, int offset, PriorityQueue`1& priorityQueue);
    internal int WordToIds(Word& word, IList`1<int> accumulatedIds, Int32& textLength, int fullTextLength, int maxTokens);
    internal int WordToIdsFromEnd(Word& word, IList`1<int> accumulatedIds, Int32& textIndex, int fullTextLength, int maxTokens);
    private int EncodeToIdsWithCache(ReadOnlySpan`1<char> text, List`1<int> accumulatedIds, int maxTokens, Int32& textLength, PriorityQueue`1& priorityQueue);
    internal int EncodeToIdsFromEndWithCache(ReadOnlySpan`1<char> text, IList`1<int> accumulatedIds, int maxTokens, Int32& textIndex, PriorityQueue`1& priorityQueue);
}
[ExtensionAttribute]
internal static class Microsoft.ML.Tokenizers.BytePairEncoder : object {
    public static ValueTuple`3[] BytePairEncode(ReadOnlyMemory`1<byte> mergingBytes, IReadOnlyDictionary`2<ReadOnlyMemory`1<byte>, int> ranks, ReadOnlySpan`1<int> indexMappingSpan);
    [ExtensionAttribute]
private static ReadOnlyMemory`1<byte> SliceStartEnd(ReadOnlyMemory`1<byte> memory, int start, int end);
    [CompilerGeneratedAttribute]
internal static int <BytePairEncode>g__GetRank|0_0(Span`1<ValueTuple`2<int, int>> byteIndicesAndRanks, int startIndex, int skip, <>c__DisplayClass0_0& );
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal class Microsoft.ML.Tokenizers.ByteToUnicodeEncoding : object {
    [CompilerGeneratedAttribute]
private static ByteToUnicodeEncoding <Instance>k__BackingField;
    [CompilerGeneratedAttribute]
private IReadOnlyDictionary`2<char, char> <ByteToUnicode>k__BackingField;
    [CompilerGeneratedAttribute]
private IReadOnlyDictionary`2<char, char> <UnicodeToByte>k__BackingField;
    [CompilerGeneratedAttribute]
private String[] <CharToString>k__BackingField;
    public static ByteToUnicodeEncoding Instance { get; }
    public IReadOnlyDictionary`2<char, char> ByteToUnicode { get; }
    public IReadOnlyDictionary`2<char, char> UnicodeToByte { get; }
    public String[] CharToString { get; }
    private static ByteToUnicodeEncoding();
    [CompilerGeneratedAttribute]
public static ByteToUnicodeEncoding get_Instance();
    [CompilerGeneratedAttribute]
public IReadOnlyDictionary`2<char, char> get_ByteToUnicode();
    [CompilerGeneratedAttribute]
public IReadOnlyDictionary`2<char, char> get_UnicodeToByte();
    [CompilerGeneratedAttribute]
public String[] get_CharToString();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal class Microsoft.ML.Tokenizers.Cache`2 : object {
    private int _capacity;
    private Dictionary`2<TKey, TValue> _map;
    private object SyncObj { get; }
    internal Cache`2(int capacity);
    private object get_SyncObj();
    internal bool TryGetValue(TKey key, TValue& value);
    internal TValue GetOrAdd(TKey key, TValue value);
    internal void Set(TKey key, TValue value);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class Microsoft.ML.Tokenizers.CodeGen : Tokenizer {
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>> _vocab;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private IReadOnlyDictionary`2<string, int> _vocabOriginal;
    private IReadOnlyDictionary`2<int, string> _vocabReverse;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>> _addedTokens;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<int, string> _addedTokensReverse;
    private Dictionary`2<StringSpanOrdinalKeyPair, int> _mergeRanks;
    private StringSpanOrdinalKeyCache`1<List`1<Token>> _cache;
    [NullableAttribute("2")]
private PreTokenizer _preTokenizer;
    [NullableAttribute("2")]
private Normalizer _normalizer;
    private static int MaxTokenLengthToCache;
    private static string DefaultSpecialToken;
    private static int BufferLength;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[CompilerGeneratedAttribute]
private IReadOnlyDictionary`2<string, int> <AddedTokens>k__BackingField;
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private string <UnknownToken>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<int> <UnknownTokenId>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <AddBeginningOfSentence>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <AddEndOfSentence>k__BackingField;
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private string <BeginningOfSentenceToken>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<int> <BeginningOfSentenceId>k__BackingField;
    [CompilerGeneratedAttribute]
private Nullable`1<int> <EndOfSentenceId>k__BackingField;
    [NullableAttribute("2")]
[CompilerGeneratedAttribute]
private string <EndOfSentenceToken>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <AddPrefixSpace>k__BackingField;
    private static char _transformedSpace;
    internal static Dictionary`2<string, int> CodeGenAddedTokens;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
public IReadOnlyDictionary`2<string, int> AddedTokens { get; }
    [NullableAttribute("2")]
public string UnknownToken { get; }
    public Nullable`1<int> UnknownTokenId { get; }
    public bool AddBeginningOfSentence { get; }
    public bool AddEndOfSentence { get; }
    [NullableAttribute("2")]
public string BeginningOfSentenceToken { get; }
    public Nullable`1<int> BeginningOfSentenceId { get; }
    public Nullable`1<int> EndOfSentenceId { get; }
    [NullableAttribute("2")]
public string EndOfSentenceToken { get; }
    public bool AddPrefixSpace { get; }
    [NullableAttribute("2")]
public PreTokenizer PreTokenizer { get; }
    [NullableAttribute("2")]
public Normalizer Normalizer { get; }
    public IReadOnlyDictionary`2<string, int> Vocab { get; }
    [NullableContextAttribute("2")]
public CodeGen(string vocabularyPath, string mergePath, PreTokenizer preTokenizer, Normalizer normalizer, IReadOnlyDictionary`2<string, int> addedTokens, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, string unknownToken, string beginningOfSentenceToken, string endOfSentenceToken);
    [NullableContextAttribute("2")]
public CodeGen(Stream vocabularyStream, Stream mergeStream, PreTokenizer preTokenizer, Normalizer normalizer, IReadOnlyDictionary`2<string, int> addedTokens, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, string unknownToken, string beginningOfSentenceToken, string endOfSentenceToken);
    [NullableContextAttribute("2")]
private CodeGen(Stream vocabularyStream, Stream mergeStream, PreTokenizer preTokenizer, Normalizer normalizer, IReadOnlyDictionary`2<string, int> addedTokens, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, string unknownToken, string beginningOfSentenceToken, string endOfSentenceToken, bool disposeStream);
    private static CodeGen();
    [CompilerGeneratedAttribute]
public IReadOnlyDictionary`2<string, int> get_AddedTokens();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public string get_UnknownToken();
    [CompilerGeneratedAttribute]
public Nullable`1<int> get_UnknownTokenId();
    [CompilerGeneratedAttribute]
public bool get_AddBeginningOfSentence();
    [CompilerGeneratedAttribute]
public bool get_AddEndOfSentence();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public string get_BeginningOfSentenceToken();
    [CompilerGeneratedAttribute]
public Nullable`1<int> get_BeginningOfSentenceId();
    [CompilerGeneratedAttribute]
public Nullable`1<int> get_EndOfSentenceId();
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
public string get_EndOfSentenceToken();
    [CompilerGeneratedAttribute]
public bool get_AddPrefixSpace();
    [NullableContextAttribute("2")]
public virtual PreTokenizer get_PreTokenizer();
    [NullableContextAttribute("2")]
public virtual Normalizer get_Normalizer();
    public IReadOnlyDictionary`2<string, int> get_Vocab();
    public virtual IReadOnlyList`1<Token> Encode(string text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<Token> Encode(ReadOnlySpan`1<char> text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    public IReadOnlyList`1<Token> Encode(string text, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public IReadOnlyList`1<Token> Encode(ReadOnlySpan`1<char> text, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private IReadOnlyList`1<Token> Encode(string text, ReadOnlySpan`1<char> textSpan, bool addPrefixSpace, bool addBos, bool addEos, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    private void EncodeInternal(string text, ReadOnlySpan`1<char> textSpan, List`1<Token> tokens, bool addPrefixSpace, int offset, PriorityQueue`1<SymbolPair> agenda);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public IReadOnlyList`1<int> EncodeToIds(string text, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    public IReadOnlyList`1<int> EncodeToIds(string text, int maxTokenCount, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, int maxTokenCount, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private IReadOnlyList`1<int> EncodeToIds(string text, ReadOnlySpan`1<char> textSpan, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    public virtual int CountTokens(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int CountTokens(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public int CountTokens(string text, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public int CountTokens(ReadOnlySpan`1<char> text, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    public virtual int IndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int IndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    public int IndexOfTokenCount(string text, int maxTokenCount, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public int IndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private int CountTokens(string text, ReadOnlySpan`1<char> textSpan, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    public virtual int LastIndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int LastIndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    public int LastIndexOfTokenCount(string text, int maxTokenCount, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public int LastIndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private int LastIndexOf(string text, ReadOnlySpan`1<char> textSpan, int maxTokenCount, bool addPrefixSpace, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& tokenCount);
    private int EncodeToIdsResult(List`1<Token> tokens, IList`1<int> accumulatedIds, int maxTokens, int fullTextLength, Int32& textLength);
    private int EncodeToIdsFromEndResult(List`1<Token> tokens, IList`1<int> accumulatedIds, int maxTokens, int fullTextLength, Int32& textIndex);
    [NullableContextAttribute("2")]
private int EncodeToIdsInternal(string text, ReadOnlySpan`1<char> textSpan, IList`1<int> accumulatedIds, PriorityQueue`1<SymbolPair> agenda, Int32& textLength, int maxTokens);
    [NullableContextAttribute("2")]
private int EncodeToIdsFromEndInternal(string text, ReadOnlySpan`1<char> textSpan, IList`1<int> accumulatedIds, PriorityQueue`1<SymbolPair> agenda, Int32& textIndex, int maxTokens);
    [NullableContextAttribute("2")]
public virtual string MapIdToToken(int id);
    [NullableContextAttribute("0")]
public virtual Nullable`1<int> MapTokenToId(ReadOnlySpan`1<char> token);
    public virtual string Decode(IEnumerable`1<int> ids);
    public string Decode(IEnumerable`1<int> ids, bool hasPrefixSpace, bool considerSpecialTokens);
    [NullableContextAttribute("0")]
private void AppendToBytesArray(ReadOnlySpan`1<char> text, Byte[]& bytes, Int32& bytesIndex);
    private static void AppendTokenWithOffsetAdjusting(IReadOnlyList`1<Token> tokensToAdd, List`1<Token> tokens, int offset, bool addPrefixSpace);
    [NullableContextAttribute("0")]
private List`1<Token> EncodeToTokens(Span`1<char> text, Span`1<int> mapping, ReadOnlySpan`1<char> originalText, PriorityQueue`1<SymbolPair> agenda);
    private static Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>> GetVocabulary(Stream vocabularyStream);
    internal static Dictionary`2<StringSpanOrdinalKeyPair, int> GetMergeRanks(Stream mergeStream);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
internal static Token <EncodeToTokens>g__GetToken|91_0(int id, string token, int index, int length, ReadOnlySpan`1<char> originalText, Span`1<int> mapping);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private void <EncodeToTokens>g__TryMerge|91_1(int left, int right, ReadOnlySpan`1<char> textSpan, <>c__DisplayClass91_0& );
}
[NullableContextAttribute("1")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
internal class Microsoft.ML.Tokenizers.DictReversingConverter : JsonConverter`1<SortedDictionary`2<int, string>> {
    public virtual SortedDictionary`2<int, string> Read(Utf8JsonReader& reader, Type typeToConvert, JsonSerializerOptions options);
    public virtual void Write(Utf8JsonWriter writer, SortedDictionary`2<int, string> value, JsonSerializerOptions options);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class Microsoft.ML.Tokenizers.EnglishRoberta : Tokenizer {
    private HighestOccurrenceMapping _vocabIdToHighestOccurrence;
    private Dictionary`2<StringSpanOrdinalKey, int> _vocab;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<string, int> _vocabOriginal;
    private SortedDictionary`2<int, StringSpanOrdinalKey> _vocabReverse;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Cache`2<ValueTuple`2<string, string>, int> _mergeRanks;
    private StringSpanOrdinalKeyCache`1<List`1<Token>> _cache;
    [NullableAttribute("2")]
private PreTokenizer _preTokenizer;
    [NullableAttribute("2")]
private Normalizer _normalizer;
    [CompilerGeneratedAttribute]
private bool <FilterUnsupportedChars>k__BackingField;
    public bool FilterUnsupportedChars { get; }
    [NullableAttribute("2")]
public PreTokenizer PreTokenizer { get; }
    [NullableAttribute("2")]
public Normalizer Normalizer { get; }
    public IReadOnlyDictionary`2<string, int> Vocab { get; }
    public int PadIndex { get; }
    public int SymbolsCount { get; }
    public EnglishRoberta(string vocabularyPath, string mergePath, string highestOccurrenceMappingPath, PreTokenizer preTokenizer, Normalizer normalizer, bool filterUnsupportedChars);
    public EnglishRoberta(Stream vocabularyStream, Stream mergeStream, Stream highestOccurrenceMappingStream, PreTokenizer preTokenizer, Normalizer normalizer, bool filterUnsupportedChars);
    public EnglishRoberta(Stream vocabularyStream, Stream mergeStream, Stream highestOccurrenceMappingStream, PreTokenizer preTokenizer, Normalizer normalizer, bool filterUnsupportedChars, bool disposeStream);
    [CompilerGeneratedAttribute]
public bool get_FilterUnsupportedChars();
    private static Dictionary`2<StringSpanOrdinalKey, int> GetVocabulary(Stream vocabularyStream);
    private static Cache`2<ValueTuple`2<string, string>, int> GetMergeRanks(Stream mergeStream);
    private Dictionary`2<string, int> GetVocab();
    [NullableContextAttribute("2")]
public virtual PreTokenizer get_PreTokenizer();
    [NullableContextAttribute("2")]
public virtual Normalizer get_Normalizer();
    public IReadOnlyDictionary`2<string, int> get_Vocab();
    [NullableContextAttribute("2")]
public virtual string MapIdToToken(int id);
    public virtual IReadOnlyList`1<Token> Encode(string text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<Token> Encode(ReadOnlySpan`1<char> text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private IReadOnlyList`1<Token> Encode(string text, ReadOnlySpan`1<char> textSpan, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
private IReadOnlyList`1<Token> EncodeInternal(ReadOnlySpan`1<char> text);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private IReadOnlyList`1<int> EncodeToIds(string text, ReadOnlySpan`1<char> textSpan, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    public virtual int CountTokens(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int CountTokens(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public virtual int IndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int IndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private int CountTokens(string text, ReadOnlySpan`1<char> textSpan, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    public virtual int LastIndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int LastIndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private int LastIndexOf(string text, ReadOnlySpan`1<char> textSpan, int maxTokenCount, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& tokenCount);
    private int EncodeToIdsResult(List`1<Token> tokens, IList`1<int> accumulatedIds, int maxTokens, int fullTextLength, Int32& textLength);
    private int EncodeToIdsFromEndResult(List`1<Token> tokens, IList`1<int> accumulatedIds, int maxTokens, int fullTextLength, Int32& textIndex);
    [NullableContextAttribute("0")]
private int EncodeToIdsInternal(ReadOnlySpan`1<char> text, IList`1<int> accumulatedIds, Int32& textLength, int maxTokens);
    [NullableContextAttribute("0")]
private int EncodeToIdsFromEndInternal(ReadOnlySpan`1<char> text, IList`1<int> accumulatedIds, Int32& textIndex, int maxTokens);
    [NullableContextAttribute("0")]
public virtual Nullable`1<int> MapTokenToId(ReadOnlySpan`1<char> token);
    public virtual string Decode(IEnumerable`1<int> ids);
    public IReadOnlyList`1<int> ConvertIdsToOccurrenceRanks(IReadOnlyList`1<int> ids);
    public IReadOnlyList`1<int> ConvertIdsToOccurrenceValues(IReadOnlyList`1<int> ids);
    public IReadOnlyList`1<int> ConvertOccurrenceRanksToIds(IReadOnlyList`1<int> ranks);
    public int get_PadIndex();
    public int get_SymbolsCount();
    public int AddMaskSymbol(string mask);
    private IReadOnlyList`1<Token> ModifyTokenListOffsets(IReadOnlyList`1<Token> tokens, Span`1<int> indexMapping);
    private static HighestOccurrenceMapping GetHighestOccurrenceMapping(Stream highestOccurrenceMappingStream);
    [NullableContextAttribute("0")]
private List`1<Token> EncodeToTokens(Span`1<char> token, Span`1<int> indexMapping);
    private static void WordToPairs(IReadOnlyList`1<string> word, HashSet`1<ValueTuple`2<string, string>> pairs);
    public bool IsSupportedChar(char ch);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private int <EncodeToTokens>b__57_0(ValueTuple`2<string, string> pair);
}
internal static class Microsoft.ML.Tokenizers.Helpers : object {
    [NullableContextAttribute("1")]
internal static void ArrayPoolGrow(T[]& arrayPoolArray, int requiredCapacity);
    internal static int EncodeToUtf8(ReadOnlySpan`1<char> text, Span`1<byte> destination, Span`1<int> indexMapping);
    internal static int EncodeToUtf8AndTransform(ReadOnlySpan`1<char> text, Span`1<char> destination, Span`1<int> indexMapping);
    [NullableContextAttribute("1")]
public static ValueTask`1<string> ReadLineAsync(StreamReader reader, CancellationToken cancellationToken);
    [NullableContextAttribute("1")]
public static Task`1<Stream> GetStreamAsync(HttpClient client, string url, CancellationToken cancellationToken);
    [NullableContextAttribute("1")]
public static Stream GetStream(HttpClient client, string url);
    [NullableContextAttribute("1")]
public static Byte[] FromBase64String(string base64String, int offset, int length);
    [NullableContextAttribute("1")]
internal static bool TryParseInt32(string s, int offset, Int32& result);
    internal static int GetHashCode(ReadOnlySpan`1<char> span);
    internal static int GetUtf8Bytes(ReadOnlySpan`1<char> source, Span`1<byte> destination);
    internal static bool TryGetUtf8Bytes(ReadOnlySpan`1<char> source, Span`1<byte> destination, Int32& bytesWritten);
    internal static string GetString(ReadOnlySpan`1<byte> utf8Bytes);
    internal static int GetChars(ReadOnlySpan`1<byte> bytes, Span`1<char> chars);
    internal static void Replace(Span`1<char> span, char oldValue, char newValue);
    internal static int EncodeCodePointToUtf8(ReadOnlySpan`1<char> text, int textIndex, Byte[]& destination, Int32& bytesIndex);
}
[NullableContextAttribute("2")]
[NullableAttribute("0")]
[DefaultMemberAttribute("Item")]
internal class Microsoft.ML.Tokenizers.HighestOccurrenceMapping : object {
    public static int NumSpecialSymbols;
    [CompilerGeneratedAttribute]
private string <PadWord>k__BackingField;
    [CompilerGeneratedAttribute]
private string <EosWord>k__BackingField;
    [CompilerGeneratedAttribute]
private string <UnkWord>k__BackingField;
    [CompilerGeneratedAttribute]
private string <BosWord>k__BackingField;
    [CompilerGeneratedAttribute]
private int <PadIndex>k__BackingField;
    [CompilerGeneratedAttribute]
private int <EosIndex>k__BackingField;
    [CompilerGeneratedAttribute]
private int <UnkIndex>k__BackingField;
    [CompilerGeneratedAttribute]
private int <BosIndex>k__BackingField;
    [CompilerGeneratedAttribute]
private string <MaskWord>k__BackingField;
    [CompilerGeneratedAttribute]
private int <MaskIndex>k__BackingField;
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private List`1<ValueTuple`2<int, int>> _symbols;
    [NullableAttribute("1")]
private Dictionary`2<int, int> _idToIndex;
    [NullableAttribute("1")]
private Dictionary`2<string, int> _stringSymbolToIndexMapping;
    public string PadWord { get; }
    public string EosWord { get; }
    public string UnkWord { get; }
    public string BosWord { get; }
    public int PadIndex { get; }
    public int EosIndex { get; }
    public int UnkIndex { get; }
    public int BosIndex { get; }
    public string MaskWord { get; private set; }
    public int MaskIndex { get; private set; }
    public int Item { get; }
    public int Count { get; }
    [NullableContextAttribute("1")]
public HighestOccurrenceMapping(string pad, string eos, string unk, string bos, String[] extraSpecialSymbols);
    [CompilerGeneratedAttribute]
public string get_PadWord();
    [CompilerGeneratedAttribute]
public string get_EosWord();
    [CompilerGeneratedAttribute]
public string get_UnkWord();
    [CompilerGeneratedAttribute]
public string get_BosWord();
    [CompilerGeneratedAttribute]
public int get_PadIndex();
    [CompilerGeneratedAttribute]
public int get_EosIndex();
    [CompilerGeneratedAttribute]
public int get_UnkIndex();
    [CompilerGeneratedAttribute]
public int get_BosIndex();
    [CompilerGeneratedAttribute]
public string get_MaskWord();
    [CompilerGeneratedAttribute]
private void set_MaskWord(string value);
    [CompilerGeneratedAttribute]
public int get_MaskIndex();
    [CompilerGeneratedAttribute]
private void set_MaskIndex(int value);
    public int IdToOccurrenceRank(int id);
    public int IdToOccurrenceValue(int id);
    public int ConvertOccurrenceRankToId(int rank);
    [NullableContextAttribute("1")]
private int ReserveStringSymbolSlot(string symbol, int defaultOccurrence);
    public int AddSymbol(int id, int highOccurrenceScore);
    [NullableContextAttribute("1")]
public int AddMaskSymbol(string mask);
    public int get_Item(int idx);
    public int get_Count();
    [NullableContextAttribute("1")]
public bool Equals(HighestOccurrenceMapping other);
    [NullableContextAttribute("1")]
public bool Contains(string symbol);
    public bool Contains(int id);
    public int IndexOf(int id);
    [NullableContextAttribute("1")]
public static HighestOccurrenceMapping Load(Stream stream);
    [NullableContextAttribute("1")]
public void AddFromStream(Stream stream);
}
[ExtensionAttribute]
internal static class Microsoft.ML.Tokenizers.IListExtensions : object {
    [NullableContextAttribute("1")]
[ExtensionAttribute]
public static void AddRange(IList`1<T> list, IEnumerable`1<T> items);
}
public class Microsoft.ML.Tokenizers.LowerCaseNormalizer : Normalizer {
    [NullableContextAttribute("1")]
public virtual string Normalize(string original);
    public virtual string Normalize(ReadOnlySpan`1<char> original);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal class Microsoft.ML.Tokenizers.LruCache`1 : object {
    public static int DefaultCacheSize;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<StringSpanOrdinalKey, LinkedListNode`1<KeyValuePair`2<string, TValue>>> _cache;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private LinkedList`1<KeyValuePair`2<string, TValue>> _lruList;
    private int _cacheSize;
    private object SyncObj { get; }
    public LruCache`1(int cacheSize);
    private object get_SyncObj();
    public bool TryGetValue(string key, TValue& value);
    [NullableContextAttribute("0")]
public bool TryGetValue(ReadOnlySpan`1<char> key, TValue& value);
    public void Add(string key, TValue value);
}
internal class Microsoft.ML.Tokenizers.Merge : ValueType {
    [CompilerGeneratedAttribute]
private int <Pos>k__BackingField;
    [CompilerGeneratedAttribute]
private int <Rank>k__BackingField;
    [CompilerGeneratedAttribute]
private int <NewId>k__BackingField;
    public int Pos { get; public set; }
    public int Rank { get; public set; }
    public int NewId { get; public set; }
    public Merge(int pos, int rank, int newId);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public int get_Pos();
    [CompilerGeneratedAttribute]
public void set_Pos(int value);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public int get_Rank();
    [CompilerGeneratedAttribute]
public void set_Rank(int value);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public int get_NewId();
    [CompilerGeneratedAttribute]
public void set_NewId(int value);
    public sealed virtual int CompareTo(Merge other);
    public virtual int GetHashCode();
    public sealed virtual bool Equals(Merge other);
}
public abstract class Microsoft.ML.Tokenizers.Normalizer : object {
    [NullableContextAttribute("1")]
public abstract virtual string Normalize(string original);
    public abstract virtual string Normalize(ReadOnlySpan`1<char> original);
}
internal class Microsoft.ML.Tokenizers.Pair`1 : ValueType {
    [CompilerGeneratedAttribute]
private T <First>k__BackingField;
    [CompilerGeneratedAttribute]
private T <Second>k__BackingField;
    public T First { get; public set; }
    public T Second { get; public set; }
    public Pair`1(T first, T second);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public T get_First();
    [CompilerGeneratedAttribute]
public void set_First(T value);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
public T get_Second();
    [CompilerGeneratedAttribute]
public void set_Second(T value);
    public static Pair`1<T> Create(T first, T second);
    public sealed virtual bool Equals(Pair`1<T> other);
    public virtual int GetHashCode();
    public sealed virtual int CompareTo(Pair`1<T> other);
}
public abstract class Microsoft.ML.Tokenizers.PreTokenizer : object {
    [NullableContextAttribute("1")]
public abstract virtual IEnumerable`1<ValueTuple`2<int, int>> PreTokenize(string text);
    public abstract virtual IEnumerable`1<ValueTuple`2<int, int>> PreTokenize(ReadOnlySpan`1<char> text);
    [NullableContextAttribute("1")]
[IteratorStateMachineAttribute("Microsoft.ML.Tokenizers.PreTokenizer/<SplitText>d__2")]
internal static IEnumerable`1<ValueTuple`2<int, int>> SplitText(string text, Regex regex);
    internal static IEnumerable`1<ValueTuple`2<int, int>> SplitText(ReadOnlySpan`1<char> text, Regex regex);
    [NullableContextAttribute("1")]
internal static bool TryGetMatch(Regex regex, string text, int beginning, int length, ValueTuple`2& match);
    internal static bool TryGetMatch(Regex regex, ReadOnlySpan`1<char> text, int beginning, int length, ValueTuple`2& match);
    [NullableContextAttribute("1")]
[IteratorStateMachineAttribute("Microsoft.ML.Tokenizers.PreTokenizer/<<SplitText>g__SplitText|3_0>d")]
[CompilerGeneratedAttribute]
internal static IEnumerable`1<ValueTuple`2<int, int>> <SplitText>g__SplitText|3_0(Char[] text, Regex regex, int textLength);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal class Microsoft.ML.Tokenizers.PriorityQueue`1 : object {
    private List`1<T> _data;
    public int Count { get; }
    public PriorityQueue`1(int capacity);
    public void Enqueue(T item);
    public T Dequeue();
    public T Peek();
    public int get_Count();
    public virtual string ToString();
    public void Clear();
    public bool IsConsistent();
}
internal class Microsoft.ML.Tokenizers.ReadOnlyMemoryByteComparer : object {
    [NullableAttribute("1")]
[CompilerGeneratedAttribute]
private static ReadOnlyMemoryByteComparer <Instance>k__BackingField;
    [NullableAttribute("1")]
public static ReadOnlyMemoryByteComparer Instance { get; }
    private static ReadOnlyMemoryByteComparer();
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
public static ReadOnlyMemoryByteComparer get_Instance();
    public sealed virtual bool Equals(ReadOnlyMemory`1<byte> x, ReadOnlyMemory`1<byte> y);
    public sealed virtual int GetHashCode(ReadOnlyMemory`1<byte> x);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class Microsoft.ML.Tokenizers.RobertaPreTokenizer : PreTokenizer {
    [CompilerGeneratedAttribute]
private static RobertaPreTokenizer <Instance>k__BackingField;
    public static RobertaPreTokenizer Instance { get; }
    private static RobertaPreTokenizer();
    [CompilerGeneratedAttribute]
public static RobertaPreTokenizer get_Instance();
    public virtual IEnumerable`1<ValueTuple`2<int, int>> PreTokenize(string text);
    [NullableContextAttribute("0")]
public virtual IEnumerable`1<ValueTuple`2<int, int>> PreTokenize(ReadOnlySpan`1<char> text);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class Microsoft.ML.Tokenizers.SentencePieceBpe : Tokenizer {
    private static int UninitializedId;
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<StringSpanOrdinalKey, ValueTuple`3<int, float, byte>> _vocab;
    private Dictionary`2<int, string> _vocabReverse;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<string, int> _publicVocab;
    private int _maxByteId;
    private int _byteCodeToIdOffset;
    private int _oneByteUtf8EncodingMaxId;
    [NullableAttribute("2")]
private Normalizer _normalizer;
    [CompilerGeneratedAttribute]
private bool <ByteFallback>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <AddDummyPrefix>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <EscapeWhiteSpaces>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <TreatWhitespaceAsSuffix>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <AddBeginningOfSentence>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <AddEndOfSentence>k__BackingField;
    [CompilerGeneratedAttribute]
private string <BeginningOfSentenceToken>k__BackingField;
    [CompilerGeneratedAttribute]
private string <EndOfSentenceToken>k__BackingField;
    [CompilerGeneratedAttribute]
private string <UnknownToken>k__BackingField;
    [CompilerGeneratedAttribute]
private int <BeginningOfSentenceId>k__BackingField;
    [CompilerGeneratedAttribute]
private int <EndOfSentenceId>k__BackingField;
    [CompilerGeneratedAttribute]
private int <UnknownId>k__BackingField;
    public bool ByteFallback { get; }
    public bool AddDummyPrefix { get; }
    public bool EscapeWhiteSpaces { get; }
    public bool TreatWhitespaceAsSuffix { get; }
    public bool AddBeginningOfSentence { get; }
    public bool AddEndOfSentence { get; }
    public string BeginningOfSentenceToken { get; }
    public string EndOfSentenceToken { get; }
    public string UnknownToken { get; }
    public int BeginningOfSentenceId { get; }
    public int EndOfSentenceId { get; }
    public int UnknownId { get; }
    [NullableAttribute("2")]
public PreTokenizer PreTokenizer { get; }
    [NullableAttribute("2")]
public Normalizer Normalizer { get; }
    public IReadOnlyDictionary`2<string, int> Vocab { get; }
    internal SentencePieceBpe(ModelProto modelProto, bool addBos, bool addEos);
    private SentencePieceBpe(ModelProto modelProto);
    [CompilerGeneratedAttribute]
public bool get_ByteFallback();
    [CompilerGeneratedAttribute]
public bool get_AddDummyPrefix();
    [CompilerGeneratedAttribute]
public bool get_EscapeWhiteSpaces();
    [CompilerGeneratedAttribute]
public bool get_TreatWhitespaceAsSuffix();
    [CompilerGeneratedAttribute]
public bool get_AddBeginningOfSentence();
    [CompilerGeneratedAttribute]
public bool get_AddEndOfSentence();
    [CompilerGeneratedAttribute]
public string get_BeginningOfSentenceToken();
    [CompilerGeneratedAttribute]
public string get_EndOfSentenceToken();
    [CompilerGeneratedAttribute]
public string get_UnknownToken();
    [CompilerGeneratedAttribute]
public int get_BeginningOfSentenceId();
    [CompilerGeneratedAttribute]
public int get_EndOfSentenceId();
    [CompilerGeneratedAttribute]
public int get_UnknownId();
    [NullableContextAttribute("2")]
public virtual PreTokenizer get_PreTokenizer();
    [NullableContextAttribute("2")]
public virtual Normalizer get_Normalizer();
    public IReadOnlyDictionary`2<string, int> get_Vocab();
    public virtual IReadOnlyList`1<Token> Encode(string text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<Token> Encode(ReadOnlySpan`1<char> text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    public IReadOnlyList`1<Token> Encode(string text, String& normalizedString, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public IReadOnlyList`1<Token> Encode(ReadOnlySpan`1<char> text, String& normalizedString, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private IReadOnlyList`1<Token> Encode(string text, ReadOnlySpan`1<char> textSpan, String& normalizedString, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
private IReadOnlyList`1<Token> EncodeInternal(ReadOnlySpan`1<char> text, bool addBeginOfSentence, bool addEndOfSentence);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    public IReadOnlyList`1<int> EncodeToIds(string text, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    public IReadOnlyList`1<int> EncodeToIds(string text, bool addBeginningOfSentence, bool addEndOfSentence, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool addBeginningOfSentence, bool addEndOfSentence, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private IReadOnlyList`1<int> EncodeToIds(string text, ReadOnlySpan`1<char> textSpan, bool addBeginningOfSentence, bool addEndOfSentence, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    [NullableContextAttribute("0")]
public IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool addBeginningOfSentence, bool addEndOfSentence, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    [NullableContextAttribute("0")]
private int EncodeToIds(ReadOnlySpan`1<char> text, bool addBeginOfSentence, bool addEndOfSentence, IList`1<int> accumulatedIds, Int32& textLength, int maxTokens);
    public virtual int CountTokens(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int CountTokens(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public virtual int IndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int IndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    public int CountTokens(string text, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public int CountTokens(ReadOnlySpan`1<char> text, bool addBeginningOfSentence, bool addEndOfSentence, bool considerPreTokenization, bool considerNormalization);
    public int IndexOfTokenCount(string text, bool addBeginningOfSentence, bool addEndOfSentence, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public int IndexOfTokenCount(ReadOnlySpan`1<char> text, bool addBeginningOfSentence, bool addEndOfSentence, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private int CountTokens(string text, ReadOnlySpan`1<char> textSpan, bool addBeginningOfSentence, bool addEndOfSentence, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    [NullableContextAttribute("0")]
public int CountTokens(ReadOnlySpan`1<char> text, bool addBeginningOfSentence, bool addEndOfSentence, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    public virtual int LastIndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int LastIndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private int LastIndexOf(string text, ReadOnlySpan`1<char> textSpan, int maxTokenCount, bool considerNormalization, String& normalizedString, Int32& tokenCount);
    [NullableContextAttribute("0")]
public int LastIndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, bool addBeginningOfSentence, bool addEndOfSentence, bool considerNormalization, String& normalizedString, Int32& tokenCount);
    [NullableContextAttribute("0")]
private int CountTokens(ReadOnlySpan`1<char> text, bool addBeginOfSentence, bool addEndOfSentence, Int32& textLength, int maxTokens);
    [NullableContextAttribute("0")]
private int CountTokensFromEnd(ReadOnlySpan`1<char> text, bool addBeginOfSentence, bool addEndOfSentence, Int32& textIndex, int maxTokens);
    [NullableContextAttribute("0")]
public virtual Nullable`1<int> MapTokenToId(ReadOnlySpan`1<char> token);
    [NullableContextAttribute("2")]
public virtual string MapIdToToken(int id);
    public virtual string Decode(IEnumerable`1<int> ids);
    [NullableContextAttribute("0")]
private string GetTokenString(int id, int index, int length, ReadOnlySpan`1<char> text);
    [NullableContextAttribute("0")]
private Dictionary`2<ValueTuple`2<int, int>, ValueTuple`4<int, int, int, int>> Encode(ReadOnlySpan`1<char> text, BpeSymbol[] symbols);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private void <EncodeInternal>g__EncodeAsBytes|57_0(ReadOnlySpan`1<char> text, int index, <>c__DisplayClass57_0& );
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private void <EncodeInternal>g__Segment|57_1(ValueTuple`2<int, int> pieceSpan, ReadOnlySpan`1<char> text, <>c__DisplayClass57_0& );
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private bool <EncodeToIds>g__EncodeAsBytes|68_0(ReadOnlySpan`1<char> text, int index, Int32& textLength, <>c__DisplayClass68_0& );
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private bool <EncodeToIds>g__Segment|68_1(ValueTuple`2<int, int> pieceSpan, ReadOnlySpan`1<char> text, Int32& textLength, <>c__DisplayClass68_0& );
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private bool <CountTokens>g__EncodeAsBytes|83_0(ReadOnlySpan`1<char> text, int index, Int32& textLength, <>c__DisplayClass83_0& );
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private bool <CountTokens>g__Segment|83_1(ValueTuple`2<int, int> pieceSpan, ReadOnlySpan`1<char> text, Int32& textLength, <>c__DisplayClass83_0& );
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private bool <CountTokensFromEnd>g__EncodeAsBytesFromEnd|84_0(ReadOnlySpan`1<char> text, int index, Int32& textIndex, <>c__DisplayClass84_0& );
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private bool <CountTokensFromEnd>g__SegmentFromEnd|84_1(ValueTuple`2<int, int> pieceSpan, ReadOnlySpan`1<char> text, Int32& textIndex, <>c__DisplayClass84_0& );
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
internal static void <Decode>g__FlushBytes|87_0(Int32& bytesCount, Byte[]& bytesPoolArray, Char[]& charPoolArray, ValueStringBuilder& sb);
    [NullableContextAttribute("2")]
[CompilerGeneratedAttribute]
internal static void <Decode>g__EncodeByte|87_1(int id, int oneByteUtf8EncodingMaxId, int byteCodeToIdOffset, Int32& bytesCount, Byte[]& bytesPoolArray, ValueStringBuilder& sb);
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
private void <Encode>g__TryMerge|89_0(int left, int right, ReadOnlySpan`1<char> textSpan, <>c__DisplayClass89_0& );
}
public class Microsoft.ML.Tokenizers.SentencePieceNormalizer : Normalizer {
    internal static char DummyPrefix;
    [CompilerGeneratedAttribute]
private bool <RemoveExtraWhiteSpaces>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <AddDummyPrefix>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <EscapeWhiteSpaces>k__BackingField;
    [CompilerGeneratedAttribute]
private bool <TreatWhitespaceAsSuffix>k__BackingField;
    public bool RemoveExtraWhiteSpaces { get; }
    public bool AddDummyPrefix { get; }
    public bool EscapeWhiteSpaces { get; }
    public bool TreatWhitespaceAsSuffix { get; }
    public SentencePieceNormalizer(bool removeExtraWhiteSpaces, bool addDummyPrefix, bool escapeWhiteSpaces, bool treatWhitespaceAsSuffix);
    [CompilerGeneratedAttribute]
public bool get_RemoveExtraWhiteSpaces();
    [CompilerGeneratedAttribute]
public bool get_AddDummyPrefix();
    [CompilerGeneratedAttribute]
public bool get_EscapeWhiteSpaces();
    [CompilerGeneratedAttribute]
public bool get_TreatWhitespaceAsSuffix();
    [NullableContextAttribute("1")]
public virtual string Normalize(string original);
    public virtual string Normalize(ReadOnlySpan`1<char> original);
}
[IsReadOnlyAttribute]
internal class Microsoft.ML.Tokenizers.StringSpanOrdinalKey : ValueType {
    public Char* Ptr;
    public int Length;
    [NullableAttribute("2")]
public string Data;
    private ReadOnlySpan`1<char> Span { get; }
    public StringSpanOrdinalKey(Char* ptr, int length);
    [NullableContextAttribute("1")]
public StringSpanOrdinalKey(string data);
    private ReadOnlySpan`1<char> get_Span();
    [NullableContextAttribute("1")]
public virtual string ToString();
    [NullableContextAttribute("2")]
public virtual bool Equals(object obj);
    public sealed virtual bool Equals(StringSpanOrdinalKey other);
    public virtual int GetHashCode();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal class Microsoft.ML.Tokenizers.StringSpanOrdinalKeyCache`1 : object {
    private int _capacity;
    private Dictionary`2<StringSpanOrdinalKey, TValue> _map;
    private object SyncObj { get; }
    internal StringSpanOrdinalKeyCache`1(int capacity);
    private object get_SyncObj();
    internal bool TryGetValue(string key, TValue& value);
    [NullableContextAttribute("0")]
internal bool TryGetValue(ReadOnlySpan`1<char> key, TValue& value);
    internal void Remove(string key);
    internal void Set(string k, TValue v);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal class Microsoft.ML.Tokenizers.StringSpanOrdinalKeyConverter : JsonConverter`1<StringSpanOrdinalKey> {
    [CompilerGeneratedAttribute]
private static StringSpanOrdinalKeyConverter <Instance>k__BackingField;
    public static StringSpanOrdinalKeyConverter Instance { get; }
    private static StringSpanOrdinalKeyConverter();
    [CompilerGeneratedAttribute]
public static StringSpanOrdinalKeyConverter get_Instance();
    public virtual StringSpanOrdinalKey ReadAsPropertyName(Utf8JsonReader& reader, Type typeToConvert, JsonSerializerOptions options);
    public virtual void WriteAsPropertyName(Utf8JsonWriter writer, StringSpanOrdinalKey value, JsonSerializerOptions options);
    public virtual StringSpanOrdinalKey Read(Utf8JsonReader& reader, Type typeToConvert, JsonSerializerOptions options);
    public virtual void Write(Utf8JsonWriter writer, StringSpanOrdinalKey value, JsonSerializerOptions options);
}
[NullableContextAttribute("1")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
internal class Microsoft.ML.Tokenizers.StringSpanOrdinalKeyCustomConverter : JsonConverter`1<Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>>> {
    [CompilerGeneratedAttribute]
private static StringSpanOrdinalKeyCustomConverter <Instance>k__BackingField;
    public static StringSpanOrdinalKeyCustomConverter Instance { get; }
    private static StringSpanOrdinalKeyCustomConverter();
    [CompilerGeneratedAttribute]
public static StringSpanOrdinalKeyCustomConverter get_Instance();
    public virtual Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>> Read(Utf8JsonReader& reader, Type typeToConvert, JsonSerializerOptions options);
    public virtual void Write(Utf8JsonWriter writer, Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>> value, JsonSerializerOptions options);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
internal static class Microsoft.ML.Tokenizers.StringSpanOrdinalKeyExtensions : object {
    [ExtensionAttribute]
public static bool TryGetValue(Dictionary`2<StringSpanOrdinalKey, TValue> map, ReadOnlySpan`1<char> key, TValue& value);
    [ExtensionAttribute]
public static bool TryGetValue(Dictionary`2<StringSpanOrdinalKey, TValue> map, string key, TValue& value);
    [NullableContextAttribute("0")]
[ExtensionAttribute]
public static bool TryGetValue(Dictionary`2<StringSpanOrdinalKeyPair, TValue> map, ReadOnlySpan`1<char> key1, ReadOnlySpan`1<char> key2, TValue& value);
    [ExtensionAttribute]
public static bool TryGetValue(Dictionary`2<StringSpanOrdinalKeyPair, TValue> map, string key1, string key2, TValue& value);
}
[IsReadOnlyAttribute]
internal class Microsoft.ML.Tokenizers.StringSpanOrdinalKeyPair : ValueType {
    private StringSpanOrdinalKey _left;
    private StringSpanOrdinalKey _right;
    public StringSpanOrdinalKeyPair(Char* ptr1, int length1, Char* ptr2, int length2);
    [NullableContextAttribute("1")]
public StringSpanOrdinalKeyPair(string data1, string data2);
    [NullableContextAttribute("2")]
public virtual bool Equals(object obj);
    public sealed virtual bool Equals(StringSpanOrdinalKeyPair other);
    public virtual int GetHashCode();
}
internal class Microsoft.ML.Tokenizers.Symbol : ValueType {
    [CompilerGeneratedAttribute]
private int <C>k__BackingField;
    [CompilerGeneratedAttribute]
private int <Prev>k__BackingField;
    [CompilerGeneratedAttribute]
private int <Next>k__BackingField;
    [CompilerGeneratedAttribute]
private int <Len>k__BackingField;
    internal int C { get; internal set; }
    internal int Prev { get; internal set; }
    internal int Next { get; internal set; }
    internal int Len { get; internal set; }
    public Symbol(int c, int prev, int next, int len);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
internal int get_C();
    [CompilerGeneratedAttribute]
internal void set_C(int value);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
internal int get_Prev();
    [CompilerGeneratedAttribute]
internal void set_Prev(int value);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
internal int get_Next();
    [CompilerGeneratedAttribute]
internal void set_Next(int value);
    [IsReadOnlyAttribute]
[CompilerGeneratedAttribute]
internal int get_Len();
    [CompilerGeneratedAttribute]
internal void set_Len(int value);
    internal void MergeWith(Symbol& other, int c);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class Microsoft.ML.Tokenizers.Tiktoken : Tokenizer {
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<ReadOnlyMemory`1<byte>, int> _encoder;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<int, ReadOnlyMemory`1<byte>> _decoder;
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private LruCache`1<ValueTuple`3[]> _cache;
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>> _vocab;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private IReadOnlyDictionary`2<string, int> _vocabOriginal;
    private static int MaxWordLengthToCache;
    [NullableAttribute("2")]
private PreTokenizer _preTokenizer;
    [NullableAttribute("2")]
private Normalizer _normalizer;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[CompilerGeneratedAttribute]
private IReadOnlyDictionary`2<string, int> <SpecialTokens>k__BackingField;
    private static string EndOfText;
    private static string FimPrefix;
    private static string FimMiddle;
    private static string FimSuffix;
    private static string EndOfPrompt;
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private static ValueTuple`2[] _modelPrefixToEncoding;
    private static Dictionary`2<string, ModelEncoding> _modelToEncoding;
    private static string Cl100kBaseRegexPattern;
    private static string P50kBaseRegexPattern;
    private static string O200kBaseRegexPattern;
    private static string Cl100kBaseVocabFile;
    private static string P50RanksFile;
    private static string R50RanksFile;
    private static string GPT2File;
    private static string O200kBaseFile;
    internal static string Cl100kBaseEncodingName;
    internal static string P50kBaseEncodingName;
    internal static string P50kEditEncodingName;
    internal static string R50kBaseEncodingName;
    internal static string O200kBaseEncodingName;
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private static ConcurrentDictionary`2<string, ValueTuple`3<Dictionary`2<ReadOnlyMemory`1<byte>, int>, Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>>, Dictionary`2<int, ReadOnlyMemory`1<byte>>>> _tiktokenCache;
    [NullableAttribute("2")]
public PreTokenizer PreTokenizer { get; }
    [NullableAttribute("2")]
public Normalizer Normalizer { get; }
    public IReadOnlyDictionary`2<string, int> Vocab { get; }
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
public IReadOnlyDictionary`2<string, int> SpecialTokens { get; }
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
public IReadOnlyDictionary`2<ReadOnlyMemory`1<byte>, int> Encoder { get; }
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
public IReadOnlyDictionary`2<int, ReadOnlyMemory`1<byte>> Decoder { get; }
    [NullableContextAttribute("2")]
public Tiktoken(string vocabFilePath, PreTokenizer preTokenizer, IReadOnlyDictionary`2<string, int> specialTokens, Normalizer normalizer, int cacheSize);
    [NullableContextAttribute("2")]
public Tiktoken(Stream vocabStream, PreTokenizer preTokenizer, IReadOnlyDictionary`2<string, int> specialTokens, Normalizer normalizer, int cacheSize);
    [NullableContextAttribute("2")]
internal Tiktoken(Dictionary`2<ReadOnlyMemory`1<byte>, int> encoder, Dictionary`2<int, ReadOnlyMemory`1<byte>> decoder, Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>> vocab, PreTokenizer preTokenizer, IReadOnlyDictionary`2<string, int> specialTokens, Normalizer normalizer, int cacheSize);
    [NullableContextAttribute("2")]
private Tiktoken(Stream vocabStream, PreTokenizer preTokenizer, IReadOnlyDictionary`2<string, int> specialTokens, Normalizer normalizer, int cacheSize, bool disposeStream);
    private static Tiktoken();
    [NullableContextAttribute("2")]
public virtual PreTokenizer get_PreTokenizer();
    [NullableContextAttribute("2")]
public virtual Normalizer get_Normalizer();
    private void CacheSpecialTokensEncoding(IReadOnlyDictionary`2<string, int> specialTokens);
    [AsyncStateMachineAttribute("Microsoft.ML.Tokenizers.Tiktoken/<LoadTiktokenBpeAsync>d__17")]
internal static ValueTask`1<ValueTuple`3<Dictionary`2<ReadOnlyMemory`1<byte>, int>, Dictionary`2<StringSpanOrdinalKey, ValueTuple`2<int, string>>, Dictionary`2<int, ReadOnlyMemory`1<byte>>>> LoadTiktokenBpeAsync(Stream vocabStream, bool useAsync, CancellationToken cancellationToken);
    public virtual IReadOnlyList`1<Token> Encode(string text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<Token> Encode(ReadOnlySpan`1<char> text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private IReadOnlyList`1<Token> Encode(string text, ReadOnlySpan`1<char> textSpan, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
private void Encode(ReadOnlySpan`1<char> text, List`1<Token> tokens, int offset);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private IReadOnlyList`1<int> EncodeToIds(string text, ReadOnlySpan`1<char> textSpan, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    [NullableContextAttribute("0")]
private int EncodeToIds(ReadOnlySpan`1<char> text, IList`1<int> accumulatedIds, Int32& textLength, int maxTokenCount);
    [NullableContextAttribute("2")]
private int EncodeToIdsResult(ValueTuple`3[] tokens, IList`1<int> accumulatedIds, int maxTokens, int fullTextLength, Int32& textLength);
    public virtual int CountTokens(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int CountTokens(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public virtual int IndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int IndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private int CountTokens(string text, ReadOnlySpan`1<char> textSpan, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& textLength, int maxTokenCount);
    [NullableContextAttribute("0")]
private int CountTokens(ReadOnlySpan`1<char> text, Int32& textLength, int maxTokens);
    public virtual int LastIndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public virtual int LastIndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("2")]
private int LastIndexOf(string text, ReadOnlySpan`1<char> textSpan, int maxTokenCount, bool considerPreTokenization, bool considerNormalization, String& normalizedString, Int32& tokenCount);
    [NullableContextAttribute("0")]
private int CountTokensFromEnd(ReadOnlySpan`1<char> text, Int32& textIndex, int maxTokens);
    [NullableContextAttribute("2")]
private int EncodeToIdsFromEndResult(ValueTuple`3[] tokens, IList`1<int> accumulatedIds, int maxTokens, int fullTextLength, Int32& textIndex);
    [NullableContextAttribute("0")]
public virtual Nullable`1<int> MapTokenToId(ReadOnlySpan`1<char> token);
    [NullableContextAttribute("2")]
public virtual string MapIdToToken(int id);
    public virtual string Decode(IEnumerable`1<int> ids);
    public IReadOnlyDictionary`2<string, int> get_Vocab();
    [CompilerGeneratedAttribute]
public IReadOnlyDictionary`2<string, int> get_SpecialTokens();
    public IReadOnlyDictionary`2<ReadOnlyMemory`1<byte>, int> get_Encoder();
    public IReadOnlyDictionary`2<int, ReadOnlyMemory`1<byte>> get_Decoder();
    internal static ModelEncoding GetModelEncoding(string modelName);
    internal static ValueTuple`3<Dictionary`2<string, int>, Regex, string> GetTiktokenConfigurations(string modelName);
    [NullableContextAttribute("2")]
internal static ValueTuple`3<Dictionary`2<string, int>, Regex, string> GetTiktokenConfigurations(ModelEncoding modelEncoding, string modelName);
    [GeneratedRegexAttribute("'(?i:[sdmt]|re|ve|ll)|(?>[^\r\n\p{L}\p{N}]?)\p{L}+|\p{N}{1,3}| ?(?>[^\s\p{L}\p{N}]+)[\r\n]*|\s*[\r\n]|\s+(?!\S)|\s+")]
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
private static Regex Cl100kBaseRegex();
    [GeneratedRegexAttribute("'(?:[sdmt]|re|ve|ll)| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+")]
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
internal static Regex P50kBaseRegex();
    [GeneratedRegexAttribute("[^\r\n\p{L}\p{N}]?[\p{Lu}\p{Lt}\p{Lm}\p{Lo}\p{M}]*[\p{Ll}\p{Lm}\p{Lo}\p{M}]+(?i:'s|'t|'re|'ve|'m|'ll|'d)?|[^\r\n\p{L}\p{N}]?[\p{Lu}\p{Lt}\p{Lm}\p{Lo}\p{M}]+[\p{Ll}\p{Lm}\p{Lo}\p{M}]*(?i:'s|'t|'re|'ve|'m|'ll|'d)?|\p{N}{1,3}| ?[^\s\p{L}\p{N}]+[\r\n/]*|\s*[\r\n]+|\s+(?!\S)|\s+")]
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
internal static Regex O200kBaseRegex();
    [NullableContextAttribute("2")]
internal static Tokenizer CreateForModel(ModelEncoding modelEncoding, string modelName, IReadOnlyDictionary`2<string, int> extraSpecialTokens, Normalizer normalizer);
    [CompilerGeneratedAttribute]
internal static void <LoadTiktokenBpeAsync>g__AddData|17_0(Byte[] tokenBytes, int rank, <>c__DisplayClass17_0& );
    [NullableContextAttribute("0")]
[CompilerGeneratedAttribute]
internal static void <Decode>g__ArrayPoolGrow|42_0(Span`1& utf8Bytes, Byte[]& arrayPoolArray, int requiredCapacity);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class Microsoft.ML.Tokenizers.TiktokenPreTokenizer : PreTokenizer {
    [NullableAttribute("2")]
private Regex _specialTokensRegex;
    private Regex _regex;
    public TiktokenPreTokenizer(Regex regex, IReadOnlyDictionary`2<string, int> specialTokensEncoder);
    public virtual IEnumerable`1<ValueTuple`2<int, int>> PreTokenize(string text);
    [NullableContextAttribute("0")]
public virtual IEnumerable`1<ValueTuple`2<int, int>> PreTokenize(ReadOnlySpan`1<char> text);
    [IteratorStateMachineAttribute("Microsoft.ML.Tokenizers.TiktokenPreTokenizer/<<PreTokenize>g__SplitText|3_0>d")]
[CompilerGeneratedAttribute]
internal static IEnumerable`1<ValueTuple`2<int, int>> <PreTokenize>g__SplitText|3_0(string text, Regex regex, Regex specialTokensRegex);
    [IteratorStateMachineAttribute("Microsoft.ML.Tokenizers.TiktokenPreTokenizer/<<PreTokenize>g__SplitText|4_0>d")]
[CompilerGeneratedAttribute]
internal static IEnumerable`1<ValueTuple`2<int, int>> <PreTokenize>g__SplitText|4_0(Char[] text, Regex regex, Regex specialTokensRegex, int textLength);
}
[IsReadOnlyAttribute]
public class Microsoft.ML.Tokenizers.Token : ValueType {
    [CompilerGeneratedAttribute]
private int <Id>k__BackingField;
    [NullableAttribute("1")]
[CompilerGeneratedAttribute]
private string <Value>k__BackingField;
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
[CompilerGeneratedAttribute]
private ValueTuple`2<int, int> <Offset>k__BackingField;
    public int Id { get; }
    [NullableAttribute("1")]
public string Value { get; }
    [TupleElementNamesAttribute("Mono.Cecil.CustomAttributeArgument[]")]
public ValueTuple`2<int, int> Offset { get; }
    public Token(int id, string value, ValueTuple`2<int, int> offset);
    [CompilerGeneratedAttribute]
public int get_Id();
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
public string get_Value();
    [CompilerGeneratedAttribute]
public ValueTuple`2<int, int> get_Offset();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public abstract class Microsoft.ML.Tokenizers.Tokenizer : object {
    [NullableAttribute("2")]
public PreTokenizer PreTokenizer { get; }
    [NullableAttribute("2")]
public Normalizer Normalizer { get; }
    [NullableContextAttribute("2")]
public virtual PreTokenizer get_PreTokenizer();
    [NullableContextAttribute("2")]
public virtual Normalizer get_Normalizer();
    public virtual IReadOnlyList`1<Token> Encode(string text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public abstract virtual IReadOnlyList`1<Token> Encode(ReadOnlySpan`1<char> text, String& normalizedString, bool considerPreTokenization, bool considerNormalization);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public abstract virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public virtual IReadOnlyList`1<int> EncodeToIds(string text, int maxTokenCount, String& normalizedText, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public abstract virtual IReadOnlyList`1<int> EncodeToIds(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedText, Int32& textLength, bool considerPreTokenization, bool considerNormalization);
    public virtual int CountTokens(string text, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public abstract virtual int CountTokens(ReadOnlySpan`1<char> text, bool considerPreTokenization, bool considerNormalization);
    public virtual int IndexOfTokenCount(string text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public abstract virtual int IndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& normalizedString, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    public virtual int LastIndexOfTokenCount(string text, int maxTokenCount, String& processedText, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    [NullableContextAttribute("0")]
public abstract virtual int LastIndexOfTokenCount(ReadOnlySpan`1<char> text, int maxTokenCount, String& processedText, Int32& tokenCount, bool considerPreTokenization, bool considerNormalization);
    public virtual Nullable`1<int> MapTokenToId(string token);
    [NullableContextAttribute("0")]
public abstract virtual Nullable`1<int> MapTokenToId(ReadOnlySpan`1<char> token);
    [NullableContextAttribute("2")]
public abstract virtual string MapIdToToken(int id);
    public virtual string Decode(IEnumerable`1<int> ids);
    [AsyncStateMachineAttribute("Microsoft.ML.Tokenizers.Tokenizer/<CreateTiktokenAsync>d__20")]
public static Task`1<Tokenizer> CreateTiktokenAsync(Stream vocabStream, PreTokenizer preTokenizer, Normalizer normalizer, IReadOnlyDictionary`2<string, int> specialTokens, int cacheSize, CancellationToken cancellationToken);
    [AsyncStateMachineAttribute("Microsoft.ML.Tokenizers.Tokenizer/<CreateTiktokenAsync>d__21")]
public static Task`1<Tokenizer> CreateTiktokenAsync(string vocabFilePath, PreTokenizer preTokenizer, Normalizer normalizer, IReadOnlyDictionary`2<string, int> specialTokensEncoder, int cacheSize, CancellationToken cancellationToken);
    public static Tokenizer CreateTiktokenForModel(string modelName, Stream vocabStream, IReadOnlyDictionary`2<string, int> extraSpecialTokens, int cacheSize, Normalizer normalizer);
    [AsyncStateMachineAttribute("Microsoft.ML.Tokenizers.Tokenizer/<CreateTiktokenForModelAsync>d__23")]
public static Task`1<Tokenizer> CreateTiktokenForModelAsync(string modelName, Stream vocabStream, IReadOnlyDictionary`2<string, int> extraSpecialTokens, int cacheSize, Normalizer normalizer, CancellationToken cancellationToken);
    public static Tokenizer CreateTiktokenForModel(string modelName, IReadOnlyDictionary`2<string, int> extraSpecialTokens, Normalizer normalizer);
    public static Tokenizer CreateTiktokenForEncoding(string encodingName, IReadOnlyDictionary`2<string, int> extraSpecialTokens, Normalizer normalizer);
    public static Tokenizer CreateLlama(Stream modelStream, bool addBeginOfSentence, bool addEndOfSentence);
    public static Tokenizer CreateCodeGen(Stream vocabStream, Stream mergesStream, bool addPrefixSpace, bool addBeginOfSentence, bool addEndOfSentence);
    public static Tokenizer CreatePhi2(Stream vocabStream, Stream mergesStream, bool addPrefixSpace, bool addBeginOfSentence, bool addEndOfSentence);
    [NullableContextAttribute("2")]
internal static IEnumerable`1<ValueTuple`2<int, int>> InitializeForEncoding(string text, ReadOnlySpan`1<char> textSpan, bool considerPreTokenization, bool considerNormalization, Normalizer normalizer, PreTokenizer preTokenizer, String& normalizedString, ReadOnlySpan`1& textSpanToEncode);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[ExtensionAttribute]
internal static class Microsoft.ML.Tokenizers.TokenizerExtensions : object {
    [ExtensionAttribute]
public static T ArgMin(IEnumerable`1<T> source, Func`2<T, int> getValue);
    [ExtensionAttribute]
public static TValue GetOrAdd(Dictionary`2<TKey, TValue> dic, TKey key, TValue setValue);
    [ExtensionAttribute]
public static IReadOnlyDictionary`2<TValue, TKey> Reverse(IReadOnlyDictionary`2<TKey, TValue> source);
    [ExtensionAttribute]
public static SortedDictionary`2<TValue, TKey> ReverseSorted(IReadOnlyDictionary`2<TKey, TValue> source);
}
public class Microsoft.ML.Tokenizers.UpperCaseNormalizer : Normalizer {
    [NullableContextAttribute("1")]
public virtual string Normalize(string original);
    public virtual string Normalize(ReadOnlySpan`1<char> original);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
[DefaultMemberAttribute("Item")]
internal class Microsoft.ML.Tokenizers.Vec`1 : ValueType {
    private static int DefaultCapacity;
    private int _count;
    [NullableAttribute("Mono.Cecil.CustomAttributeArgument[]")]
private T[] _buffer;
    public T& Item { get; }
    public int Capacity { get; }
    public int Count { get; }
    public Vec`1(int capacity);
    public T& get_Item(int index);
    public int get_Capacity();
    public int get_Count();
    public void Push(T t);
    public void Remove(int index);
    public void Clear();
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
public class Microsoft.ML.Tokenizers.WhiteSpace : PreTokenizer {
    [CompilerGeneratedAttribute]
private static WhiteSpace <Instance>k__BackingField;
    private static string PretokenizePattern;
    public static WhiteSpace Instance { get; }
    private static WhiteSpace();
    [CompilerGeneratedAttribute]
public static WhiteSpace get_Instance();
    [GeneratedRegexAttribute("\w+|[^\w\s]+")]
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
private static Regex PretokenizeRegex();
    public virtual IEnumerable`1<ValueTuple`2<int, int>> PreTokenize(string text);
    [NullableContextAttribute("0")]
public virtual IEnumerable`1<ValueTuple`2<int, int>> PreTokenize(ReadOnlySpan`1<char> text);
}
[NullableContextAttribute("1")]
[NullableAttribute("0")]
internal class Microsoft.ML.Tokenizers.Word : ValueType {
    [NullableAttribute("2")]
[ThreadStaticAttribute]
private static Random _random;
    [NullableAttribute("0")]
private Vec`1<Symbol> _symbols;
    public int SymbolsCount { get; }
    public Word(int capacity);
    public static Word WithCapacity(int capacity);
    public int get_SymbolsCount();
    public void Add(int c, int charLength);
    [NullableContextAttribute("0")]
public Vec`1<ValueTuple`2<Pair`1<int>, int>> Merge(int c1, int c2, int replacement);
    [NullableContextAttribute("2")]
public void MergeAll(Dictionary`2<Pair`1<int>, ValueTuple`2<int, int>> merges, Nullable`1<float> dropout, PriorityQueue`1& priorityQueue);
    public void PopulateIds(IList`1<int> accumulatedIds);
    public int PopulateIdsUpToMax(IList`1<int> accumulatedIds, int maxTokens, Int32& textLength);
    public int PopulateIdsUpToMaxFromEnd(IList`1<int> accumulatedIds, int maxTokens, int fullTextLength, Int32& textIndex);
    public int CountIdsUpToMax(int maxTokens, Int32& textLength);
    public int CountIdsUpToMaxFromEnd(int maxTokens, int fullTextLength, Int32& textIndex);
    [NullableContextAttribute("0")]
public Vec`1<int> GetChars();
    public virtual string ToString();
    public void ToTokens(SortedDictionary`2<int, string> vocabReverse, List`1<Token> tokens, int offset);
}
[DebuggerDisplayAttribute("{ToString(),nq}")]
internal class Sentencepiece.ModelProto : object {
    private static MessageParser`1<ModelProto> _parser;
    private UnknownFieldSet _unknownFields;
    private ExtensionSet`1<ModelProto> _extensions;
    public static int PiecesFieldNumber;
    private static FieldCodec`1<SentencePiece> _repeated_pieces_codec;
    private RepeatedField`1<SentencePiece> pieces_;
    public static int TrainerSpecFieldNumber;
    private TrainerSpec trainerSpec_;
    public static int NormalizerSpecFieldNumber;
    private NormalizerSpec normalizerSpec_;
    public static int SelfTestDataFieldNumber;
    private SelfTestData selfTestData_;
    public static int DenormalizerSpecFieldNumber;
    private NormalizerSpec denormalizerSpec_;
    private ExtensionSet`1<ModelProto> _Extensions { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public static MessageParser`1<ModelProto> Parser { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public static MessageDescriptor Descriptor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private MessageDescriptor pb::Google.Protobuf.IMessage.Descriptor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public RepeatedField`1<SentencePiece> Pieces { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public TrainerSpec TrainerSpec { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public NormalizerSpec NormalizerSpec { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public SelfTestData SelfTestData { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public NormalizerSpec DenormalizerSpec { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public ModelProto(ModelProto other);
    private static ModelProto();
    private ExtensionSet`1<ModelProto> get__Extensions();
    public static MessageParser`1<ModelProto> get_Parser();
    public static MessageDescriptor get_Descriptor();
    private sealed virtual override MessageDescriptor pb::Google.Protobuf.IMessage.get_Descriptor();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual ModelProto Clone();
    public RepeatedField`1<SentencePiece> get_Pieces();
    public TrainerSpec get_TrainerSpec();
    public void set_TrainerSpec(TrainerSpec value);
    public NormalizerSpec get_NormalizerSpec();
    public void set_NormalizerSpec(NormalizerSpec value);
    public SelfTestData get_SelfTestData();
    public void set_SelfTestData(SelfTestData value);
    public NormalizerSpec get_DenormalizerSpec();
    public void set_DenormalizerSpec(NormalizerSpec value);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual bool Equals(object other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual bool Equals(ModelProto other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual int GetHashCode();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual string ToString();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void WriteTo(CodedOutputStream output);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private sealed virtual override void pb::Google.Protobuf.IBufferMessage.InternalWriteTo(WriteContext& output);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual int CalculateSize();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void MergeFrom(ModelProto other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void MergeFrom(CodedInputStream input);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private sealed virtual override void pb::Google.Protobuf.IBufferMessage.InternalMergeFrom(ParseContext& input);
    public sealed virtual TValue GetExtension(Extension`2<ModelProto, TValue> extension);
    public sealed virtual RepeatedField`1<TValue> GetExtension(RepeatedExtension`2<ModelProto, TValue> extension);
    public sealed virtual RepeatedField`1<TValue> GetOrInitializeExtension(RepeatedExtension`2<ModelProto, TValue> extension);
    public sealed virtual void SetExtension(Extension`2<ModelProto, TValue> extension, TValue value);
    public sealed virtual bool HasExtension(Extension`2<ModelProto, TValue> extension);
    public sealed virtual void ClearExtension(Extension`2<ModelProto, TValue> extension);
    public sealed virtual void ClearExtension(RepeatedExtension`2<ModelProto, TValue> extension);
}
[DebuggerDisplayAttribute("{ToString(),nq}")]
internal class Sentencepiece.NormalizerSpec : object {
    private static MessageParser`1<NormalizerSpec> _parser;
    private UnknownFieldSet _unknownFields;
    private ExtensionSet`1<NormalizerSpec> _extensions;
    private int _hasBits0;
    public static int NameFieldNumber;
    private static string NameDefaultValue;
    private string name_;
    public static int PrecompiledCharsmapFieldNumber;
    private static ByteString PrecompiledCharsmapDefaultValue;
    private ByteString precompiledCharsmap_;
    public static int AddDummyPrefixFieldNumber;
    private static bool AddDummyPrefixDefaultValue;
    private bool addDummyPrefix_;
    public static int RemoveExtraWhitespacesFieldNumber;
    private static bool RemoveExtraWhitespacesDefaultValue;
    private bool removeExtraWhitespaces_;
    public static int EscapeWhitespacesFieldNumber;
    private static bool EscapeWhitespacesDefaultValue;
    private bool escapeWhitespaces_;
    public static int NormalizationRuleTsvFieldNumber;
    private static string NormalizationRuleTsvDefaultValue;
    private string normalizationRuleTsv_;
    private ExtensionSet`1<NormalizerSpec> _Extensions { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public static MessageParser`1<NormalizerSpec> Parser { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public static MessageDescriptor Descriptor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private MessageDescriptor pb::Google.Protobuf.IMessage.Descriptor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string Name { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasName { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public ByteString PrecompiledCharsmap { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasPrecompiledCharsmap { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool AddDummyPrefix { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasAddDummyPrefix { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool RemoveExtraWhitespaces { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasRemoveExtraWhitespaces { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool EscapeWhitespaces { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasEscapeWhitespaces { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string NormalizationRuleTsv { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasNormalizationRuleTsv { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public NormalizerSpec(NormalizerSpec other);
    private static NormalizerSpec();
    private ExtensionSet`1<NormalizerSpec> get__Extensions();
    public static MessageParser`1<NormalizerSpec> get_Parser();
    public static MessageDescriptor get_Descriptor();
    private sealed virtual override MessageDescriptor pb::Google.Protobuf.IMessage.get_Descriptor();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual NormalizerSpec Clone();
    public string get_Name();
    public void set_Name(string value);
    public bool get_HasName();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearName();
    public ByteString get_PrecompiledCharsmap();
    public void set_PrecompiledCharsmap(ByteString value);
    public bool get_HasPrecompiledCharsmap();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearPrecompiledCharsmap();
    public bool get_AddDummyPrefix();
    public void set_AddDummyPrefix(bool value);
    public bool get_HasAddDummyPrefix();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearAddDummyPrefix();
    public bool get_RemoveExtraWhitespaces();
    public void set_RemoveExtraWhitespaces(bool value);
    public bool get_HasRemoveExtraWhitespaces();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearRemoveExtraWhitespaces();
    public bool get_EscapeWhitespaces();
    public void set_EscapeWhitespaces(bool value);
    public bool get_HasEscapeWhitespaces();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearEscapeWhitespaces();
    public string get_NormalizationRuleTsv();
    public void set_NormalizationRuleTsv(string value);
    public bool get_HasNormalizationRuleTsv();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearNormalizationRuleTsv();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual bool Equals(object other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual bool Equals(NormalizerSpec other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual int GetHashCode();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual string ToString();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void WriteTo(CodedOutputStream output);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private sealed virtual override void pb::Google.Protobuf.IBufferMessage.InternalWriteTo(WriteContext& output);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual int CalculateSize();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void MergeFrom(NormalizerSpec other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void MergeFrom(CodedInputStream input);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private sealed virtual override void pb::Google.Protobuf.IBufferMessage.InternalMergeFrom(ParseContext& input);
    public sealed virtual TValue GetExtension(Extension`2<NormalizerSpec, TValue> extension);
    public sealed virtual RepeatedField`1<TValue> GetExtension(RepeatedExtension`2<NormalizerSpec, TValue> extension);
    public sealed virtual RepeatedField`1<TValue> GetOrInitializeExtension(RepeatedExtension`2<NormalizerSpec, TValue> extension);
    public sealed virtual void SetExtension(Extension`2<NormalizerSpec, TValue> extension, TValue value);
    public sealed virtual bool HasExtension(Extension`2<NormalizerSpec, TValue> extension);
    public sealed virtual void ClearExtension(Extension`2<NormalizerSpec, TValue> extension);
    public sealed virtual void ClearExtension(RepeatedExtension`2<NormalizerSpec, TValue> extension);
}
[DebuggerDisplayAttribute("{ToString(),nq}")]
internal class Sentencepiece.SelfTestData : object {
    private static MessageParser`1<SelfTestData> _parser;
    private UnknownFieldSet _unknownFields;
    private ExtensionSet`1<SelfTestData> _extensions;
    public static int SamplesFieldNumber;
    private static FieldCodec`1<Sample> _repeated_samples_codec;
    private RepeatedField`1<Sample> samples_;
    private ExtensionSet`1<SelfTestData> _Extensions { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public static MessageParser`1<SelfTestData> Parser { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public static MessageDescriptor Descriptor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private MessageDescriptor pb::Google.Protobuf.IMessage.Descriptor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public RepeatedField`1<Sample> Samples { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public SelfTestData(SelfTestData other);
    private static SelfTestData();
    private ExtensionSet`1<SelfTestData> get__Extensions();
    public static MessageParser`1<SelfTestData> get_Parser();
    public static MessageDescriptor get_Descriptor();
    private sealed virtual override MessageDescriptor pb::Google.Protobuf.IMessage.get_Descriptor();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual SelfTestData Clone();
    public RepeatedField`1<Sample> get_Samples();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual bool Equals(object other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual bool Equals(SelfTestData other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual int GetHashCode();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual string ToString();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void WriteTo(CodedOutputStream output);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private sealed virtual override void pb::Google.Protobuf.IBufferMessage.InternalWriteTo(WriteContext& output);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual int CalculateSize();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void MergeFrom(SelfTestData other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void MergeFrom(CodedInputStream input);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private sealed virtual override void pb::Google.Protobuf.IBufferMessage.InternalMergeFrom(ParseContext& input);
    public sealed virtual TValue GetExtension(Extension`2<SelfTestData, TValue> extension);
    public sealed virtual RepeatedField`1<TValue> GetExtension(RepeatedExtension`2<SelfTestData, TValue> extension);
    public sealed virtual RepeatedField`1<TValue> GetOrInitializeExtension(RepeatedExtension`2<SelfTestData, TValue> extension);
    public sealed virtual void SetExtension(Extension`2<SelfTestData, TValue> extension, TValue value);
    public sealed virtual bool HasExtension(Extension`2<SelfTestData, TValue> extension);
    public sealed virtual void ClearExtension(Extension`2<SelfTestData, TValue> extension);
    public sealed virtual void ClearExtension(RepeatedExtension`2<SelfTestData, TValue> extension);
}
internal static class Sentencepiece.SentencepieceModelReflection : object {
    private static FileDescriptor descriptor;
    public static FileDescriptor Descriptor { get; }
    private static SentencepieceModelReflection();
    public static FileDescriptor get_Descriptor();
}
[DebuggerDisplayAttribute("{ToString(),nq}")]
internal class Sentencepiece.TrainerSpec : object {
    private static MessageParser`1<TrainerSpec> _parser;
    private UnknownFieldSet _unknownFields;
    private ExtensionSet`1<TrainerSpec> _extensions;
    private int _hasBits0;
    private int _hasBits1;
    public static int InputFieldNumber;
    private static FieldCodec`1<string> _repeated_input_codec;
    private RepeatedField`1<string> input_;
    public static int InputFormatFieldNumber;
    private static string InputFormatDefaultValue;
    private string inputFormat_;
    public static int ModelPrefixFieldNumber;
    private static string ModelPrefixDefaultValue;
    private string modelPrefix_;
    public static int ModelTypeFieldNumber;
    private static ModelType ModelTypeDefaultValue;
    private ModelType modelType_;
    public static int VocabSizeFieldNumber;
    private static int VocabSizeDefaultValue;
    private int vocabSize_;
    public static int AcceptLanguageFieldNumber;
    private static FieldCodec`1<string> _repeated_acceptLanguage_codec;
    private RepeatedField`1<string> acceptLanguage_;
    public static int SelfTestSampleSizeFieldNumber;
    private static int SelfTestSampleSizeDefaultValue;
    private int selfTestSampleSize_;
    public static int EnableDifferentialPrivacyFieldNumber;
    private static bool EnableDifferentialPrivacyDefaultValue;
    private bool enableDifferentialPrivacy_;
    public static int DifferentialPrivacyNoiseLevelFieldNumber;
    private static float DifferentialPrivacyNoiseLevelDefaultValue;
    private float differentialPrivacyNoiseLevel_;
    public static int DifferentialPrivacyClippingThresholdFieldNumber;
    private static ulong DifferentialPrivacyClippingThresholdDefaultValue;
    private ulong differentialPrivacyClippingThreshold_;
    public static int CharacterCoverageFieldNumber;
    private static float CharacterCoverageDefaultValue;
    private float characterCoverage_;
    public static int InputSentenceSizeFieldNumber;
    private static ulong InputSentenceSizeDefaultValue;
    private ulong inputSentenceSize_;
    public static int ShuffleInputSentenceFieldNumber;
    private static bool ShuffleInputSentenceDefaultValue;
    private bool shuffleInputSentence_;
    public static int MiningSentenceSizeFieldNumber;
    private static int MiningSentenceSizeDefaultValue;
    private int miningSentenceSize_;
    public static int TrainingSentenceSizeFieldNumber;
    private static int TrainingSentenceSizeDefaultValue;
    private int trainingSentenceSize_;
    public static int SeedSentencepieceSizeFieldNumber;
    private static int SeedSentencepieceSizeDefaultValue;
    private int seedSentencepieceSize_;
    public static int ShrinkingFactorFieldNumber;
    private static float ShrinkingFactorDefaultValue;
    private float shrinkingFactor_;
    public static int MaxSentenceLengthFieldNumber;
    private static int MaxSentenceLengthDefaultValue;
    private int maxSentenceLength_;
    public static int NumThreadsFieldNumber;
    private static int NumThreadsDefaultValue;
    private int numThreads_;
    public static int NumSubIterationsFieldNumber;
    private static int NumSubIterationsDefaultValue;
    private int numSubIterations_;
    public static int MaxSentencepieceLengthFieldNumber;
    private static int MaxSentencepieceLengthDefaultValue;
    private int maxSentencepieceLength_;
    public static int SplitByUnicodeScriptFieldNumber;
    private static bool SplitByUnicodeScriptDefaultValue;
    private bool splitByUnicodeScript_;
    public static int SplitByNumberFieldNumber;
    private static bool SplitByNumberDefaultValue;
    private bool splitByNumber_;
    public static int SplitByWhitespaceFieldNumber;
    private static bool SplitByWhitespaceDefaultValue;
    private bool splitByWhitespace_;
    public static int TreatWhitespaceAsSuffixFieldNumber;
    private static bool TreatWhitespaceAsSuffixDefaultValue;
    private bool treatWhitespaceAsSuffix_;
    public static int AllowWhitespaceOnlyPiecesFieldNumber;
    private static bool AllowWhitespaceOnlyPiecesDefaultValue;
    private bool allowWhitespaceOnlyPieces_;
    public static int SplitDigitsFieldNumber;
    private static bool SplitDigitsDefaultValue;
    private bool splitDigits_;
    public static int PretokenizationDelimiterFieldNumber;
    private static string PretokenizationDelimiterDefaultValue;
    private string pretokenizationDelimiter_;
    public static int ControlSymbolsFieldNumber;
    private static FieldCodec`1<string> _repeated_controlSymbols_codec;
    private RepeatedField`1<string> controlSymbols_;
    public static int UserDefinedSymbolsFieldNumber;
    private static FieldCodec`1<string> _repeated_userDefinedSymbols_codec;
    private RepeatedField`1<string> userDefinedSymbols_;
    public static int RequiredCharsFieldNumber;
    private static string RequiredCharsDefaultValue;
    private string requiredChars_;
    public static int ByteFallbackFieldNumber;
    private static bool ByteFallbackDefaultValue;
    private bool byteFallback_;
    public static int VocabularyOutputPieceScoreFieldNumber;
    private static bool VocabularyOutputPieceScoreDefaultValue;
    private bool vocabularyOutputPieceScore_;
    public static int HardVocabLimitFieldNumber;
    private static bool HardVocabLimitDefaultValue;
    private bool hardVocabLimit_;
    public static int UseAllVocabFieldNumber;
    private static bool UseAllVocabDefaultValue;
    private bool useAllVocab_;
    public static int UnkIdFieldNumber;
    private static int UnkIdDefaultValue;
    private int unkId_;
    public static int BosIdFieldNumber;
    private static int BosIdDefaultValue;
    private int bosId_;
    public static int EosIdFieldNumber;
    private static int EosIdDefaultValue;
    private int eosId_;
    public static int PadIdFieldNumber;
    private static int PadIdDefaultValue;
    private int padId_;
    public static int UnkPieceFieldNumber;
    private static string UnkPieceDefaultValue;
    private string unkPiece_;
    public static int BosPieceFieldNumber;
    private static string BosPieceDefaultValue;
    private string bosPiece_;
    public static int EosPieceFieldNumber;
    private static string EosPieceDefaultValue;
    private string eosPiece_;
    public static int PadPieceFieldNumber;
    private static string PadPieceDefaultValue;
    private string padPiece_;
    public static int UnkSurfaceFieldNumber;
    private static string UnkSurfaceDefaultValue;
    private string unkSurface_;
    public static int TrainExtremelyLargeCorpusFieldNumber;
    private static bool TrainExtremelyLargeCorpusDefaultValue;
    private bool trainExtremelyLargeCorpus_;
    public static int SeedSentencepiecesFileFieldNumber;
    private static string SeedSentencepiecesFileDefaultValue;
    private string seedSentencepiecesFile_;
    private ExtensionSet`1<TrainerSpec> _Extensions { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public static MessageParser`1<TrainerSpec> Parser { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public static MessageDescriptor Descriptor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private MessageDescriptor pb::Google.Protobuf.IMessage.Descriptor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public RepeatedField`1<string> Input { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string InputFormat { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasInputFormat { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string ModelPrefix { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasModelPrefix { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public ModelType ModelType { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasModelType { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int VocabSize { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasVocabSize { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public RepeatedField`1<string> AcceptLanguage { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int SelfTestSampleSize { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasSelfTestSampleSize { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool EnableDifferentialPrivacy { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasEnableDifferentialPrivacy { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public float DifferentialPrivacyNoiseLevel { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasDifferentialPrivacyNoiseLevel { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public ulong DifferentialPrivacyClippingThreshold { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasDifferentialPrivacyClippingThreshold { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public float CharacterCoverage { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasCharacterCoverage { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public ulong InputSentenceSize { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasInputSentenceSize { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool ShuffleInputSentence { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasShuffleInputSentence { get; }
    [ObsoleteAttribute]
[DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int MiningSentenceSize { get; public set; }
    [ObsoleteAttribute]
[DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasMiningSentenceSize { get; }
    [ObsoleteAttribute]
[DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int TrainingSentenceSize { get; public set; }
    [ObsoleteAttribute]
[DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasTrainingSentenceSize { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int SeedSentencepieceSize { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasSeedSentencepieceSize { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public float ShrinkingFactor { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasShrinkingFactor { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int MaxSentenceLength { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasMaxSentenceLength { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int NumThreads { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasNumThreads { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int NumSubIterations { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasNumSubIterations { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int MaxSentencepieceLength { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasMaxSentencepieceLength { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool SplitByUnicodeScript { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasSplitByUnicodeScript { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool SplitByNumber { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasSplitByNumber { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool SplitByWhitespace { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasSplitByWhitespace { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool TreatWhitespaceAsSuffix { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasTreatWhitespaceAsSuffix { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool AllowWhitespaceOnlyPieces { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasAllowWhitespaceOnlyPieces { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool SplitDigits { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasSplitDigits { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string PretokenizationDelimiter { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasPretokenizationDelimiter { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public RepeatedField`1<string> ControlSymbols { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public RepeatedField`1<string> UserDefinedSymbols { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string RequiredChars { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasRequiredChars { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool ByteFallback { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasByteFallback { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool VocabularyOutputPieceScore { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasVocabularyOutputPieceScore { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HardVocabLimit { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasHardVocabLimit { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool UseAllVocab { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasUseAllVocab { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int UnkId { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasUnkId { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int BosId { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasBosId { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int EosId { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasEosId { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public int PadId { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasPadId { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string UnkPiece { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasUnkPiece { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string BosPiece { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasBosPiece { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string EosPiece { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasEosPiece { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string PadPiece { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasPadPiece { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string UnkSurface { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasUnkSurface { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool TrainExtremelyLargeCorpus { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasTrainExtremelyLargeCorpus { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public string SeedSentencepiecesFile { get; public set; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public bool HasSeedSentencepiecesFile { get; }
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public TrainerSpec(TrainerSpec other);
    private static TrainerSpec();
    private ExtensionSet`1<TrainerSpec> get__Extensions();
    public static MessageParser`1<TrainerSpec> get_Parser();
    public static MessageDescriptor get_Descriptor();
    private sealed virtual override MessageDescriptor pb::Google.Protobuf.IMessage.get_Descriptor();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual TrainerSpec Clone();
    public RepeatedField`1<string> get_Input();
    public string get_InputFormat();
    public void set_InputFormat(string value);
    public bool get_HasInputFormat();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearInputFormat();
    public string get_ModelPrefix();
    public void set_ModelPrefix(string value);
    public bool get_HasModelPrefix();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearModelPrefix();
    public ModelType get_ModelType();
    public void set_ModelType(ModelType value);
    public bool get_HasModelType();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearModelType();
    public int get_VocabSize();
    public void set_VocabSize(int value);
    public bool get_HasVocabSize();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearVocabSize();
    public RepeatedField`1<string> get_AcceptLanguage();
    public int get_SelfTestSampleSize();
    public void set_SelfTestSampleSize(int value);
    public bool get_HasSelfTestSampleSize();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearSelfTestSampleSize();
    public bool get_EnableDifferentialPrivacy();
    public void set_EnableDifferentialPrivacy(bool value);
    public bool get_HasEnableDifferentialPrivacy();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearEnableDifferentialPrivacy();
    public float get_DifferentialPrivacyNoiseLevel();
    public void set_DifferentialPrivacyNoiseLevel(float value);
    public bool get_HasDifferentialPrivacyNoiseLevel();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearDifferentialPrivacyNoiseLevel();
    public ulong get_DifferentialPrivacyClippingThreshold();
    public void set_DifferentialPrivacyClippingThreshold(ulong value);
    public bool get_HasDifferentialPrivacyClippingThreshold();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearDifferentialPrivacyClippingThreshold();
    public float get_CharacterCoverage();
    public void set_CharacterCoverage(float value);
    public bool get_HasCharacterCoverage();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearCharacterCoverage();
    public ulong get_InputSentenceSize();
    public void set_InputSentenceSize(ulong value);
    public bool get_HasInputSentenceSize();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearInputSentenceSize();
    public bool get_ShuffleInputSentence();
    public void set_ShuffleInputSentence(bool value);
    public bool get_HasShuffleInputSentence();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearShuffleInputSentence();
    public int get_MiningSentenceSize();
    public void set_MiningSentenceSize(int value);
    public bool get_HasMiningSentenceSize();
    [ObsoleteAttribute]
[DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearMiningSentenceSize();
    public int get_TrainingSentenceSize();
    public void set_TrainingSentenceSize(int value);
    public bool get_HasTrainingSentenceSize();
    [ObsoleteAttribute]
[DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearTrainingSentenceSize();
    public int get_SeedSentencepieceSize();
    public void set_SeedSentencepieceSize(int value);
    public bool get_HasSeedSentencepieceSize();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearSeedSentencepieceSize();
    public float get_ShrinkingFactor();
    public void set_ShrinkingFactor(float value);
    public bool get_HasShrinkingFactor();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearShrinkingFactor();
    public int get_MaxSentenceLength();
    public void set_MaxSentenceLength(int value);
    public bool get_HasMaxSentenceLength();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearMaxSentenceLength();
    public int get_NumThreads();
    public void set_NumThreads(int value);
    public bool get_HasNumThreads();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearNumThreads();
    public int get_NumSubIterations();
    public void set_NumSubIterations(int value);
    public bool get_HasNumSubIterations();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearNumSubIterations();
    public int get_MaxSentencepieceLength();
    public void set_MaxSentencepieceLength(int value);
    public bool get_HasMaxSentencepieceLength();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearMaxSentencepieceLength();
    public bool get_SplitByUnicodeScript();
    public void set_SplitByUnicodeScript(bool value);
    public bool get_HasSplitByUnicodeScript();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearSplitByUnicodeScript();
    public bool get_SplitByNumber();
    public void set_SplitByNumber(bool value);
    public bool get_HasSplitByNumber();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearSplitByNumber();
    public bool get_SplitByWhitespace();
    public void set_SplitByWhitespace(bool value);
    public bool get_HasSplitByWhitespace();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearSplitByWhitespace();
    public bool get_TreatWhitespaceAsSuffix();
    public void set_TreatWhitespaceAsSuffix(bool value);
    public bool get_HasTreatWhitespaceAsSuffix();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearTreatWhitespaceAsSuffix();
    public bool get_AllowWhitespaceOnlyPieces();
    public void set_AllowWhitespaceOnlyPieces(bool value);
    public bool get_HasAllowWhitespaceOnlyPieces();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearAllowWhitespaceOnlyPieces();
    public bool get_SplitDigits();
    public void set_SplitDigits(bool value);
    public bool get_HasSplitDigits();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearSplitDigits();
    public string get_PretokenizationDelimiter();
    public void set_PretokenizationDelimiter(string value);
    public bool get_HasPretokenizationDelimiter();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearPretokenizationDelimiter();
    public RepeatedField`1<string> get_ControlSymbols();
    public RepeatedField`1<string> get_UserDefinedSymbols();
    public string get_RequiredChars();
    public void set_RequiredChars(string value);
    public bool get_HasRequiredChars();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearRequiredChars();
    public bool get_ByteFallback();
    public void set_ByteFallback(bool value);
    public bool get_HasByteFallback();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearByteFallback();
    public bool get_VocabularyOutputPieceScore();
    public void set_VocabularyOutputPieceScore(bool value);
    public bool get_HasVocabularyOutputPieceScore();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearVocabularyOutputPieceScore();
    public bool get_HardVocabLimit();
    public void set_HardVocabLimit(bool value);
    public bool get_HasHardVocabLimit();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearHardVocabLimit();
    public bool get_UseAllVocab();
    public void set_UseAllVocab(bool value);
    public bool get_HasUseAllVocab();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearUseAllVocab();
    public int get_UnkId();
    public void set_UnkId(int value);
    public bool get_HasUnkId();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearUnkId();
    public int get_BosId();
    public void set_BosId(int value);
    public bool get_HasBosId();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearBosId();
    public int get_EosId();
    public void set_EosId(int value);
    public bool get_HasEosId();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearEosId();
    public int get_PadId();
    public void set_PadId(int value);
    public bool get_HasPadId();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearPadId();
    public string get_UnkPiece();
    public void set_UnkPiece(string value);
    public bool get_HasUnkPiece();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearUnkPiece();
    public string get_BosPiece();
    public void set_BosPiece(string value);
    public bool get_HasBosPiece();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearBosPiece();
    public string get_EosPiece();
    public void set_EosPiece(string value);
    public bool get_HasEosPiece();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearEosPiece();
    public string get_PadPiece();
    public void set_PadPiece(string value);
    public bool get_HasPadPiece();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearPadPiece();
    public string get_UnkSurface();
    public void set_UnkSurface(string value);
    public bool get_HasUnkSurface();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearUnkSurface();
    public bool get_TrainExtremelyLargeCorpus();
    public void set_TrainExtremelyLargeCorpus(bool value);
    public bool get_HasTrainExtremelyLargeCorpus();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearTrainExtremelyLargeCorpus();
    public string get_SeedSentencepiecesFile();
    public void set_SeedSentencepiecesFile(string value);
    public bool get_HasSeedSentencepiecesFile();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public void ClearSeedSentencepiecesFile();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual bool Equals(object other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual bool Equals(TrainerSpec other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual int GetHashCode();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public virtual string ToString();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void WriteTo(CodedOutputStream output);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private sealed virtual override void pb::Google.Protobuf.IBufferMessage.InternalWriteTo(WriteContext& output);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual int CalculateSize();
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void MergeFrom(TrainerSpec other);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
public sealed virtual void MergeFrom(CodedInputStream input);
    [DebuggerNonUserCodeAttribute]
[GeneratedCodeAttribute("protoc", "")]
private sealed virtual override void pb::Google.Protobuf.IBufferMessage.InternalMergeFrom(ParseContext& input);
    public sealed virtual TValue GetExtension(Extension`2<TrainerSpec, TValue> extension);
    public sealed virtual RepeatedField`1<TValue> GetExtension(RepeatedExtension`2<TrainerSpec, TValue> extension);
    public sealed virtual RepeatedField`1<TValue> GetOrInitializeExtension(RepeatedExtension`2<TrainerSpec, TValue> extension);
    public sealed virtual void SetExtension(Extension`2<TrainerSpec, TValue> extension, TValue value);
    public sealed virtual bool HasExtension(Extension`2<TrainerSpec, TValue> extension);
    public sealed virtual void ClearExtension(Extension`2<TrainerSpec, TValue> extension);
    public sealed virtual void ClearExtension(RepeatedExtension`2<TrainerSpec, TValue> extension);
}
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
[SkipLocalsInitAttribute]
internal class System.Text.RegularExpressions.Generated.<RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__Cl100kBaseRegex_0 : Regex {
    [NullableAttribute("1")]
internal static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__Cl100kBaseRegex_0 Instance;
    private static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__Cl100kBaseRegex_0();
}
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
[SkipLocalsInitAttribute]
internal class System.Text.RegularExpressions.Generated.<RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__O200kBaseRegex_2 : Regex {
    [NullableAttribute("1")]
internal static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__O200kBaseRegex_2 Instance;
    private static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__O200kBaseRegex_2();
}
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
[SkipLocalsInitAttribute]
internal class System.Text.RegularExpressions.Generated.<RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__P50kBaseRegex_1 : Regex {
    [NullableAttribute("1")]
internal static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__P50kBaseRegex_1 Instance;
    private static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__P50kBaseRegex_1();
}
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
[SkipLocalsInitAttribute]
internal class System.Text.RegularExpressions.Generated.<RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__PretokenizeRegex_3 : Regex {
    [NullableAttribute("1")]
internal static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__PretokenizeRegex_3 Instance;
    private static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__PretokenizeRegex_3();
}
[GeneratedCodeAttribute("System.Text.RegularExpressions.Generator", "8.0.10.6711")]
internal static class System.Text.RegularExpressions.Generated.<RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__Utilities : object {
    internal static TimeSpan s_defaultTimeout;
    internal static bool s_hasTimeout;
    private static <RegexGenerator_g>FDF62D86A1D181DC904D12536914C2EA774396C6B9770EB520C299FABEF56CFED__Utilities();
    internal static bool IsWordChar(char ch);
    [NullableContextAttribute("1")]
internal static void StackPush(Int32[]& stack, Int32& pos, int arg0);
    [NullableContextAttribute("1")]
[CompilerGeneratedAttribute]
internal static void <StackPush>g__WithResize|3_0(Int32[]& stack, Int32& pos, int arg0);
}
[IsByRefLikeAttribute]
[ObsoleteAttribute("Types with embedded references are not supported in this version of your compiler.", "True")]
[CompilerFeatureRequiredAttribute("RefStructs")]
[DefaultMemberAttribute("Item")]
internal class System.Text.ValueStringBuilder : ValueType {
    [NullableAttribute("2")]
private Char[] _arrayToReturnToPool;
    private Span`1<char> _chars;
    private int _pos;
    private static UInt32 ArrayMaxLength;
    public int Length { get; public set; }
    public int Capacity { get; }
    public Char& Item { get; }
    public Span`1<char> RawChars { get; }
    public ValueStringBuilder(Span`1<char> initialBuffer);
    public ValueStringBuilder(int initialCapacity);
    public int get_Length();
    public void set_Length(int value);
    public int get_Capacity();
    public void EnsureCapacity(int capacity);
    public Char& GetPinnableReference();
    public Char& GetPinnableReference(bool terminate);
    public Char& get_Item(int index);
    [NullableContextAttribute("1")]
public string ToString(char oldValue, char newValue);
    [NullableContextAttribute("1")]
public virtual string ToString();
    public Span`1<char> get_RawChars();
    public ReadOnlySpan`1<char> AsSpan(bool terminate);
    public void RemoveLastChar();
    public ReadOnlySpan`1<char> AsSpan();
    public ReadOnlySpan`1<char> AsSpan(int start);
    public ReadOnlySpan`1<char> AsSpan(int start, int length);
    public bool TryCopyTo(Span`1<char> destination, Int32& charsWritten);
    [NullableContextAttribute("1")]
public void Replace(string oldValue, string newValue);
    [NullableContextAttribute("1")]
public bool RemoveSuffix(string value);
    [NullableContextAttribute("1")]
public bool EndsWith(string value);
    public void Insert(int index, char value, int count);
    [NullableContextAttribute("2")]
public void Insert(int index, string s);
    public void Append(char c);
    [NullableContextAttribute("2")]
public void Append(string s);
    [NullableContextAttribute("1")]
private void AppendSlow(string s);
    public void Append(char c, int count);
    public void Append(Char* value, int length);
    public void Append(ReadOnlySpan`1<char> value);
    public Span`1<char> AppendSpan(int length);
    private void GrowAndAppend(char c);
    private void Grow(int additionalCapacityBeyondPos);
    public void Dispose();
}
